{
    "cells": [
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "# Trump Speech Analysis for 2025 SOTU Predictions\n",
       "\n",
       "This notebook analyzes the frequency of specific phrases in Trump's speeches, with a focus on:\n",
       "1. Previous State of the Union addresses\n",
       "2. Recent speeches (since Jan 20, 2025 inauguration)\n",
       "3. Overall usage patterns across all speeches"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
       "import os\n",
       "import re\n",
       "from datetime import datetime\n",
       "import pandas as pd\n",
       "import matplotlib.pyplot as plt\n",
       "import seaborn as sns\n",
       "from collections import defaultdict\n",
       "\n",
       "# Set style for plots\n",
       "plt.style.use('default')  # Use default matplotlib style\n",
       "sns.set_theme(style='whitegrid')  # Set seaborn style\n",
       "plt.rcParams['figure.figsize'] = [12, 6]  # Set default figure size"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
       "# Define the phrases to search for\n",
       "SEARCH_PHRASES = {\n",
       "    'Immigration': r'\\b(illegal\\s+immigra(nt|tion|nts)|immigra(nt|tion|nts))\\b',\n",
       "    'America First': r'\\bamerica\\s+first\\b',\n",
       "    'America': r'\\bamerica\\b',\n",
       "    'Border': r'\\bborder(s)?\\b',\n",
       "    'DOGE': r'\\b(doge|department\\s+of\\s+government\\s+efficiency)\\b',\n",
       "    'AI': r'\\b(ai|artificial\\s+intelligence)\\b',\n",
       "    'Ceasefire': r'\\bceasefire(s)?\\b',\n",
       "    'Middle Class': r'\\bmiddle\\s+class\\b',\n",
       "    'God': r'\\bgod\\b',\n",
       "    'Elon': r'\\b(elon|elon\\s+musk)\\b',\n",
       "    'Drill Baby Drill': r'\\bdrill\\s+baby\\s+drill\\b',\n",
       "    'Biden': r'\\bbiden\\b',\n",
       "    'Make America Healthy Again': r'\\bmake\\s+america\\s+healthy\\s+again\\b',\n",
       "    'LA': r'\\b(la|los\\s+angeles)\\b',\n",
       "    'January 6': r'\\b(january\\s+6(th)?|6th\\s+of\\s+january)\\b',\n",
       "    'TikTok': r'\\btiktok\\b',\n",
       "    'Crypto': r'\\b(crypto|bitcoin)\\b',\n",
       "    'MAGA': r'\\b(maga|make\\s+america\\s+great\\s+again)\\b',\n",
       "    'Trans': r'\\btrans\\b',\n",
       "    'Kamala': r'\\bkamala\\b',\n",
       "    'Rigged': r'\\b(rig(ged)?|rigging)\\b',\n",
       "    'Mandate': r'\\bmandate(s|d)?\\b',\n",
       "    'Carnage': r'\\bcarnage\\b'\n",
       "]\n",
       "\n",
       "# Inauguration date\n",
       "INAUGURATION_DATE = datetime(2025, 1, 20)"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
       "def count_phrases(text, phrases=SEARCH_PHRASES):\n",
       "    \"\"\"Count occurrences of phrases in text\"\"\"\n",
       "    counts = {}\n",
       "    for name, pattern in phrases.items():\n",
       "        counts[name] = len(re.findall(pattern, text.lower()))\n",
       "    return counts\n",
       "\n",
       "def get_date_from_filename(filename):\n",
       "    \"\"\"Extract date from filename format YYYY-MM-DD_...\"\"\"\n",
       "    date_str = filename.split('_')[0]\n",
       "    return datetime.strptime(date_str, '%Y-%m-%d')\n",
       "\n",
       "def read_transcript(filepath):\n",
       "    \"\"\"Read and return transcript text\"\"\"\n",
       "    with open(filepath, 'r', encoding='utf-8') as f:\n",
       "        return f.read()\n",
       "\n",
       "def process_directory(directory):\n",
       "    \"\"\"Process all transcripts in a directory and its subdirectories\"\"\"\n",
       "    results = []\n",
       "    \n",
       "    for root, _, files in os.walk(directory):\n",
       "        for file in files:\n",
       "            if file.endswith('.txt'):\n",
       "                filepath = os.path.join(root, file)\n",
       "                try:\n",
       "                    date = get_date_from_filename(file)\n",
       "                    text = read_transcript(filepath)\n",
       "                    counts = count_phrases(text)\n",
       "                    \n",
       "                    results.append({\n",
       "                        'date': date,\n",
       "                        'file': file,\n",
       "                        'category': os.path.basename(root),\n",
       "                        'text_length': len(text.split()),\n",
       "                        **counts\n",
       "                    })\n",
       "                except Exception as e:\n",
       "                    print(f\"Error processing {filepath}: {str(e)}\")\n",
       "    \n",
       "    return pd.DataFrame(results)"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
       "# Process all transcripts\n",
       "df = process_directory('../data/processed-transcripts')\n",
       "df = df.sort_values('date')\n",
       "\n",
       "# Create separate dataframes for different time periods\n",
       "df_post_inaug = df[df['date'] >= INAUGURATION_DATE]\n",
       "df_sotu = df[df['category'] == 'sotu']\n",
       "\n",
       "print(f\"Total transcripts: {len(df)}\")\n",
       "print(f\"Post-inauguration transcripts: {len(df_post_inaug)}\")\n",
       "print(f\"SOTU addresses: {len(df_sotu)}\")"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
       "# Calculate frequency per 1000 words for each period\n",
       "def calculate_frequencies(df):\n",
       "    total_words = df['text_length'].sum()\n",
       "    frequencies = {}\n",
       "    \n",
       "    for phrase in SEARCH_PHRASES.keys():\n",
       "        total_occurrences = df[phrase].sum()\n",
       "        frequency = (total_occurrences / total_words) * 1000\n",
       "        frequencies[phrase] = {\n",
       "            'total_occurrences': total_occurrences,\n",
       "            'frequency_per_1000': frequency\n",
       "        }\n",
       "    \n",
       "    return pd.DataFrame(frequencies).T\n",
       "\n",
       "# Calculate frequencies for each period\n",
       "freq_all = calculate_frequencies(df)\n",
       "freq_post_inaug = calculate_frequencies(df_post_inaug)\n",
       "freq_sotu = calculate_frequencies(df_sotu)\n",
       "\n",
       "# Combine into a single table\n",
       "comparison_table = pd.DataFrame({\n",
       "    'All Time Occurrences': freq_all['total_occurrences'],\n",
       "    'All Time Freq (per 1000 words)': freq_all['frequency_per_1000'],\n",
       "    'Post-Inaug Occurrences': freq_post_inaug['total_occurrences'],\n",
       "    'Post-Inaug Freq (per 1000 words)': freq_post_inaug['frequency_per_1000'],\n",
       "    'SOTU Occurrences': freq_sotu['total_occurrences'],\n",
       "    'SOTU Freq (per 1000 words)': freq_sotu['frequency_per_1000']\n",
       "})\n",
       "\n",
       "# Sort by total occurrences\n",
       "comparison_table = comparison_table.sort_values('All Time Occurrences', ascending=False)\n",
       "\n",
       "# Display the table\n",
       "pd.set_option('display.float_format', lambda x: '%.2f' % x)\n",
       "comparison_table"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## Trends Over Time\n",
       "\n",
       "Let's visualize how the usage of the most frequent terms has changed over time:"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
       "# Get top 10 most frequent terms\n",
       "top_terms = comparison_table.nlargest(10, 'All Time Occurrences').index\n",
       "\n",
       "# Create a rolling average plot for each term\n",
       "plt.figure(figsize=(15, 8))\n",
       "\n",
       "for term in top_terms:\n",
       "    # Calculate rolling average (30-day window)\n",
       "    term_freq = df.set_index('date').resample('D')[term].mean().rolling(window=30, min_periods=1).mean()\n",
       "    plt.plot(term_freq.index, term_freq.values, label=term, alpha=0.7)\n",
       "\n",
       "plt.title('30-Day Rolling Average Usage of Top Terms')\n",
       "plt.xlabel('Date')\n",
       "plt.ylabel('Average Occurrences per Speech')\n",
       "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
       "plt.tight_layout()\n",
       "plt.grid(True, alpha=0.3)\n",
       "plt.show()"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## SOTU-Specific Analysis\n",
       "\n",
       "Let's look at how these terms have been used in previous State of the Union addresses:"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
       "# Create a heatmap of term usage in SOTU addresses\n",
       "sotu_pivot = df_sotu.pivot(index='date', columns=df_sotu.columns[4:-1].tolist(), values=df_sotu.columns[4:-1].tolist())\n",
       "\n",
       "plt.figure(figsize=(15, 10))\n",
       "sns.heatmap(sotu_pivot, cmap='YlOrRd', annot=True, fmt='g')\n",
       "plt.title('Term Usage in State of the Union Addresses')\n",
       "plt.xlabel('Terms')\n",
       "plt.ylabel('Date')\n",
       "plt.xticks(rotation=45, ha='right')\n",
       "plt.tight_layout()\n",
       "plt.show()"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## Recent Trends (Post-Inauguration)\n",
       "\n",
       "Let's analyze how term usage has changed since the 2025 inauguration:"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
       "# Calculate weekly averages for post-inauguration period\n",
       "weekly_avg = df_post_inaug.set_index('date').resample('W').mean()\n",
       "\n",
       "# Plot weekly trends for top terms\n",
       "plt.figure(figsize=(15, 8))\n",
       "\n",
       "for term in top_terms[:5]:  # Top 5 terms for clarity\n",
       "    plt.plot(weekly_avg.index, weekly_avg[term], label=term, marker='o', alpha=0.7)\n",
       "\n",
       "plt.title('Weekly Average Usage of Top Terms (Post-Inauguration)')\n",
       "plt.xlabel('Date')\n",
       "plt.ylabel('Average Occurrences per Speech')\n",
       "plt.legend()\n",
       "plt.grid(True, alpha=0.3)\n",
       "plt.tight_layout()\n",
       "plt.show()"
      ]
     }
    ],
    "metadata": {
     "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
     },
     "language_info": {
      "codemirror_mode": {
       "name": "ipython",
       "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
     }
    },
    "nbformat": 4,
    "nbformat_minor": 4
   }