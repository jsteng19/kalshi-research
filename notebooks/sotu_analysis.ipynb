{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trump Speech Analysis for 2025 SOTU Predictions\n",
    "\n",
    "This notebook analyzes the frequency of specific phrases to predict their occurrence in the 2025 SOTU address using:\n",
    "1. Regular speeches (pre-inauguration)\n",
    "2. Post-inauguration speeches (Jan 20, 2025 onwards)\n",
    "3. Previous State of the Union addresses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set style for plots\n",
    "plt.style.use('default')\n",
    "sns.set_theme(style='whitegrid')\n",
    "plt.rcParams['figure.figsize'] = [12, 6]\n",
    "\n",
    "# Set pandas display options\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "INAUGURATION_DATE = datetime(2025, 1, 20)\n",
    "CONTEXT_WINDOW = 200 # words to display for context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Phrases to Track\n",
    "\n",
    "- Illegal Immigrant / Immigration\n",
    "- America First\n",
    "- DOGE / Department of Government Efficiency \n",
    "- America (15+ times)\n",
    "- Israel\n",
    "- Border (5+ times)\n",
    "- AI / Artificial Intelligence\n",
    "- Canada\n",
    "- Mexico\n",
    "- Middle Class\n",
    "- Ceasefire\n",
    "- Gaza\n",
    "- God (4+ times)\n",
    "- Biden\n",
    "- Panama\n",
    "- Elon / Elon Musk\n",
    "- Drill Baby Drill\n",
    "- LA / Los Angeles\n",
    "- Make America Healthy Again\n",
    "- January 6\n",
    "- TikTok\n",
    "- Crypto / Bitcoin\n",
    "- Hell\n",
    "- Kamala\n",
    "- Trans\n",
    "- Greenland\n",
    "- MAGA / Make America Great Again (4+ times)\n",
    "- Rig / Rigged\n",
    "- Mandate (3+ times)\n",
    "- Carnage\n",
    "- Doge / Dogecoin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Claude don't touch this cell!\n",
    "SEARCH_PHRASES = {\n",
    "    'Immigration': r'\\b(illegal\\s+immigra(nt|nts|nt\\'s|nts\\')|immigration)\\b',\n",
    "    'America First': r'\\b(america\\s+first)\\b',\n",
    "    'America': r'\\b(america|america\\'s)\\b', \n",
    "    'Border': r'\\b(border|borders|border\\'s|borders\\')\\b',\n",
    "    'DOGE': r'\\b(doge|doge\\'s|department\\s+of\\s+government\\s+efficiency)\\b',\n",
    "    'AI': r'\\b(ai|ai\\'s|artificial\\s+intelligence|artificial\\s+intelligence\\'s)\\b',\n",
    "    'Ceasefire': r'\\b(ceasefire|ceasefires|ceasefire\\'s|ceasefires\\')\\b',\n",
    "    'Middle Class': r'\\b(middle\\s+class|middle\\s+class\\'s|middle\\s+classes|middle\\s+classes\\')\\b',\n",
    "    'God': r'\\b(god|god\\'s|gods|gods\\')\\b',\n",
    "    'Elon': r'\\b(elon|elon\\'s|elon\\s+musk|elon\\s+musk\\'s)\\b',\n",
    "    'Drill Baby Drill': r'\\bdrill\\s+baby\\s+drill\\b',\n",
    "    'Biden': r'\\b(biden|biden\\'s)\\b',\n",
    "    'Make America Healthy Again': r'\\bmake\\s+america\\s+healthy\\s+again\\b',\n",
    "    'LA': r'\\b(LA|LA\\'s|los\\s+angeles|los\\s+angeles\\')\\b',\n",
    "    'January 6': r'\\b(january\\s+6(th)?|january\\s+sixth)\\b',\n",
    "    'TikTok': r'\\b(tiktok|tiktok\\'s)\\b',\n",
    "    'Crypto': r'\\b(crypto|crypto\\'s|cryptos|bitcoin|bitcoin\\'s)\\b',\n",
    "    'MAGA': r'\\b(maga|maga\\'s|make\\s+america\\s+great\\s+again)\\b',\n",
    "    'Trans': r'\\b(trans)(?!-)\\b',\n",
    "    'Kamala': r'\\b(kamala|kamala\\'s)\\b',\n",
    "    'Rigged': r'\\b(rig(ged)?)\\b',\n",
    "    'Mandate': r'\\b(mandate|mandates|mandate\\'s|mandates\\')\\b',\n",
    "    'Carnage': r'\\b(carnage|carnage\\'s)\\b',\n",
    "    'Israel': r'\\b(israel|israel\\'s)\\b',\n",
    "    'Hell': r'\\b(hell|hell\\'s)\\b',\n",
    "    'Greenland': r'\\b(greenland|greenland\\'s)\\b',\n",
    "    'Mexico': r'\\b(mexico|mexico\\'s)\\b',\n",
    "    'Canada': r'\\b(canada|canada\\'s)\\b',\n",
    "    'Panama': r'\\b(panama|panama\\'s)\\b',\n",
    "    'Gaza': r'\\b(gaza|gaza\\'s)\\b',\n",
    "   \n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_phrases(text, phrases=SEARCH_PHRASES):\n",
    "    \"\"\"Count occurrences of phrases in text\"\"\"\n",
    "    counts = {}\n",
    "    for name, pattern in phrases.items():\n",
    "        counts[name] = len(re.findall(pattern, text.lower()))\n",
    "    return counts\n",
    "\n",
    "def get_date_from_filename(filename):\n",
    "    \"\"\"Extract date from filename format YYYY-MM-DD_...\"\"\"\n",
    "    date_str = filename.split('_')[0]\n",
    "    return datetime.strptime(date_str, '%Y-%m-%d')\n",
    "\n",
    "def read_transcript(filepath):\n",
    "    \"\"\"Read and return transcript text\"\"\"\n",
    "    with open(filepath, 'r', encoding='utf-8') as f:\n",
    "        return f.read()\n",
    "\n",
    "def find_phrase_context(text, pattern, window=CONTEXT_WINDOW):\n",
    "    \"\"\"Find phrase in text with surrounding context\"\"\"\n",
    "    matches = []\n",
    "    for match in re.finditer(pattern, text.lower()):\n",
    "        start = max(0, match.start() - window)\n",
    "        end = min(len(text), match.end() + window)\n",
    "        context = text[start:end]\n",
    "        # Add ellipsis if we're not at the start/end of the text\n",
    "        if start > 0:\n",
    "            context = '...' + context\n",
    "        if end < len(text):\n",
    "            context = context + '...'\n",
    "        matches.append(context)\n",
    "    return matches\n",
    "\n",
    "def process_directory(directory):\n",
    "    \"\"\"Process transcripts from speech and sotu directories only\"\"\"\n",
    "    results = []\n",
    "    categories_found = set()\n",
    "    \n",
    "    for root, _, files in os.walk(directory):\n",
    "        category = os.path.basename(root)\n",
    "        categories_found.add(category)\n",
    "        for file in files:\n",
    "            if file.endswith('.txt'):\n",
    "                filepath = os.path.join(root, file)\n",
    "                try:\n",
    "                    date = get_date_from_filename(file)\n",
    "                    text = read_transcript(filepath)\n",
    "                    counts = count_phrases(text)\n",
    "                    \n",
    "                    results.append({\n",
    "                        'date': date,\n",
    "                        'file': file,\n",
    "                        'category': category,\n",
    "                        'text_length': len(text.split()),\n",
    "                        'text': text,  # Store full text for context analysis\n",
    "                        **counts\n",
    "                    })\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing {filepath}: {str(e)}\")\n",
    "    \n",
    "    print(\"Categories found in directory:\")\n",
    "    for cat in sorted(categories_found):\n",
    "        print(f\"- {cat}\")\n",
    "    print(\"\\nOnly 'speech' and 'sotu' categories will be analyzed.\\n\")\n",
    "    \n",
    "    return pd.DataFrame(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process transcripts\n",
    "df = process_directory('../data/processed-transcripts')\n",
    "df = df.sort_values('date')\n",
    "\n",
    "# Filter out press briefings\n",
    "df = df[df['category'] != 'press briefing']\n",
    "\n",
    "# Split data by date and category\n",
    "speech_mask = df['category'] == 'speech'\n",
    "sotu_mask = df['category'] == 'sotu'\n",
    "date_mask = df['date'] >= INAUGURATION_DATE\n",
    "\n",
    "# Create speech dataframes\n",
    "df_speech = df[speech_mask]\n",
    "df_speech_pre = df[speech_mask & ~date_mask]\n",
    "df_speech_post = df[speech_mask & date_mask]\n",
    "\n",
    "# Create non-speech and SOTU dataframes \n",
    "df_nonspeech = df[~speech_mask & ~sotu_mask]\n",
    "df_nonspeech_pre = df[~speech_mask & ~sotu_mask & ~date_mask]\n",
    "df_nonspeech_post = df[~speech_mask & ~sotu_mask & date_mask]\n",
    "df_sotu = df[sotu_mask]\n",
    "\n",
    "df_pre = pd.concat([df_speech_pre, df_nonspeech_pre])\n",
    "df_post = pd.concat([df_speech_post, df_nonspeech_post])\n",
    "\n",
    "# Print dataset statistics\n",
    "print(\"Dataset Statistics:\")\n",
    "print(\"Speeches:\")\n",
    "print(f\"Pre-inauguration: {len(df_speech_pre)}\")\n",
    "print(f\"Post-inauguration: {len(df_speech_post)}\")\n",
    "print(\"\\nNon-speeches:\")\n",
    "print(f\"Pre-inauguration: {len(df_nonspeech_pre)}\")\n",
    "print(f\"Post-inauguration: {len(df_nonspeech_post)}\")\n",
    "print(\"\\nState of the Union:\")\n",
    "print(f\"Total: {len(df_sotu)}\")\n",
    "\n",
    "print(\"\\nWord Count Statistics:\")\n",
    "print(\"Speeches:\")\n",
    "print(f\"Pre-inauguration average length: {df_speech_pre['text_length'].mean():.0f} words\")\n",
    "print(f\"Post-inauguration average length: {df_speech_post['text_length'].mean():.0f} words\")\n",
    "print(\"\\nNon-speeches:\")\n",
    "print(f\"Pre-inauguration average length: {df_nonspeech_pre['text_length'].mean():.0f} words\") \n",
    "print(f\"Post-inauguration average length: {df_nonspeech_post['text_length'].mean():.0f} words\")\n",
    "print(\"\\nState of the Union:\")\n",
    "print(f\"Average length: {df_sotu['text_length'].mean():.0f} words\")\n",
    "\n",
    "print(\"\\nDate Ranges:\")\n",
    "print(\"Speeches:\")\n",
    "print(f\"Pre-inauguration: {df_speech_pre['date'].min().strftime('%Y-%m-%d')} to {df_speech_pre['date'].max().strftime('%Y-%m-%d')}\")\n",
    "print(f\"Post-inauguration: {df_speech_post['date'].min().strftime('%Y-%m-%d')} to {df_speech_post['date'].max().strftime('%Y-%m-%d')}\")\n",
    "print(\"\\nNon-speeches:\")\n",
    "print(f\"Pre-inauguration: {df_nonspeech_pre['date'].min().strftime('%Y-%m-%d')} to {df_nonspeech_pre['date'].max().strftime('%Y-%m-%d')}\")\n",
    "print(f\"Post-inauguration: {df_nonspeech_post['date'].min().strftime('%Y-%m-%d')} to {df_nonspeech_post['date'].max().strftime('%Y-%m-%d')}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phrase Frequency Over Time\n",
    "\n",
    "Speeches dropped off dramatically between election day and inauguration day. Non-speech transcripts mostly don't go back as far in time (need to scrape more data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_phrase_frequency_over_time(df_speech, df_non_speech, phrase, window=30):\n",
    "    \"\"\"Plot the frequency of a phrase over time with separate lines for speech and non-speech\"\"\"\n",
    "    plt.figure(figsize=(15, 6))\n",
    "    \n",
    "    # Process speech data\n",
    "    df_speech = df_speech.copy()\n",
    "    df_speech[f'{phrase}_freq'] = (df_speech[phrase] / df_speech['text_length']) * 1000\n",
    "    speech_series = df_speech.set_index('date')[f'{phrase}_freq']\n",
    "    speech_rolling = speech_series.rolling(window=f'{window}D', min_periods=1).mean()\n",
    "    \n",
    "    # Process non-speech data\n",
    "    df_non_speech = df_non_speech.copy()\n",
    "    df_non_speech[f'{phrase}_freq'] = (df_non_speech[phrase] / df_non_speech['text_length']) * 1000\n",
    "    non_speech_series = df_non_speech.set_index('date')[f'{phrase}_freq']\n",
    "    non_speech_rolling = non_speech_series.rolling(window=f'{window}D', min_periods=1).mean()\n",
    "    \n",
    "    # Plot speech data\n",
    "    plt.scatter(speech_series.index, speech_series.values, alpha=0.3, color='red', label='Speech Transcripts')\n",
    "    plt.plot(speech_rolling.index, speech_rolling.values, 'r-', linewidth=2, label=f'Speech {window}-day Average')\n",
    "    \n",
    "    # Plot non-speech data\n",
    "    plt.scatter(non_speech_series.index, non_speech_series.values, alpha=0.3, color='blue', label='Non-Speech Transcripts')\n",
    "    plt.plot(non_speech_rolling.index, non_speech_rolling.values, 'b-', linewidth=2, label=f'Non-Speech {window}-day Average')\n",
    "    \n",
    "    plt.title(f'Frequency of \"{phrase}\" Over Time')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Occurrences per 1000 words')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add vertical line for inauguration\n",
    "    plt.axvline(x=INAUGURATION_DATE, color='k', linestyle='--', alpha=0.5, label='Inauguration')\n",
    "    \n",
    "    # Auto-adjust y-axis limit up to max of 8\n",
    "    ymax = min(8, max(\n",
    "        df_speech[f'{phrase}_freq'].max(),\n",
    "        df_non_speech[f'{phrase}_freq'].max()\n",
    "    ) * 1.1)  # Add 10% padding\n",
    "    plt.ylim(0, ymax)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Plot time series for all phrases, sorted by frequency\n",
    "phrase_freqs = {}\n",
    "for phrase in SEARCH_PHRASES.keys():\n",
    "    # Calculate average frequency across all data\n",
    "    speech_freq = (df_speech[phrase].sum() / df_speech['text_length'].sum()) * 1000\n",
    "    nonspeech_freq = (df_nonspeech[phrase].sum() / df_nonspeech['text_length'].sum()) * 1000\n",
    "    phrase_freqs[phrase] = (speech_freq + nonspeech_freq) / 2\n",
    "\n",
    "# Sort phrases by frequency and plot\n",
    "for phrase in sorted(phrase_freqs, key=phrase_freqs.get, reverse=True):\n",
    "    plot_phrase_frequency_over_time(df_speech, df_nonspeech, phrase)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Previous State of the Unions\n",
    "\n",
    "Relevant for tone, stable phrases and for predicting length of future SOTUs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a table showing phrase counts for each SOTU\n",
    "sotu_counts = []\n",
    "\n",
    "for phrase in SEARCH_PHRASES.keys():\n",
    "    # Get counts for each SOTU\n",
    "    counts = df_sotu[['date', phrase]].values.tolist()\n",
    "    \n",
    "    # Format into a row with the phrase and counts\n",
    "    row = {'Phrase': phrase}\n",
    "    for date, count in counts:\n",
    "        year = date.year\n",
    "        row[f'SOTU {year}'] = count\n",
    "        \n",
    "    sotu_counts.append(row)\n",
    "\n",
    "# Convert to DataFrame and display\n",
    "df_sotu_counts = pd.DataFrame(sotu_counts)\n",
    "# Sort by average counts across all SOTUs\n",
    "df_sotu_counts['Average'] = df_sotu_counts[[col for col in df_sotu_counts.columns if 'SOTU' in col]].mean(axis=1)\n",
    "df_sotu_counts = df_sotu_counts.sort_values('Average', ascending=False)\n",
    "\n",
    "# Display the table\n",
    "display(df_sotu_counts.style.format({col: '{:.0f}' for col in df_sotu_counts.columns if 'SOTU' in col}))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Poisson Predictions\n",
    "\n",
    "The most naive approach is to use the past frequency of a phrase over a given time period to forecast the probability of a phrase occurring during the expected length of a future speech. Using the Poisson distribution, we assume each word is independent and identically distributed. This allows us to compute threshold probabilities for a phrase occurring a given number of times, which can be compared to the prediction market's implied probability. However, this approach does not account for the clear dependence between words in a speech. This approach can still be useful for analyzing mentions where mostly independent occurrences might be expected (America, God, etc.) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_poisson_predictions(df, avg_length):\n",
    "    \"\"\"Calculate predictions with likelihoods using Poisson distribution\"\"\"\n",
    "    predictions = []\n",
    "    \n",
    "    for phrase in SEARCH_PHRASES.keys():\n",
    "        # Calculate rate per word\n",
    "        total_occurrences = df[phrase].sum()\n",
    "        total_words = df['text_length'].sum()\n",
    "        rate_per_word = total_occurrences / total_words\n",
    "        \n",
    "        # Expected occurrences in SOTU\n",
    "        expected = rate_per_word * avg_length\n",
    "        \n",
    "        # Calculate likelihoods using Poisson PMF\n",
    "        def poisson_ge_k(lambda_, k):\n",
    "            return 1 - stats.poisson.cdf(k-1, lambda_)\n",
    "        \n",
    "        predictions.append({\n",
    "            'Phrase': phrase,\n",
    "            'Expected': expected,\n",
    "            'Historical Rate': rate_per_word * 1000,  # per 1000 words\n",
    "            'Total Historical': total_occurrences,\n",
    "            'P(≥1)': poisson_ge_k(expected, 1),\n",
    "            'P(≥3)': poisson_ge_k(expected, 3),\n",
    "            'P(≥4)': poisson_ge_k(expected, 4),\n",
    "            'P(≥5)': poisson_ge_k(expected, 5),\n",
    "            'P(≥15)': poisson_ge_k(expected, 15)\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(predictions)\n",
    "\n",
    "# Use SOTU average length for predictions\n",
    "avg_sotu_length = df_sotu['text_length'].mean()\n",
    "\n",
    "# Calculate predictions from different data sources\n",
    "predictions_all = calculate_poisson_predictions(df, avg_sotu_length)\n",
    "predictions_speeches = calculate_poisson_predictions(df_speech, avg_sotu_length)\n",
    "predictions_post_all = calculate_poisson_predictions(pd.concat([df_nonspeech_post, df_speech_post]), avg_sotu_length)\n",
    "\n",
    "# Format the tables\n",
    "def format_prediction_table(df, source):\n",
    "    formatted = df.copy()\n",
    "    formatted = formatted.round(2)\n",
    "    formatted['P(≥1)'] = formatted['P(≥1)'].apply(lambda x: f\"{x:.1%}\")\n",
    "    formatted['P(≥3)'] = formatted['P(≥3)'].apply(lambda x: f\"{x:.1%}\")\n",
    "    formatted['P(≥4)'] = formatted['P(≥4)'].apply(lambda x: f\"{x:.1%}\")\n",
    "    formatted['P(≥5)'] = formatted['P(≥5)'].apply(lambda x: f\"{x:.1%}\")\n",
    "    formatted['P(≥15)'] = formatted['P(≥15)'].apply(lambda x: f\"{x:.1%}\")\n",
    "    \n",
    "    return formatted[[\n",
    "        'Phrase', 'Expected',\n",
    "        'P(≥1)', 'P(≥3)', 'P(≥4)', 'P(≥5)', 'P(≥15)',\n",
    "        'Historical Rate', 'Total Historical'\n",
    "    ]].sort_values('Expected', ascending=False)\n",
    "\n",
    "print(\"Predictions based on all appearances:\")\n",
    "display(format_prediction_table(predictions_all, 'all'))\n",
    "\n",
    "print(\"\\nPredictions based on all speeches:\")\n",
    "display(format_prediction_table(predictions_speeches, 'post-inauguration-speeches'))\n",
    "\n",
    "print(\"\\nPredictions based on all post-inauguration appearances:\")\n",
    "display(format_prediction_table(predictions_post_all, 'post-inauguration-all'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Negative Binomial \n",
    "\n",
    "A more general model that accounts for overdispersion. The dispersion parameter r is estimated using the method of moments, and it controls how much extra variance there is compared to a Poisson distribution. As r approaches infinity, the negative binomial converges to a Poisson distribution (in practice we use r=100 to approximate this). Values closer to 0 indicate that the data is overdispersed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def calculate_negative_binomial_predictions(df, avg_length):\n",
    "    \"\"\"Calculate predictions using Negative Binomial distribution\"\"\"\n",
    "    predictions = []\n",
    "    \n",
    "    for phrase in SEARCH_PHRASES.keys():\n",
    "        # Calculate rate per word and variance\n",
    "        total_occurrences = df[phrase].sum()\n",
    "        total_words = df['text_length'].sum()\n",
    "        rate_per_word = total_occurrences / total_words\n",
    "        \n",
    "        # Expected occurrences in speech of avg_length\n",
    "        expected = rate_per_word * avg_length\n",
    "        \n",
    "        # Calculate sample variance to estimate overdispersion\n",
    "        counts_per_speech = df[phrase] / df['text_length'] * avg_length\n",
    "        sample_variance = counts_per_speech.var()\n",
    "        \n",
    "        if sample_variance > expected and expected > 0:  # Check for overdispersion\n",
    "            # Calculate r parameter for negative binomial using method of moments\n",
    "            r = max(0.1, expected**2 / (sample_variance - expected))\n",
    "            p = r/(r + expected)\n",
    "        else:\n",
    "            # If no overdispersion, fallback to quasi-Poisson\n",
    "            r = 100\n",
    "            p = r/(r + expected)\n",
    "        \n",
    "        # Calculate likelihoods using Negative Binomial CDF\n",
    "        def nb_ge_k(r, p, k):\n",
    "            return 1 - stats.nbinom.cdf(k-1, r, p)\n",
    "        \n",
    "        predictions.append({\n",
    "            'Phrase': phrase,\n",
    "            'Expected': expected,\n",
    "            'Dispersion (r)': r,\n",
    "            'Sample Variance': sample_variance,\n",
    "            'P(≥1)': nb_ge_k(r, p, 1),\n",
    "            'P(≥3)': nb_ge_k(r, p, 3),\n",
    "            'P(≥4)': nb_ge_k(r, p, 4),\n",
    "            'P(≥5)': nb_ge_k(r, p, 5),\n",
    "            'P(≥15)': nb_ge_k(r, p, 15)\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(predictions)\n",
    "\n",
    "\n",
    "def format_prediction_table(df):\n",
    "    \"\"\"Format prediction table with percentages\"\"\"\n",
    "    formatted = df.copy()\n",
    "    formatted = formatted.round(3)\n",
    "    \n",
    "    # Format probability columns as percentages\n",
    "    prob_columns = ['P(≥1)', 'P(≥3)', 'P(≥4)', 'P(≥5)', 'P(≥15)']\n",
    "    for col in prob_columns:\n",
    "        formatted[col] = formatted[col].map('{:.1%}'.format)\n",
    "    \n",
    "    # Round other numeric columns\n",
    "    formatted['Expected'] = formatted['Expected'].round(2)\n",
    "    if 'Dispersion (r)' in formatted.columns:\n",
    "        formatted['Dispersion (r)'] = formatted['Dispersion (r)'].round(2)\n",
    "        formatted['Sample Variance'] = formatted['Sample Variance'].round(2)\n",
    "    \n",
    "    return formatted.sort_values('Expected', ascending=False)\n",
    "\n",
    "def compare_models(poisson_df, nb_df):\n",
    "    \"\"\"Compare Poisson and Negative Binomial predictions\"\"\"\n",
    "    comparison = pd.DataFrame()\n",
    "    comparison['Phrase'] = poisson_df['Phrase']\n",
    "    comparison['Expected'] = poisson_df['Expected']\n",
    "    \n",
    "    # Convert percentage strings back to floats for calculations\n",
    "    for k in [1, 5]:\n",
    "        # Get raw probability values directly\n",
    "        comparison[f'Poisson P(≥{k})'] = poisson_df[f'P(≥{k})'].astype(float)\n",
    "        comparison[f'NB P(≥{k})'] = nb_df[f'P(≥{k})'].astype(float)\n",
    "        comparison[f'Δ P(≥{k})'] = (comparison[f'NB P(≥{k})'] - comparison[f'Poisson P(≥{k})']) * 100\n",
    "    \n",
    "    comparison['Dispersion (r)'] = nb_df['Dispersion (r)']\n",
    "    comparison['Sample Variance'] = nb_df['Sample Variance']\n",
    "    \n",
    "    # Format probability columns as percentages\n",
    "    for col in comparison.columns:\n",
    "        if 'P(≥' in col and 'Δ' not in col:\n",
    "            comparison[col] = comparison[col].map('{:.1%}'.format)\n",
    "    \n",
    "    return comparison.round(3).sort_values('Δ P(≥1)', ascending=True)\n",
    "\n",
    "def plot_distribution_comparison(phrase, poisson_df, nb_df, max_k=10):\n",
    "    \"\"\"Plot comparison of Poisson and Negative Binomial distributions\"\"\"\n",
    "    phrase_data = poisson_df[poisson_df['Phrase'] == phrase].iloc[0]\n",
    "    nb_data = nb_df[nb_df['Phrase'] == phrase].iloc[0]\n",
    "    \n",
    "    lambda_ = phrase_data['Expected']\n",
    "    r = nb_data['Dispersion (r)']\n",
    "    p = r/(r + lambda_)\n",
    "    \n",
    "    k = np.arange(0, max_k+1)\n",
    "    poisson_pmf = stats.poisson.pmf(k, lambda_)\n",
    "    nb_pmf = stats.nbinom.pmf(k, r, p)\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.bar(k-0.2, poisson_pmf, width=0.4, alpha=0.5, label='Poisson', color='blue')\n",
    "    plt.bar(k+0.2, nb_pmf, width=0.4, alpha=0.5, label='Negative Binomial', color='red')\n",
    "    plt.title(f'Distribution Comparison for \"{phrase}\"')\n",
    "    plt.xlabel('Number of Occurrences')\n",
    "    plt.ylabel('Probability')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.show()\n",
    "\n",
    "# Calculate predictions using both models\n",
    "avg_speech_length = df_sotu['text_length'].mean()\n",
    "\n",
    "print(\"Negative Binomial Predictions based on all appearances:\")\n",
    "nb_predictions = calculate_negative_binomial_predictions(df, avg_speech_length)\n",
    "display(format_prediction_table(nb_predictions))\n",
    "\n",
    "print(\"Negative Binomial Predictions based on all speeches:\")\n",
    "nb_predictions = calculate_negative_binomial_predictions(df_speech, avg_speech_length)\n",
    "display(format_prediction_table(nb_predictions))\n",
    "\n",
    "\n",
    "print(\"Negative Binomial Predictions based on all appearances post inauguration:\")\n",
    "nb_predictions_all = calculate_negative_binomial_predictions(df_post, avg_speech_length)\n",
    "display(format_prediction_table(nb_predictions_all))\n",
    "\n",
    "poisson_predictions = calculate_poisson_predictions(df_speech_post, avg_speech_length)\n",
    "\n",
    "print(\"\\nModel Comparison (Negative Binomial vs Poisson):\")\n",
    "display(compare_models(poisson_predictions, nb_predictions))\n",
    "\n",
    "# Plot distributions for most overdispersed phrases\n",
    "most_overdispersed = nb_predictions[nb_predictions['Phrase'].isin(['Border', 'America', 'God', 'January 6', 'MAGA', 'LA', 'Rigged', 'Hell'])]\n",
    "for _, row in most_overdispersed.iterrows():\n",
    "    # Get parameters for both distributions\n",
    "    phrase_data = poisson_predictions[poisson_predictions['Phrase'] == row['Phrase']].iloc[0]\n",
    "    lambda_ = phrase_data['Expected']\n",
    "    r = row['Dispersion (r)']\n",
    "    p = r/(r + lambda_)\n",
    "    \n",
    "    # Find where probability becomes negligible (< 0.1%)\n",
    "    k = 0\n",
    "    while stats.nbinom.pmf(k, r, p) > 0.001 or stats.poisson.pmf(k, lambda_) > 0.001:\n",
    "        k += 1\n",
    "    \n",
    "    # Ensure minimum k of 30 for 'America' to show full distribution\n",
    "    if row['Phrase'] == 'America':\n",
    "        k = max(k, 60)\n",
    "    \n",
    "    print(f\"\\nDistribution comparison for {row['Phrase']} (r = {row['Dispersion (r)']:.2f}):\")\n",
    "    plot_distribution_comparison(row['Phrase'], poisson_predictions, nb_predictions, max_k=k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recent Usage in context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recent_contexts(df, phrase, n=5):\n",
    "    \"\"\"Get the n most recent contexts for a phrase\"\"\"\n",
    "    # Create a list to store matches with their dates\n",
    "    all_matches = []\n",
    "    \n",
    "    # Look through speeches from newest to oldest\n",
    "    for _, row in df.sort_values('date', ascending=False).iterrows():\n",
    "        matches = find_phrase_context(row['text'], SEARCH_PHRASES[phrase])\n",
    "        for match in matches:\n",
    "            all_matches.append({\n",
    "                'date': row['date'],\n",
    "                'category': row['category'],\n",
    "                'context': match\n",
    "            })\n",
    "        if len(all_matches) >= n:\n",
    "            break\n",
    "    \n",
    "    return pd.DataFrame(all_matches[:n])\n",
    "\n",
    "# Get recent contexts for each phrase\n",
    "for phrase in SEARCH_PHRASES.keys():\n",
    "    contexts = get_recent_contexts(df, phrase)\n",
    "    if not contexts.empty:\n",
    "        print(f\"\\n=== Recent usage of '{phrase}' ===\\n\")\n",
    "        for _, row in contexts.iterrows():\n",
    "            print(f\"Date: {row['date'].strftime('%Y-%m-%d')} ({row['category']})\")\n",
    "            print(f\"Context: {row['context']}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_recent_contexts(df, 'Trans', 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Per-Speech Frequencies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sotu_mean_length = df_sotu['text_length'].mean()\n",
    "\n",
    "# Plot distribution of speech lengths with SOTU average marked\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.hist(df_speech['text_length'], bins=30, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "plt.axvline(x=sotu_mean_length, color='red', linestyle='--', label=f'Avg SOTU Length ({int(sotu_mean_length):,} words)')\n",
    "plt.xlabel('Speech Length (words)')\n",
    "plt.ylabel('Number of Speeches')\n",
    "plt.title('Distribution of Trump Speech Lengths')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find and display the 5 shortest speeches with their full text\n",
    "shortest_speeches = df_speech.nsmallest(5, 'text_length')\n",
    "\n",
    "print(\"5 Shortest Speeches:\")\n",
    "for _, speech in shortest_speeches.iterrows():\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"File: {speech['file']}\")\n",
    "    print(f\"Date: {speech['date'].strftime('%Y-%m-%d')}\")\n",
    "    print(f\"Category: {speech['category']}\")\n",
    "    print(f\"Length: {speech['text_length']:,} words\")\n",
    "    print(\"-\" * 40)\n",
    "    print(speech['text'])\n",
    "    print()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sotu_mean_length = df_sotu['text_length'].mean()\n",
    "\n",
    "# Plot distribution of speech lengths with SOTU average marked\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.hist(df_speech['text_length'], bins=30, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "plt.axvline(x=sotu_mean_length, color='red', linestyle='--', label=f'Avg SOTU Length ({int(sotu_mean_length):,} words)')\n",
    "plt.xlabel('Speech Length (words)')\n",
    "plt.ylabel('Number of Speeches')\n",
    "plt.title('Distribution of Trump Speech Lengths')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate percentage of appearances containing each phrase at least once\n",
    "phrase_percentages = {}\n",
    "for phrase in SEARCH_PHRASES.keys():\n",
    "    all_pct = (df[phrase] >= 1).mean() * 100\n",
    "    speech_pct = (df_speech[phrase] >= 1).mean() * 100\n",
    "    post_pct = (df_post[phrase] >= 1).mean() * 100\n",
    "    phrase_percentages[phrase] = {\n",
    "        'All Appearances': all_pct,\n",
    "        'Speeches Only': speech_pct, \n",
    "        'Post-Inauguration': post_pct\n",
    "    }\n",
    "\n",
    "# Create DataFrame and sort by percentage in all appearances\n",
    "phrase_df = pd.DataFrame.from_dict(phrase_percentages, orient='index')\n",
    "phrase_df = phrase_df.sort_values('All Appearances', ascending=False)\n",
    "phrase_df.index.name = 'Phrase'\n",
    "\n",
    "# Format table for display\n",
    "styled_df = phrase_df.style.format({\n",
    "    'All Appearances': '{:.1f}%'.format,\n",
    "    'Speeches Only': '{:.1f}%'.format,\n",
    "    'Post-Inauguration': '{:.1f}%'.format\n",
    "})\n",
    "\n",
    "print(\"Percentage of Appearances Containing Each Phrase:\")\n",
    "display(styled_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_frequency_comparison(df, df_speech, df_post):\n",
    "    \"\"\"Create a comparison table of per-speech frequencies across datasets\"\"\"\n",
    "    results = []\n",
    "    \n",
    "    for phrase in SEARCH_PHRASES.keys():\n",
    "        result = {\n",
    "            'Phrase': phrase,\n",
    "            'All Data P(≥1)': (df[phrase] >= 1).mean(),\n",
    "            'All Speeches P(≥1)': (df_speech[phrase] >= 1).mean(),\n",
    "            'Post-Inauguration P(≥1)': (df_post[phrase] >= 1).mean(),\n",
    "            'All Data n': len(df),\n",
    "            'All Speeches n': len(df_speech),\n",
    "            'Post-Inauguration n': len(df_post)\n",
    "        }\n",
    "        results.append(result)\n",
    "    \n",
    "    comparison_df = pd.DataFrame(results)\n",
    "    \n",
    "    # Format percentages\n",
    "    for col in ['All Data P(≥1)', 'All Speeches P(≥1)', 'Post-Inauguration P(≥1)']:\n",
    "        comparison_df[col] = comparison_df[col].map('{:.1%}'.format)\n",
    "    \n",
    "    # Sort by All Data frequency\n",
    "    comparison_df = comparison_df.sort_values('All Data P(≥1)', ascending=False)\n",
    "    \n",
    "    return comparison_df\n",
    "\n",
    "print(\"Comparison of Per-Speech Frequencies (P(≥1)):\")\n",
    "comparison_table = create_frequency_comparison(df, df_speech, df_post)\n",
    "display(comparison_table)\n",
    "\n",
    "# ... existing code ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Individual Phrase Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find speeches shorter than 6000 words with 4+ mentions of MAGA\n",
    "short_maga_speeches = df[\n",
    "    (df['text_length'] < 10200) & \n",
    "    (df['MAGA'] >= 4)\n",
    "][['file', 'MAGA']]\n",
    "\n",
    "print(f\"\\nSpeeches under 10200 words with 4+ mentions of MAGA:\")\n",
    "print(short_maga_speeches.sort_values('MAGA', ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['January 6'] > 0][['file', 'text_length', 'January 6', 'category']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['LA'] > 0][['file', 'text_length', 'LA', 'category']].sort_values('file')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert date strings to datetime \n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "# Create weekly bins\n",
    "df['week'] = df['date'].dt.to_period('W')\n",
    "\n",
    "# Group by week and calculate metrics\n",
    "weekly_stats = df.groupby('week').agg({\n",
    "    'file': 'count',  # Total speeches per week\n",
    "    'LA': lambda x: (x > 0).sum()  # Speeches containing LA per week\n",
    "}).reset_index()\n",
    "\n",
    "# Create figure\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "# Plot bars for speech counts\n",
    "ax.bar(range(len(weekly_stats)), weekly_stats['file'], alpha=0.3, color='gray', label='Total Appearances')\n",
    "ax.bar(range(len(weekly_stats)), weekly_stats['LA'], alpha=0.6, color='blue', label='Appearances with LA')\n",
    "\n",
    "# Customize axes\n",
    "ax.set_xlabel('Week')\n",
    "ax.set_ylabel('Number of Appearances')\n",
    "\n",
    "# Set x-axis ticks to show dates every 2 weeks\n",
    "tick_indices = range(0, len(weekly_stats), 2)\n",
    "plt.xticks(tick_indices, [str(weekly_stats['week'].iloc[i]) for i in tick_indices], rotation=45)\n",
    "\n",
    "# Add legend\n",
    "ax.legend(loc='upper left')\n",
    "\n",
    "plt.title('Weekly Frequency of LA Mentions in Appearances')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
