Mr. Graham: (00:00) ... I want to talk about here is health risk associated with social media. A 2018 Pew Research Center survey of nearly 750, 13 to 17 year olds found that 45% are online almost constantly and 97% use social media platforms such as YouTube, Facebook, Instagram, or Snapchat. So why are we having this hearing? The products that these two companies offer, people like and they use. So the bottom line is they've probably been more successful than their wildest dreams, and they're having to make decisions that offend people on the left and the right. And what we're trying to do is look at Section 230 and to see if it needs to be modified or changed because Section 230 basically allows social media platforms like Twitter and Facebook to pass on information without legal liability. If a newspaper does something you don't like, you think they've slandered you in a certain way, you can sue them. Mr. Graham: (01:15) If a news program does something that you think is out of line, even as a politician with a high bar, you can sue them. These companies have a liability protection when it comes to the content that their users engage in. You can sue the person who gave the tweet, but you can't sue Twitter who gave that person access to the world in terms of what they said. And we got to find a way to make sure that when Twitter and Facebook make a decision about what's reliable and what's not, what to keep up, what to take down, that there's transparency in the system. And I think Section 230 has to be changed because we can't get there from here without change. But in 2019, a study of more than 6500, 12 to 15 year olds in the US found that those who spent more than three hours a day using social media might be at heightened risk for mental health problems. Mr. Graham: (02:21) Another study 12,000, 13 to 16 year olds in England found that using social media more than three times a day, predicted poor mental health and wellbeing in teens. Other studies also have observed links between high levels of social media use, depression or anxiety. The average millennial checks their phone 157 times daily. I don't know how a member of the Senate, I don't know where we fall. Social media is designed to sustain user's attention with a mix of good user interface, design, and psychology, creating an addictive mix for users. It's called the slot machine effect. A technique which utilizes a pull to refresh and scrolling mechanisms on newsfeed similar a slot machine. The like button, a feature to provide social validation through a positive feedback loop my measuring and comparing the number of likes a users' content obtains. Gamifying social interactions, employing gamification to engage users and keep them coming back. Mr. Graham: (03:35) For example, streaks is the one causing the most concern and using elongating red lines to display the number of days since two users interacted. Guess what these technologies do is try to keep us engaged. The more we engage the technology, the more advertising benefit to the company. Is that a good business practice? Maybe so. Does it create a health hazard over time? It's something to look at. Now, the other aspect of this debate is are these companies newspapers or they're TV stations? Do they have the power of media organizations that have rules and regulations and the current media platforms do not? There are rules about what a television station can do. There are rules about what a newspaper can do. And what I want to try to find out is if you're not a newspaper at Twitter or Facebook, then why do you have editorial control over the New York Post? Mr. Graham: (04:52) They decided, and maybe for a good reason I don't know, that the New York Post articles about Hunter Biden needed to be flagged, excluded from distribution or made hard to find. That to me, seems like you're the ultimate editor. The editorial decision at the New York Post to run the story was overwritten by Twitter and Facebook in different fashions to prevent its dissemination. Now, if that's not making an editorial decision, I don't know what would be. It's one thing when we do it in our private lives. Nikki Haley made a post about her concerns about mail-in balloting. It was flagged as something, a claim this hasn't been legitimatized. Mr. Graham: (05:53) Let me read it to you. "The next question to ask is why is it a crime to raise doubts about the Holocaust? Why should anyone who writes about such doubts be imprisoned while insulting the prophet is allowed?" Now, that's the Ayatollah. He's opining that raising doubts about the Holocaust shouldn't be a crime and he is openly called for the destruction of Israel. His regime has. and his tweet was basically allowed to flourish. Here's what Nikki Haley said. "Despite what the media tells us, election fraud does happen and policies like ballot harvesting, and mailing ballots to people who don't request them makes that easier. That needs to stop." This claim about election fraud is disputed. Well, that's her opinion. Mr. Graham: (06:57) She believes, like I do, that mail-in balloting is ripe for fraud if you can't verify the signature. And if we just send mail ballots out to the world that are not requested, and you don't have a signature verification system that can be trusted, you have in fact led to harvesting of ballots for nefarious purposes. The question for us as a country, at what point did the decisions by these organizations cross a line? At what point do they have to assume responsibility that Section 230 shields them from? And to the people who are about to testify, I consider your products to have changed the world, mostly for the good. We're able to interact among ourselves. We're able to talk to each other and share life experiences. We're able to real-time communicate to our neighbors and our friends and those who oppose us. What we think with technology that just makes it instantaneous and can literally light up the world. Mr. Graham: (08:13) Section 230 was developed to allow these technologies to flourish. Early on, if you could sue Twitter or Facebook for content on a Facebook posting or a tweet, and they were liable for what somebody else said or what they felt or did, then the company would have probably never been in existence. The companies are trying to help us deal with child pornography. We have the EARN IT Act. That to be able to maintain liability protections when it comes to sexual exploitation of social media sites about sexual predators, this committee has passed a bill saying you can only maintain that liability protection if in fact you use best business practices. And that's where I think we need to be going. My hope is that we change Section 230 to incentivize social media platforms to come up with standards that are transparent and opaque that will allow us to make judgements about their judgments. That the fact checkers be known. That the community standards, who sets them, what are their biases and give some direction to these companies because they have almost an impossible task. Mr. Graham: (09:38) They're literally trying to engage in telling us what's reliable and what's not based on cable news commentary or tweets from politicians or average citizens. Nobody in a free society has ever had that responsibility before. And the question is, how do you control that responsibility? I don't want the government to take over the job of telling America what tweets are legitimate and what are not. I don't want the government deciding what content to take up and put down. I think we're all in that category. But when you have companies that have the power of governments, have far more power than traditional media outlets, something has to give. And I'm hoping in this hearing today that we can find a baseline of agreement. Mr. Graham: (10:41) That Section 230 needs to be changed. That my bias would be to allow the industry itself, to develop best business practices to protect the sites against terrorism and child exportation and other concerns. That we look at the business practices of these companies through a health prism. That some of their practices need to be modified because it can become addictive. We thought tobacco was a good thing for a long time to the point that we sent it to our soldiers in combat. The more we realized about the addictive nature of tobacco, the more we changed our mind about telling the public about the product. Mr. Graham: (11:22) So whether or not we do that with social media platforms, that these platforms can be addictive if used too often. I don't know if we need to go there, but I do know that Section 230 exists today is got to give. And I think there's Republican and Democrat concern about the power that's being used by social media outlets to tell us what we can see and what we can. What's true and what's not to the extent that Section 230 in my view has to be rewritten. So that's the purpose of this hearing is to find a way forward to bring about change. And when it comes to social media platforms and Section 230, change is going to come. With that, Senator Blumenthal. Senator Blumenthal: (12:10) Thank you very, very much Mr. Chairman. And thank you for having this hearing today. And I look forward to cooperating with you not only in this hearing, but in the up coming Congress on our own EARN IT bill, on other measures, because you're absolutely right. Change must come to social media. The fact is we meet today in an unprecedented and precarious moment in American history. Daily, the president shocks our conscience and shakes the very foundations of our democracy using a powerful megaphone, social media. The president has used this microphone to spread vicious falsehoods and an apparent attempt to overturn the will of voters. Every day, he posts new threats and conspiracy theories about mail-in ballots and voting machines, lies that contradict his own election security officials and his lawyers. He uses this megaphone potentially to block a peaceful transition of power. Now, Mr. Zuckerberg and Mr. Dorsey, you have built terrifying tools of persuasion and manipulation with power far exceeding the robber barons of the last Guilded Age. Senator Blumenthal: (13:35) You have profited hugely by strip mining data about our private lives and promoting hate speech and voter suppression. You have an immense civic and moral responsibility to ensure these instruments of influence do not irreparably harm our country. I recognize the steps. They're really baby steps that you've taken so far. The destructive incendiary misinformation is still a scourge on both your platforms and on others. In fact, Google has been given a pass from today's hearing. It's been rewarded by this committee for its timidity, doing even less than you have done to live up to its responsibilities. The recent actions you have taken in fact are simply to check the truth of what appears on platform. Often it is voter suppression and incendiary malicious misinformation. And you've tried to slow its insidious spread. That's not censorship, that's moral and civic responsibility. Senator Blumenthal: (14:48) Now, I believe and I hope the chairman agrees that a series of hearings on big tech is long overdue on antitrust issues, on privacy concerns and Section 230. I have urged, in fact, a breakup of tech giants because they've misused their bigness and power. Breaking off, for example, WhatsApp and Instagram. Rigorous privacy protection, because consumers should have control over their own data. And indeed Section 230 reform, meaningful reform, including even possible repeal in large part because their immunity is way too broad and victims of their harms deserve a day in court. But this hearing is certainly not the serious proceeding that we need. It may become a political sideshow, a public tar and feathering. My colleagues seem to want to ignore the foreign disinformation campaigns intended to interfere in our democracy and calls for murder of FBI director Ray and Dr. Fauci. What we've seen here are fighting words and hate speech that certainly deserve no free expression protection. Senator Blumenthal: (16:24) The fact is that the purpose of today's hearing seems as much to bully or brow beat you Mr. Zuckerberg and Mr. Dorsey from taking the more responsible action by threatening cuts to Section 230. Censorship is really a misnomer for this hearing. What you've done is to label and to fact check to avoid amplifying misinformation and to in effect impose those labels to alert people that what they are consuming may misinform them. And Facebook took down ads for Biden in Michigan and the ACLU in Colorado for mistaken information about voting. In short, there was action that affected both sides. I have fought for Section 230 reform for 16 years. From my time as Connecticut's attorney general, when I took on the scourge of registered sex offenders grooming children on Facebook and MySpace. With Senator Portman, I have led passage of the only successful revision so far to Section 230 to Stop Enabling Sex Traffickers Act known as SESTA. Senator Blumenthal: (17:52) And chairman Graham and I have authored the only bill to reform Section 230 that has actually moved out of the committee. The EARN IT Act passed this committee unanimously. Change is going to come, no question. Change is on the way and I intend to bring aggressive and targeted reform to Section 230. But I am not, nor should we be on this committee interested in being a member of the speech police. There are real harms and real victims here. And in some ways, this hearing is a betrayal of those real harms and the real victims of them. Those harms have been caused by big tech because you have failed your responsibility as have others in this industry. I want to see real reform that will enable these abuses to be reformed because your platforms have embraced abuse and weaponized child predators, violent white supremacists and human traffickers. Senator Blumenthal: (19:07) And I've heard heart wrenching stories from victims. You've set back civil rights protections for Muslim Americans who live in fear of armed militias organized by private online groups. You have setback consumers and competition making that kind of antitrust action very, very important. The American public deserves and demands real reform and accountability, national consumer privacy rules, antitrust principles that curb predatory power and reforms the Section 230 that stops shutting the courthouse door to victims. I look forward to an opportunity for real change, and I think you can meet this moment by put in your power and your money on the right side of history. Thanks Mr. Chairman. Mr. Graham: (20:10) Well, thank you. A lot to unpack there. Senator Blumenthal, it's been great to work with. I'll continue to work with you. If we keep control of the committee, Senator Grassley would be the chairman next year. And I would encourage him to have the hearings that Senator Blumenthal referenced. That this is a ongoing conversation to get it right to the extent that we can get it right. Mr. Dorsey from Twitter, are you with us, Mr. Dorsey? Mr. Dorsey: (20:37) I am. Can you hear me? Mr. Graham: (20:40) Thank you. The floor is yours. Mr. Dorsey: (20:43) Thank you to the members of the judiciary committee for the opportunity to speak with the American people about Twitter and your concerns around censorship and suppression of a specific news article and generally what we saw in the 2020 US elections conversation. We were called here today because of an enforcement decision we made against the New York Post based on a policy we created in 2018 to prevent Twitter from being used to spread hacked materials. This resulted in us blocking people from sharing a New York Post article publicly or privately. We made a quick interpretation using no other evidence that the materials in the article were obtained through hacking. And according to our policy, we blocked them from being spread. Upon further consideration, we admitted this action was wrong and corrected it within 24 hours. We informed the New York Post of our error and policy update and how to unlock their account by deleting the original violating tweet which freed them to tweet the exact same content and news article again. Mr. Dorsey: (21:47) They chose not to, instead insisting we reverse our enforcement action. We did not have a practice around retroactively overturning prior enforcements. This incident demonstrated that we needed one. And so we created one we believe is fair and appropriate. I hope this illustrates the rationale behind our actions and demonstrates our ability to take feedback, admit mistakes, and make changes all transparently to the public. We acknowledge there are still concerns around how do we moderate content and specifically our use of Section 230. Three weeks ago we proposed three solutions to address the concerns raised and they all focus on services that decide to moderate or remove content. It could be expansions to Section 230, new legislative frameworks or a commitment to industry-wide self-regulation best practices requiring; one, moderation process and practices to be published. Two, a straight forward process to appeal decisions and three, best efforts around algorithmic choice or suggestions to address the concerns we all have going forward. Mr. Dorsey: (22:57) And they're all achievable in short order. It's critical as we consider these solutions, we optimize for new startups and independent developers. Doing so ensures a level playing field that increases the probability of competing ideas to help solve problems going forward. We mustn't entrench the largest companies any further. Finally, before I close, I wanted to share some reflections on what we saw during the US presidential election. We focused on addressing attempts to undermine civic integrity, providing informative context and product changes to encourage greater conversation. Mr. Dorsey: (23:35) We updated our civic integrity policy to address misleading or disputed information that undermines confidence in the election, causes voter intimidation or suppression or confusion about how to vote or misrepresents affiliation or election outcomes. More than a year ago, the public asked us to offer additional context to help make potentially misleading information more apparent. We did exactly that, applying labels to over 300,000 tweets from October 27th to November 11th, which represented about 2.2% of all US election related tweets. We also changed how our product works in order to help increase context and encourage more thoughtful consideration before tweets are shared broadly. We're continuing to assess the impact of these product changes to inform our longterm roadmap. Thank you for the time and look forward to a productive discussion focused on solutions. Mr. Graham: (24:34) Thank you, Mr. Dorsey. Mr. Zuckerberg. Mr. Zuckerberg: (24:38) Thank you Chairman Graham, ranking member Blumenthal and members of the committee. At last year's hearing, or last months hearing and I spoke about the role internet platforms play in supporting democracy, keeping people safe and upholding fundamental values like free expression. People have deeply held beliefs about these issues and can reach very different conclusions about the right balance. We try to do what's best for our community and the world, acknowledging that there are difficult trade-offs. I believe that some of these trade-offs and decisions would be better made through a democratic process and I look forward to discussing that today. But first I want to update you on our efforts during the election. At Facebook, we took our responsibility to protect the integrity of this selection very seriously. In 2016, we began to face new kinds of threats and after years of preparation, we were ready to defend against them. Mr. Zuckerberg: (25:31) We built sophisticated systems to protect against election interference that combine artificial intelligence, significant human review and partnerships with the intelligence community, law enforcement and other tech platforms. We've taken down more than 100 networks of bad actors who were trying to coordinate and interfere globally. We established a network of independent fact checkers that covers more than 60 languages. We made political advertising more transparent on Facebook than anywhere else including TV, radio, and email. And we introduced new policies to combat voter suppression and misinformation. Still, the pandemic created new challenges, how to handle misinformation about COVID and voting by mail, how to prepare people for the reality that results would take time and how to handle if someone prematurely declared victory or refused to accept the results. So in September, we updated our policies again, to reflect these realities of voting in 2020, and make sure that we were taking precautions given these unique circumstances. Mr. Zuckerberg: (26:33) We worked with the local election officials to remove false claims about polling conditions that might lead to voter suppression. We partnered with Reuters and the National Election Pool to provide reliable information about results. We attached voting information to posts by candidates on both sides and additional contexts to posts trying to de-legitimized the outcome. We locked down new political ads in the week before the election to prevent misleading claims from spreading when they couldn't be rebutted. We strengthened our enforcement against malicious and conspiracy networks like QAnon to prevent them from using our platforms to organize violence or civil unrest. Altogether, I believe this was the largest election integrity effort by any private company in recent times. This is what people expect of us. And I'm glad that from what we've seen so far, our systems performed well. But election interference remains an ongoing threat that will never fully be solved so we continue to improve with each election. Mr. Zuckerberg: (27:32) But our integrity work is really only half the story. We also ran an unprecedented civic engagement program to encourage people to take part in our democracy. We ran the largest voter information campaign in history. 140 million people visited our voting information center, including more than 33 million on election day alone. We estimate that we helped more than 4.5 million people register to vote and helped States recruit 100,000 poll workers. This was done in a transparent and nonpartisan way as part of our ongoing commitment to supporting the civic process. And on top of these efforts by Facebook, my wife Priscilla and I personally donated $400 million to support election officials around the country and making sure that they had the infrastructure they needed to enable everyone to vote safely during this pandemic. In my last testimony, I said that people would judge us by our performance during this election. Mr. Zuckerberg: (28:32) Now, I believe that the full story is not only how we handle bad behavior on our platforms, but also how we encourage civic engagement more broadly. I'm proud of the work we've done to support our democracy and I look forward to discussing this. I also welcome the opportunity to discuss internet regulation. I believe we are well overdue to update the rules for the internet around content, elections, privacy, and data portability. There are important questions here, including who should be responsible for what people say online. For any system to work, I believe there needs to be a transparent process that people feel they can trust. And this will be difficult, especially since our country is so divided, but I believe it's the only way to address these issues for the longterm. The challenges that we face are deeper than any one platform. They're about how we want to balance basic social equities that we all care about like free expression, public safety and privacy. This is why I believe we would benefit from clearer guidance from elected officials and I look forward to discussing this today. Mr. Graham: (29:37) Well, thank you both. We'll have one round and seven minutes. But I'll, as always, try to be a little bit liberal with the time, because this is a very important topic. So let's just get right into it. Mr. Dorsey, you can go first and Mr. Zuckerberg. When you heard Senator Blumenthal's opening statement and mine, what did you get from it? Mr. Dorsey: (30:04) Well, I think you pointed out that we are facing something that feels impossible. We are required to help increase the health of the public conversation while at the same time, ensuring that as many people as possible can participate. And in order to do so, we need to make policies so that people feel safe and they feel free to express themselves. To minimize threats of abuse, of harassment, of misleading information, of organized campaigns to artificially amplify or influence a particular conversation. And that policy creation, that enforcement is challenging, but also it is more or less opaque to the public. And that's where I think we have a gap. We have transparency around our policies. Mr. Dorsey: (31:01) We do not have transparency around how we operate content moderation, the rationale behind it, the reasoning. And as we look forward, we have more and more of our decisions, of our operations, moving to algorithms, which have a difficult time explaining why they make decisions, bringing transparency around those decisions. And that is why we believe that we should have more choice in how these algorithms are applied to our content, whether we use them at all so we can turn them on or off and have clarity around the outcomes that they are projecting and how they affect our experience. Mr. Graham: (31:46) Thank you. Mr. Zuckerberg, very quickly please. What did you hear? Mr. Zuckerberg: (31:52) Senator, I heard that there are issues around content moderation, as well as other areas. And frankly, I'm optimistic from the statements that we may be able to move forward and hopefully update some of the rules for the internet around these areas. I've been encouraging and hoping that we would do this for a couple of years. And from your opening statements, it sounds like there may be now enough common ground on views that real progress can be made here. Mr. Graham: (32:23) So from my point of view, the question for us is when it comes time to flag content as being reliable or not reliable, do either one of you believe that the government should do that? Is that a solution where the government sets a regulatory scheme that talks about what should be up and what should be down? Mr. Dorsey: (32:47) I don't believe so. I think that would be very challenging. Mr. Graham: (32:51) Okay. Do you agree with that Mr. Zuckerberg? Mr. Zuckerberg: (32:54) Senator, for certain types of illegal content, I think it may be appropriate for there to be clear rules around that. But I would side of clear harms, including things like child exploitation and areas like that. Terrorism, I would agree with your sentiment that, that's not something that government should be deciding on a piece of content by piece of content basis. Mr. Graham: (33:22) So if we take the government out of the picture, at least, and not in criminal areas, should we leave it up to the industry to come up with best business practices in terms of how to moderate content? Mr. Dorsey: (33:39) I think we need to align around the problem that we're trying to solve. And there are many solutions to solving those problems, but I think we also have to focus our efforts on what is going to have the greatest impact. And we believe that the greatest impact is going to be found in how we deal with algorithms, how we use those algorithms, because they are responsible for showing us what we see or what we don't see and there needs to be more choice in their use. Mr. Graham: (34:08) Do you agree with that, Mr. Zuckerberg? Mr. Zuckerberg: (34:15) Senator, I think that there is a role for regulation in the process, even if not defining on a piece of content by piece of content basis. And one of the areas that I've advocated for is regulation around transparency. That goes beyond just about what the policies are and what the process is, but also goes towards the results. As an example of this, every quarter, Facebook releases a Community Standards Enforcement Report. It's basically a transparency report that breaks down each category of potentially harmful content that we track, ranging from terrorism to child exploitation content to incitement of violence- Mr. Zuckerberg: (35:03) ... To child exploitation content, to incitement of violence, to pornography [crosstalk 00:35:05] violations. Mr. Graham: (35:07) Yes. If I may, I don't mean to interrupt, but who sets those community standards? How are they set by the company? Mr. Zuckerberg: (35:14) Senator, we have a policy team that consults with a number of different stakeholders and outside groups to make sure that we're getting feedback from broad swaths of [crosstalk 00:00:26]. Mr. Graham: (35:26) Is that publicly known? Mr. Zuckerberg: (35:30) Senator, I believe so. Our head of content policy has testified publicly multiple times. Mr. Graham: (35:38) Okay. So when it comes to fact checking, would you give us a list of the people you use to fact check? Mr. Zuckerberg: (35:46) Senator, yes. We work with a number of independent organizations that are accredited by the Poynter Institute and they include Reuters, The Associated Press, Agence-France Presse [inaudible 00:36:00] United States, USA Today, factcheck.org, Science Feedback, PolitiFact, Check Your Fact, lead stories and the dispatch in the United States. Mr. Graham: (36:11) Okay. I think it's important for the public to know who sets community standards, how they're set, who does the fact checking, who you rely upon to do that. I think that would go a long way to people having a better understanding of the decisions you make. Mr. Zuckerberg, do you believe your product can be addictive? Mr. Zuckerberg: (36:36) Senator, we certainly do not design the product in that way. We designed the product to be as useful and meaningful as possible. We take steps... Mr. Graham: (36:45) That's not my question. My question is that there seems to be an ample body of growing medical evidence that social media sites have an addictive nature to them. Do you agree with that? Mr. Zuckerberg: (36:58) Senator, I don't think the research has been conclusive, but it is an area that we care about and study. We certainly do not want our products to be addictive. We want people to use them because they're meaningful and we take steps to make sure that this is the case. So for example, we don't give the team that's running newsfeed a goal around how much time people spend on our products, which goes counter to a lot of the memes and misinformation out there around how we operate. But my goal is to help people connect and find content and interactions that are going to be meaningful to them on our service. Our view is that if that's what we deliver over the longterm and people find the services useful, then they'll use them more. But I don't think that companies should be optimizing to just encourage people to spend as much time as possible on them. Mr. Graham: (37:50) Well, time's about up. Have you seen the movie Social Dilemma? Mr. Zuckerberg: (37:56) Senator, I'm familiar with it. Mr. Graham: (37:57) Okay. Have you seen it, Mr. Dorsey? Mr. Dorsey: (38:05) No, I have not. Mr. Graham: (38:06) I would encourage both of you to see it. So here's what I think we're going to do on the committee over time. My hope is to ask the question more directly, are these social media sites addictive? Do they have a public health component that needs to be addressed? For years we thought tobacco was a great thing. We found out tobacco was not such a great thing. The medical science around these websites are becoming very concerning to me, particularly among children and that you can manipulate how many times you watch and you can set these media sites up so that people will constantly interact. So to both of you, I appreciate coming for the committee. We've got a long way to go. I don't think the government needs to regulate what we think or what we say, but we've got to up our game here. I'll end with this last question. Do both of you support change to 230, reform of Section 230? Mr. Zuckerberg: (39:10) Senator, I do. Mr. Graham: (39:12) Mr. Dorsey? Mr. Dorsey: (39:14) Yes. Mr. Graham: (39:14) Thank you. Senator Blumenthal. Senator Blumenthal: (39:19) Thanks Mr. Chairman. Let me bring this down to very practical terms. We're in the middle of another election. This election in Georgia could determine, in fact, which party controls the United States Senate. I'm concerned that both of your companies are in fact backsliding or retrenching, that you are failing to take action against dangerous disinformation, exactly the same kind of voter suppression tactics that existed in the last election and that you are, in fact, reducing content modification. Fighting words and hate speech in the last election could inflame violence and send poll workers into hiding, discourage people from coming to the polls. We have to expect the same kinds of malign tactics. In fact, they are already visible. I'm going to ask, Mr. Chairman, that these posts and tweets be entered into the record, if there's no objection, that are aimed at de-legitimizing the election in January. My question to you is will you commit to the same kind of robust content modification playbook in this coming election, including fact-checking, labeling, reducing the spread of misinformation, and other steps, even for politicians in the runoff elections ahead? Mr. Zuckerberg: (41:10) Senator, our policy is to have a similar approach in the upcoming Georgia special elections that we took during the general election. Senator Blumenthal: (41:21) Mr. Dorsey? Mr. Dorsey: (41:23) Yes, we do. We intend to learn from all of our experience with this election and bring all that learning going forward to make it more robust. Senator Blumenthal: (41:32) During the past election, there was rampant disinformation on social media in Spanish speaking sites, repeating Q Anon conspiracies and false claims of election rigging. In my view, you need to do better. Will you commit to taking steps to improve content modification for Spanish speaking communities before the Georgia runoff? Mr. Zuckerberg: (42:07) Senator, this is something that we are already working on and worked on ahead of the general election. We have multiple fact-checkers who focus on Spanish as a language. We made sure that we translated our voter information center into Spanish, which we showed at the top of Facebook and Instagram to everyone who uses those products in Spanish and in the US. Those are a couple of the steps that we've taken. We're certainly committed to focusing on this. Mr. Dorsey: (42:40) Yes, we will in partnership with [inaudible 00:42:44] civil rights groups. Senator Blumenthal: (42:46) I'd like to know, and perhaps you could submit to me within one week, what additional steps you're going to take because this Georgia runoff is underway. As I've indicated, I've seen a backsliding and retrenchment that is very deeply troubling that has enabled the spread of this disinformation, the restarting of certain algorithms, for example, that promote or amplify misinformation is very, very troubling. I think I want to know within a week, what additional steps we are taking to enhance the efforts to stop this kind of amplification and spread. Let me ask about Facebook community standards, which ban language that quote incites or facilitates serious violence. As you know, on November 5th, Steve Bannon, in a Facebook live video called for beheadings of Dr. Fauci and FBI Director Wray for not acting more favorably toward President Trump. Twitter banned Bannon for these remarks. You removed the video, Mr. Zuckerberg. But on Thursday, you reportedly told Facebook employees that Bannon had not violated enough policies that he should be banned from Facebook. My question to you is how many times is Steve Bannon allowed the call for the murder of government officials before Facebook suspends his account? Mr. Zuckerberg: (44:31) Senator, as you say, the content in question did violate our policies and we took it down. Having a content violation does not automatically mean your account gets taken down, and the number of strikes varies depending on the type of offense. So if people are posting terrorist content or child exploitation content, then the first time that they do it, then we will take down their account. For other things, it's multiple. I'd be happy to follow up afterwards. We try not to disclose these... Senator Blumenthal: (45:05) [crosstalk 00:45:05] his account. Mr. Zuckerberg: (45:06) Sorry, I didn't hear that. Senator Blumenthal: (45:08) Will you commit to taking down that account, Steve Bannon's account? Mr. Zuckerberg: (45:13) Senator, no. That's not what our policies would suggest that we should do in this case. Senator Blumenthal: (45:22) According to the internal records that are on record now, leaked by NBC news, Facebook has removed fact checks and forgiven infractions for conservative pages and pundits such as Breitbart, Donald Trump, Jr., Eric Trump and gateway pundit based on a fear of accusations of bias. Has Facebook avoided penalizing or fact-checking conservative pages that had violated its policies based on concerns of political bias and allegations of bias? Mr. Zuckerberg: (46:03) Senator, no. We haven't done that. I think that those reports mischaracterize the actions that we take. I'm not aware of any instance where we have overturned a fact check specifically, and certainly no action like that would be taken for the reasons that you're saying. What we do sometimes is apply some judgment on whether the repeat offender policies would render too harsh of a penalty, but that's different from overturning a specific fact check and is not done for the reasons that you said. Senator Blumenthal: (46:47) Well, I'm very concerned that, in fact, Facebook seems to have a record of making accommodations and caving to conservative pressure. The president has tried to use an executive order on Section 230 to, again, bully or brow beat, and exert pressure on you and others in this industry. They're in effect working the refs and they're winning. Let me ask you about antitrust issues. In 2013 Facebook bought Onavo, which is a virtual private records network that claim to protect users' privacy. In fact, Onavo's access to private information about its users provided Facebook with unparalleled ability to track potential competition. I want to know whether Facebook used data from Onavo when it decided to purchase WhatsApp in 2014. Mr. Zuckerberg: (47:58) Senator, I believe that data from Onavo was one of the sources that the team looked at, but I don't think it would have taken using Onavo to understand that WhatsApp was a great product. I don't think that was determinative in my decision to pursue that. Senator Blumenthal: (48:18) Well, in fact, the House Antitrust Report says, "Onavo data was used to determine whether WhatsApp was quote, killing Facebook messenger, end quote." My time has almost expired, but let me just say finally, that antitrust action by the federal trade commission is long overdue. I believe that decisive action is necessary, including very likely breaking up Facebook as a remedy. All options ought to be on the table, including divestment of Instagram and WhatsApp. The FTC ought to impose strict conditions on how Facebook uses consumer data and competes with rivals because the abuse of competition must end. Mr. Chairman, I ask that three letters from civil rights groups regarding disinformation, hate speech on Twitter, Facebook, and YouTube, and also a letter from Coalition of Children's Protection Advocates on the EARN IT Act and child sexual abuse material on digital platform be entered into the record. Thank you both for being here today. Mr. Graham: (49:35) Without objection. Senator Cornyn. Senator Cornyn: (49:39) Thank you, Mr. Chairman. Well, I'm glad to hear both of our witnesses today say that Section 230, that they are open to reform, because think it's fair to say the internet has outgrown Section 230 and while we've made some modifications when it comes to terrorism and when it comes to child exploitation, I think there's more to do, but I think the question is going to be how this regulation is going to come to pass. I know there's some, including on this committee, who suggested maybe we ought to create a private right of action so that individuals can sue over claims of violated rights on your platforms. I think that's one form of regulation. It's called regulation by litigation, but it's certainly not my first choice and it's not optimal. I don't think it's something we ought to be embracing in the first instance. But I do think it's critical that each of you and your counterparts work with us to try to come up with something that will address the concerns. The basic concern I have is it's hard to know exactly how to classify your business model. Senator Cornyn: (51:05) We have a provision in the Bill of Rights protecting freedom of the press, but yet, while we would never let the government regulate what the press writes or doesn't write, essentially we are allowing private companies, which are now de facto public forums, to regulate that speech. I'm no more comfortable delegating those decisions to you than I am delegating to you my vote in the last or upcoming elections. Louis Brandeis famously said that the solution for bad speech is not less speech, it's more speech. It seems to me like the practices that you are engaging in to tag, remove, and otherwise censor speech on your platforms violates that principle. I'd like to know why that shouldn't be a better approach by allowing more speech rather than censoring what is perceived as bad speech. Then as I think I've discussed with you, Mr. Zuckerberg, I think we're all sort of struggling to come up with what the appropriate analogy here is to your business model. We know, as newspapers have become less profitable and many of them gone out of business, there's been consolidation in the news media. Senator Cornyn: (52:33) There is a proliferation of cable TV shows and people being able to get information through a variety of sources, but there's no Walter Cronkite or the big TV networks with the trusted anchor person who people have confidence in that they will shoot with them straight. So I know it's a very difficult thing to manage, but I would just encourage both of you not to wait for the lawsuits. We saw what happened to Microsoft. I think Bill Gates said that was one of his biggest mistakes failing to engage with some of the antitrust concerns when it came to Microsoft. He learned that the hard way. I think there is a better way for the American people, and that's, if we work on this together. Mr. Zuckerberg, I believe that that Facebook publishes, on a quarterly basis, a report of its actions in this area. Is that correct? Mr. Zuckerberg: (53:39) Senator, that's correct. Senator Cornyn: (53:41) And could you describe that for us and what motivated you to undertake that sort of transparency? Mr. Zuckerberg: (53:48) Yes. Senator, I believe that in order for people to trust that we're doing a good job, they have to be able to see the results. We have to be able to break down content in a kind of category by category basis, across all of the different categories of harm, whether it's terrorist content or child exploitation or incitement of violence or pornography or intellectual property violations, how much of the violating content is on our platforms and how effective our systems are at removing it and what we hold ourselves accountable towards is getting as high a percent of this harmful content down and addressing it before real people have to experience it and report it to us themselves. So in categories where we do quite well, for example, in fighting against terrorist content, our AI systems and counter-terrorism teams are able to remove 98 or 99% of that harmful content before anyone has to report it to us. Mr. Zuckerberg: (54:53) In other categories, it's more challenging and we're still making more progress. But I think that as part of a regulatory framework here, it would be good if every company had to issue a transparency report outlining what they're seeing on their platforms and the results in effectiveness of their content moderation systems so that way the people who are responsible for holding all of us accountable, whether it's journalists, Congress, academics could have an apples to apples comparison about how all the different companies are doing and potentially is part of a law require that companies even maintain a certain level of effectiveness. Senator Cornyn: (55:37) Thank you. Mr. Dorsey, when Twitter decided to take down the story, the New York Post story on Hunter Biden's laptop, did you do that under your terms of service or did you do it under some other claim of authority? Mr. Dorsey: (55:55) We did an under our terms of service, which as you know, everyone agrees to when they sign up for Twitter. This was a policy around distribution of hacked materials. We did not want Twitter to be a distribution point for hacked materials. Senator Cornyn: (56:09) Well, you do realize that by taking down that story, you probably gave it more prominence and more visibility than it ever would have gotten had you left it alone. Mr. Dorsey: (56:21) We realize that and we recognize it as a mistake that we made both in terms of the intention of the policy and also the enforcement action of not allowing people to share it publicly or privately, which is why we corrected it within 24 hours. Senator Cornyn: (56:41) And Mr. Dorsey, why isn't Justice Brandeis' formulation in Whitney versus California. Why shouldn't that apply to the internet platforms like yours? In other words, the cure for bad speech is not censorship, it's more speech. Why wouldn't that principle apply to Twitter? Mr. Dorsey: (57:10) I think it does apply. All of our policies are focused on encouraging more speech. What we saw and what the market told us was that people would not put up with abuse, harassment, and misleading information that would cause offline harm, and they would leave our service because of it. So our intention is to create clear policy, clear enforcement that enables people to feel that they can express themselves on our service and ultimately trust it. Senator Cornyn: (57:39) So it was a business decision. Mr. Dorsey: (57:42) It was a business decision. Senator Cornyn: (57:43) Thank you. Mr. Graham: (57:46) Senator Feinstein. Senator Feinstein: (57:52) Thanks very much, Mr. Chairman. Mr. Dorsey, in recent hearings before the Senate Commerce Committee, you said, "I think that Twitter has a policy against misinformation relating to civic integrity." President Trump and his allies have tweeted hundreds of false claims about the 2020 election. Trump has falsely claimed victory and alleged widespread voter fraud. So here's the question. Does misinformation about the results of an election and voter fraud relate to civic integrity? Why or why not? Mr. Dorsey: (58:35) Yes, it does. We label those tweets when the election has not been called yet, or multiple sources have called it differently. Senator Feinstein: (58:46) I'm sorry. I didn't understand that. Did you say you have been able to tweet? Mr. Dorsey: (58:52) No. We have labeled the tweets that would indicate a different result in the election called by multiple sources. Senator Feinstein: (59:01) I see. At what point was that done? Mr. Dorsey: (59:05) Throughout the period, October 11th to up until today. Senator Feinstein: (59:10) So when the tweet initially came in, how long was it before you quote updated it? Mr. Dorsey: (59:20) We didn't update it. We put a label on it, pointing to the broader conversation. Our goal is to connect people with more information around what's happening with the election. That occurred anywhere from five minutes to 30 minutes, but as quickly as we can. Senator Feinstein: (59:42) Thank you, is 30 minutes the maximum time? Mr. Dorsey: (59:46) I don't know. We can get you that information [crosstalk 00:59:48]. Senator Feinstein: (59:48) Would you? I'm interested in this. Does misinformation about the results of an election and voter fraud relate to civic integrity? Why or why not? Mr. Dorsey: (01:00:04) Yes, it does. We also label those tweets that would indicate whether fraud was happening. Again, we connect those to larger conversations on platform. So we want to provide context here. That is our goal, providing more context, providing more information. Senator Feinstein: (01:00:23) Okay. Now a specific question, and I'm not sure actually what the answer to this should be, but on November 7, president Trump tweeted and I quote, "I won this election by a lot." Obviously, that's not true. President Trump lost the election. The warning label that Twitter is applied to the tweet says, and I quote, "Official sources may not have called the race when this was tweeted." Do you believe that label goes far enough to prevent the tweet's harms when the tweet is still visible and not accurate? Mr. Dorsey: (01:01:03) I do because it's not just the surface level label. It points to a collection of news articles of information and conversation that gives you an expansion on what's happening with the election. Senator Feinstein: (01:01:17) I guess you see my concerns are that these tweets arouse people. It seems to me that the entity that runs this operation ought to have an understanding that when there is a major situation, that the tweets can play a unique role in either reassuring or stirring people up to unacceptable levels. Could you comment on that? Mr. Dorsey: (01:01:51) Well, I agree in [inaudible 00:26:54]. I know our policy is focused on misleading information around the election and the civic process to provide greater context, to provide additive information so that people can make decisions around what's happening with the election. That is three phases. That's the run-up to the election, that's Election Day, and also the phase we're in right now. Post-election. So our policies and enforcement are focused on providing more information and more context to people in those three phases. Senator Feinstein: (01:02:27) Well, let me give you a specific. On November 7, President Trump tweeted this, "I won this election by a lot." That's obviously not true. President Trump lost the election. The warning label that Twitter has applied to the tweet says, and I quote, "Official sources may not have called the race when this was tweeted." Now, here's the question. Does that label do enough to prevent the tweet's harms when the tweet is still visible and is not accurate? Mr. Dorsey: (01:03:04) I believe it's really important that we show people a broader context, and that is the intention of the label. It is not just text below a tweet. It is a link to connect to a much larger conversation and news articles across the spectrum. Senator Feinstein: (01:03:22) Well, give me an example of what would have to happen before the situation would warrant a stronger response? Mr. Dorsey: (01:03:33) Well, we did have stronger responses during Election Day and the week after where we did put an interstitial, meaning that you had to click through to see the content of the tweet and it limited spread for anything that went against our civic integrity policy, including premature calls to election results. Senator Feinstein: (01:03:58) Well, let me give you one more. On November 12, President Trump tweeted a conspiracy theory that 2.7 million votes for him were deleted. The warning label that Twitter has applied to that tweet said, "This claim about election fraud is disputed." Now here's the question. I think it is a tough issue. Do you believe this label does enough to prevent the tweet's harms when the tweet is still visible? It's a highly emotional situation, but the tweet has no factual basis. Mr. Dorsey: (01:04:37) But the tweet has a link to more information, to more conversation and more context that informs the situation what's happening. So I do believe that connecting people to the larger conversation, giving them more context is the right path here. Senator Feinstein: (01:04:57) But they have to move to solicit that contact, right? It's not contained as an addendum to the original tweet. Mr. Dorsey: (01:05:06) The label is an addendum to the original tweet. If you tap on it or click it, you will go to an expansion of the information. Senator Feinstein: (01:05:14) I see. Can I ask a question to Mr. Zuckerberg? Is he... Mr. Graham: (01:05:22) Yes, you may. One more, if that would be okay. Senator Feinstein: (01:05:26) Mr. Zuckerberg, at the recent hearing before the Senate Commerce Committee, you said that Facebook has a "Policy in place that prevents any candidate," from "trying to delegitimize the result of the election." But the hashtags, stealthevote and voterfraud, garnered more than 300,000 interactions on your platform in the hours after Mr. Trump falsely declared victory. So here's the question. Do you believe Facebook did enough to prevent Trump's efforts to delegitimize the election result? If so, why have you reached that conclusion? Mr. Zuckerberg: (01:06:21) Senator, I believe that we've taken some very significant steps in this area, not just the adding additional context to specific posts and making it so that when people search for different hashtags, we show additional information, but we also took the unprecedented step of putting the voter information center at the top of Facebook and Instagram for everyone in the US that showed them reliable information about the election, including partnering with organizations like Reuters and the National Election Pool to show them accurate information about the results of the election. So all taken together, I think that we really went quite far in terms of helping to distribute reliable and accurate information about what was going on during this election. Senator Feinstein: (01:07:15) Okay. Let me give you one more along this line. After President Trump falsely claimed that the election was being stolen. A group called Stop The Steal was started on Facebook. It grew to more than 300,000 users in less than a day, making it one of the fastest growing groups, I understand, in Facebook history. You shut the group down, but substantial damage already had been done. Trump supporters, some of them armed with assault weapons, held Stop The Steal rallies outside election offices. In Philadelphia, two armed supporters who had traveled from Virginia were arrested on their way to the city's vote counting center. Here's the question, and this is a tough one. What are your concerns about the spread of misinformation? No matter how innocent it is, or it is not innocent, like Trump's claims about the election that they may incite violence. Mr. Zuckerberg: (01:08:23) Senator, I'm very worried about this, especially any misinformation or content that could incite violence. In during such a volatile period like this, one of our top priorities is making sure that people don't use our platform to organize any violence or civil unrest. That was the basis under which we took down that group, because there were a number of members who were posting potentially violent or encouraging violent comments that violated our policies. We also have broader policies in place around trying to slow the spread of misinformation more broadly, even when it's not going to lead to some kind of violence or imminent harm. That's why we've created this independent fact-checking program where we work with more than 80 partners around the world to help do fact checking because people in our community have told us they don't want to see misinformation, but they also don't want us to be deciding what is true and false. So we've taken the step of building this program, which I believe is more sophisticated than what anyone else in our industry has. So I'm very focused on these issues. Senator Feinstein: (01:09:44) Well, I'm happy to hear that because I'm really struck by it that people armed with assault weapons as a product of a tweet could rally outside an election office. I think it's really a serious issue that needs to be... Senator Feinstein: (01:10:03) It's really a serious issue that needs to be considered and there need to be, once you signal that and people respond to it, it has to be, in some way, abated or some way pointed out or restructured on the internet itself. Now, can you respond to that- Speaker 1: (01:10:27) Senator Feinstein, I hate to... We're almost doubled the time. Could we- Senator Feinstein: (01:10:32) I'm sorry. Speaker 1: (01:10:33) That's all right. We're going to have a vote come up I and apologize. Senator Lee. Mr. Lee: (01:10:38) Thank you, Mr. Chairman. First, I'd like to note that as far as the president's arguments about the election and how they turned out, inciting violence, I'd like to point out here that the only violence that I'm aware of has occurred in connection with Antifa, Antifa's response to pro-Trump peaceful rally attenders. So I don't quite understand that. Maybe we will have a chance to dwell on that more in a minute, but first I want to talk a little bit about federal law, existing federal law, and what it requires. Section five of the federal trade commission act prohibits businesses from engaging in unfair or deceptive trade practices. Compliance with this particular law requires that there be some consistency between what a company represents as their practices and their products and what they actually are. In other words, you can't sell one thing and provide another under the guise of providing something different than what's being sold. Both Twitter and Facebook represent and have represented for years to their users, their customers, that they take a neutral approach to election content moderation. However, as we've heard today and as we will continue to hear today and into the foreseeable future, there are instances in which your platforms are taking a very distinctively partisan approach and not a neutral one to election related content moderation. For example, just days before the election, Twitter suspended the account of Mark Morgan. Now Mark Morgan is the commissioner of the US Customs and Border Protection Office, and they suspended Commissioner Morgan's Twitter account specifically for a tweet celebrating the access of the US southern border wall. Mr. Lee: (01:12:42) Apparently, Commissioner Morgan's tweet, his comments about the border wall, violated Twitter platform rules governing what it calls atrial conduct. Now I've read the offending post and the offending post from Commissioner Mark Morgan reads as follows. @ CVP and the Army Corps of engineers, "continue to build a new wall every day. Every mile helps us stop gang members, murderers, sexual predators, and drugs from entering our country. It's a fact walls work." Mr. Dorsey, can you tell me in one sentence, what exactly is hateful about Commissioner Morgan's tweet that I just read? Mr. Dorsey: (01:13:29) Well, we evaluated this treat again and we found that we were wrong. There was a mistake and it was due to the fact that we had heightened awareness around government accounts during this time. So that was a mistake. We reverted it. Mr. Lee: (01:13:44) Thank you. I appreciate that, and we're going to get back to more of that in a minute and get back to the fact that I understand that mistakes happen, but what we're going to see today is that mistakes happen a whole lot more, almost entirely on one side of the political aisle rather than the other. Now, Commissioner Morgan's statement in that tweet, as was initially taken down, is factual. There's nothing remotely hateful about it, and yet it was taken down. Now on October 15th, Facebook relied on a third party fact checker's assessment to ban two advertisements from Facebook for "partly false information." Now, both of these advertisements were factual in nature. They revealed Joe Biden's and Kamala Harris' views on late term abortion. Mr. Lee: (01:14:37) Joe Biden has stated that he won't accept any restrictions on abortion and Senator Harris' views are such that she voted against requiring care for a child born alive during a botched abortion. The very next day, the third party fact checker issued a statement retracting the assessment and retracting it as erroneous. However, it stunningly took Facebook almost two more weeks, until October 29th when voting had already started in many jurisdictions to lift the ban on these legitimate ads, ads that the fact checker had already declared a couple of weeks earlier were erroneously taken down. So Mr. Zuckerberg, why on earth did it take Facebook two weeks to correct this error? Mr. Zuckerberg: (01:15:37) Senator, I'm not familiar with the details of us re-enabling that ad so I can follow up with you after. It's possible that this was just a mistake or delay and unfortunately, when we handle millions or billions of pieces of content today, while we strive to do as well as possible and be as precise as possible, we will make some mistakes. Mr. Lee: (01:16:06) Thank you. I appreciate your acknowledgement of the fact that there are mistakes. As I've noted previously, those mistakes sure happen a whole lot more on one side of the political spectrum than the other. Now this is understandable. We're humans, but it's also understandable why this might occur. Maybe some of it has to do with your employees. 92.83% of Facebook employees who donated to federal candidates, they give to Democrats. At Twitter, it's even more stark than that, as if it could get much more stark, but 99.3% of Twitter employees who have donated to federal candidates gave to Democrats, and so these mistakes, they may be mistakes, but they're mistakes that rhyme. Mr. Lee: (01:16:45) They may not repeat themselves, but they rhyme and the consistent theme happens to be Republicans, conservatives, and the pro-life activists. Now I'd like to ask both of you, is there a list of every user or every content creator who has been de-platformed or had their contents reach altered or have had some other adverse action taken by either Facebook or Twitter altered? Is there some list that identifies each user for which that has happened? Mr. Zuckerberg, let's hear from you, just a yes or no question. Does such a list exist? Mr. Zuckerberg: (01:17:30) Senator, I'm not aware of anything like that existing. Mr. Lee: (01:17:35) Mr. Dorsey, how about you? Mr. Dorsey: (01:17:38) I'm not exactly sure what you're asking, but we certainly- Mr. Lee: (01:17:43) Simple question, do you have a list of people, your users or content creators who have had some adverse action taken against them, either being de-platformed or having their reach altered or something because of the content of their posts? Mr. Dorsey: (01:17:56) Well, certainly whenever we take an action, it's recorded somewhere in the database, but I'm not sure if that's your intent. Mr. Lee: (01:18:02) No, that's helpful. So what I'm hearing from both of you is that while there may not be an actual list, and I'd like you both to check to see if such a list exists, but even if there isn't, there is a defacto list because you have within your databases, records of occasions when this has occurred, and so I'd like to ask both of you, if such a list exists, please send it to me. I'd like to see it. If such a list does not exist, you certainly do have the data necessary in order to generate some and I request as a member of this committee that you generate such a list and provide it to me. Thank you very much, Mr. Chairman. Mr. Lee: (01:18:46) Senator Graham, the chairman of the committee, has stepped out momentarily. I've been directed to recess the hearing momentarily so that we can go and vote, and then we will pick up back here in just a few minutes. I would like to, as long as I have the gavel momentarily, I'm going to ask one more question before I leave to go vote and then we'll recess the hearing after this question. Speaker 2: (01:19:13) Could I ask when we're coming back? I've been waiting to ask questions for an hour now. Mr. Lee: (01:19:19) We'll be coming back as soon as Senator Graham returns. He left to vote just a moment ago. He'll be back. Mr. Zuckerberg, in September, Facebook tagged an ad run by the American principles project in Michigan that criticized Joe Biden and criticized Senator Gary Peters, and the ad was tagged because it was "missing context." Now the next day, the ad was shut down entirely by Facebook. Facebook relied on a supposed fact check from PolitiFact, which is a nice way for you to avoid taking accountability for the problem, except that the fact check in question literally said that the ad "makes predictions we can't fact check." Apparently, this had to do with lacking context, but when did lacking context become a new standard for political ads? Mr. Lee: (01:20:23) I mean, all political ads, all ads in general, but certainly all political ads, lack context. Ben Sasse just finished a resounding victory in Nebraska, and I haven't seen his TV ads, but I'm sure they're brilliant. This guy's made for television, and with or without the beard, and I'm sure his ads didn't say Ben Sasse, great Senator, but not that great of a hockey player or there's always context that is lacking, left out in any advertisement. So what does that mean and have you applied the missing context label to any democratic ads, a single one that you can identify? Mr. Zuckerberg: (01:21:09) Senator, I'm not familiar with that specific standard, but as kind of a background on the fact checking program, the basis of this is that we have heard resoundingly from our community that people do not want to see misinformation and believe that it is a problem, but people also believe that they do not want Facebook to be the arbiter of truth and deciding everything that is true and false, and for what it's worth, I strongly agree with that and I do not think it is the right thing for us to assume that role. Mr. Zuckerberg: (01:21:40) So within those bounds, we've tried to create a fact checking program that works with independent third-parties who have been accredited by the Poynter Institute for Journalism, which I think is widely respected, and we give those fact checkers the latitude to determine whether ads or other content on our service is accurate, and if not, we apply some demotions or we prevent them from being run as ads. I can follow up in more detail afterwards on the specifics of your questions since I'm not as familiar with them right now. Mr. Lee: (01:22:21) I would appreciate that very much if you'd be willing to do that because it's not only inconsistent with logic and with what the standards that apply in every other advertising context that I'm familiar with. It's also inconsistent with what Facebook itself does. Just to give you some context for that, while we're talking about missing context, I recently posted something about the election on Facebook, and my Facebook post was almost immediately tagged with the following. "Election officials say that voter fraud, which is historically rare, has not affected the outcome in this election. They have confirmed that mail-in voting was conducted in accordance with state voting rules." Mr. Lee: (01:23:08) Now I find this a little disturbing. Accounts tagged to me sounds a whole lot more like state run media announcing the party line rather than a neutral company as it purports to be running an open online forum is editorializing insulates people from the truth and it insinuates that anyone concerned about voter fraud must be crazy. It also states it as if it were an irrefutable neutral objective fact. Now maybe these kinds of concerns are out of the mainstream in Palo Alto, but they're not out of the mainstream with the rest of America. Mr. Lee: (01:23:53) I have to reiterate, I hope this kind of manipulation wasn't intentional, but it's getting harder and harder for me to accept the premise that it could be anything but intentional, and if it was intentional, it's yet more evidence that Facebook's actions surrounding this election are incongruent with the promises that you've made to your own users and that's a problem. Consistent with the directions of but given by Chairman Graham, we're now going to recess. I predict we'll be in recess for no more than 10 or 15 minutes until Chairman Graham returns. We stand in recess. Mr. Lee: (01:24:31) [inaudible 01:25:32]. Sen. John Kennedy: (01:24:31) (Silence). Sen. John Kennedy: (01:52:23) The committee will come to order. Senator Leahy? Sen Patrick Leahy: (01:52:27) Thank you, can you hear me all right? Sen. John Kennedy: (01:52:28) Yes, sir. Sen Patrick Leahy: (01:52:30) Good. Sen. John Kennedy: (01:52:31) We can see you too, Senator. You look great. Sen Patrick Leahy: (01:52:36) Well let me start by saying... It's my thick head of hair, that's what does it. But I want to say I recognize the challenging position that social media companies are in where your platforms hosts much of the news that America, and actually the world, use to stay informed. So you're on the frontline of both domestic and foreign disinformation campaigns and you have to balance American ideals like freedom of speech, you have to limit hate speech, you have to limit dangerous misinformation. That's a significant challenge. I saw one of the people who came here to demonstrate last weekend in Washington say they're there because they had found out that China had one minute before the polls closed dumped millions of votes for Joe Biden. Somebody said, "Well, what do you mean?" They said, "Well, it was on the internet, it's got to be accurate." Sen Patrick Leahy: (01:53:42) But now your platforms are taken some positive steps, but I mention that one thing and I hear from people all the time that stop me with some of these misinformation, sometimes very dangerous misinformation, they've gotten it from your platforms. And I happen to think you can and must do better, our security, I think even our democracy, our understanding of basic truth depends upon you doing a better job. President Obama described the escalating erosion of the acceptance of facts, of science, of clear evidence as, "Truth decay." Without facts, it's hard to imagine how a government by and for the people can exist and your platforms can bring people together. I think often they act as a form of driving people apart. Sen Patrick Leahy: (01:54:46) Now, during this election, President Trump has emerged as the most prominent distributor of false and misleading election information, he still does it, nothing short of propaganda. Without evidence, he routinely claims the election was rigged, says the States actually cheated and fixed the results, even claims that millions of Trump votes were deleted. And he's doing that while his own Department of Homeland Security is staying the election was the most secure in American history and there's no evidence any voting system deleted or lost, changed votes, or was in any way compromised, that's what our own US Government is saying when the head of government, the President, is saying just the opposite. So it may make him feel better about the fact that he lost badly, but we shouldn't have to put up with it. Sen Patrick Leahy: (01:55:47) So I have a question for both of you, has Facebook or Twitter conducted an in-depth postmortem review of election misinformation spread on your platforms? Not just what you're label, but how far the misinformation reached? Have you done that kind of a post-mortem? Mr. Zuckerberg: (01:56:11) Senator, we will do that analysis and, also, we are commissioning and working with independent academics to enable them to do the studies themselves and to publish what they find without any intervention or permission required from Facebook. Sen Patrick Leahy: (01:56:31) Thank you, and? Mr. Dorsey: (01:56:33) And we are doing the same, including opening up our APIs to researchers to make sure that others are able to see what we may not see ourselves. Sen Patrick Leahy: (01:56:42) Will that be made available to us? Can other people see the results of that study you're going to do, both of you I would ask? Mr. Zuckerberg: (01:56:54) Senator, yes, the academic research is going to be public and the academics are going to be able to publish this themselves without even having to get Facebook's approval over what they publish. Sen Patrick Leahy: (01:57:07) Thank you. And Mr. Dorsey? Mr. Dorsey: (01:57:10) And we'll make our reports and findings public as well, so everyone can learn. Sen Patrick Leahy: (01:57:15) I'll look forward to reading them. I'm actually one member of the Senate who will actually read them, so thank you. Because you look at some of the things that went on, I know Senator Blumenthal and others have raised this question about Steve Bannon putting on a video, think of what it did. It called for the murder, the beheading of Dr. Fauci and the Director of the FBI, Christopher Ray. Just think what that does. I mean the FBI Director travels with security all the time, Dr. Fauci and his family are private citizens, they're calling for their beheading. And it was seen by, I think, 200,000 people on Facebook. Well, if you are going to have somebody threatening to murder somebody, what do you do about that? I mean, how do you catch that in a hurry? Because I was a prosecutor, I prosecuted murderers and we didn't have to face this kind of threat at that time. But what do you do when hundreds of thousands of people see a threat, "Go murder somebody."? Mr. Zuckerberg: (01:58:39) Senator, in that case, that content violated our policies and we took it down. And as has been the subject of some of the other questions, if someone had multiple offenses like that, we would remove their whole account. Sen Patrick Leahy: (01:58:52) Well, I'm sure that's the threat that they do multiple times say, "Go out and murder somebody, cut off their head," we're going to face a real problem. "Facebook will take down our posting? Oh my goodness, what a deterrent." Mr. Zuckerberg: (01:59:18) So Senator, what we try to do is identify content that violates our policy before anyone in the community has to see it or even report it to us. And for some categories like terrorism, which I've cited before, about 98% or 99% of the content that we take down our AI and human systems find before anyone even has to report it to us. On hate speech, we're up to 94% of the content that we take down our AI systems and content reviewers find it before people have to report it to us. What we try to drive on more effectiveness is basically finding more and more of that harmful content earlier, before it is seen broadly across our system. Sen Patrick Leahy: (02:00:07) Let me ask you about that because we've had these discussions before, I'm deeply concerned about Facebook's role in spreading hate speech in Myanmar. Hate speech that helped fuel a genocide against the Muslim Rohingya people. And I mean, horrible, I've seen the pictures, I've seen some of the genocide. Now, you've made some progress about this since you and I had talked about it last, but my understanding is that Facebook shuts down specific accounts that violates your content related policy, but then that user could, of course, just create a new account. In Myanmar, for example, on October 8th, Facebook took down 38 inauthentic accounts created and controlled by members of the Myanmar military in part to promote anti-Rohingya content, and I compliment you for doing, but the Myanmar military just turned around and created new accounts that promote the same content. So in some way you've got a whack-a-mole problem here, but is there a way that you can stop these things, not just at the account level, but at the user level? And I use that as an example because people are being murdered in a systematic genocide. Sen. Lindsay Graham: (02:01:44) Please answer Senator Leahy's question, then we'll need to move. Go ahead. Sen Patrick Leahy: (02:01:49) And I'm sorry to take long, but the previous questioner took all his time plus all the time that had been allotted to me. Sen. Lindsay Graham: (02:01:57) No, I agree. No, we're at two and a half minutes and let's just wrap it up, but go ahead and answer the question. Mr. Zuckerberg: (02:02:03) Senator you're correctly pointing out that we did disable certain generals in the Myanmar military as dangerous figures and they are not allowed to sign up for new accounts. But as you point out, these kinds of integrity problems are not ones that there's a silver bullet or where you can ever fully solve them. We will always be working to help minimize the prevalence of harm in the same way that a city you will never eliminate all crime, you try to reduce it and have it be as little as possible. And that's what we try to do through a combination of building AI systems to identify harmful content upfront, hiring thousands of people, tens of thousands of people to do content review, and partnering with organizations, whether it's in the intelligence community, law enforcement, election officials, or in Myanmar, local civil society to help us flag things that we should be aware of and on high alert about. Sen Patrick Leahy: (02:03:12) Thank you. Mr. Chairman, I'll have some questions for the record for both of the witnesses. Sen. Lindsay Graham: (02:03:19) Thank you very much, Senator Leahy, I appreciate that. Senator Cruz? Sen. Ted Cruz: (02:03:24) Thank you Mr. Chairman. Facebook and Twitter and Google have massive power, they have a monopoly on public discourse in the online arena. I will say it's dismaying listening to the questions from our democratic colleagues because consistently the message from Senate Democrats is for Facebook and Twitter and Google to censor more, to abuse their power more, to silence voices that Senate Democrats disagree with more. That is very dangerous if we want to maintain a free and fair democracy, if we want to maintain free speech. There was a time when Democrats embraced and defended the principles of free speech, there was a time when Democrats embraced and defended the principles of a free press, and yet there's an absolute silence from Democrats speaking up for the press outlets censored by big tech, there's an absolute silence for Democrats speaking out for the citizens silenced by big tech. Instead, there is a demand, "Use even more power to silence dissent," and that's a totalitarian instinct that I think is very dangerous. Sen. Ted Cruz: (02:04:43) At the same time that big tech exercises massive power, it also enjoys massive corporate welfare through the effect of Section 230, a special immunity from liability that nobody else gets. Congress has given big tech, in effect, a subsidy while they become some of the wealthiest corporations on the face of the planet. Mr. Dorsey, I want to focus primarily on Twitter and ask you initially, is Twitter a publisher? Mr. Dorsey: (02:05:18) Is Twitter a publisher? Sen. Ted Cruz: (02:05:20) Yes. Mr. Dorsey: (02:05:20) No, we are not, we distribute information. Sen. Ted Cruz: (02:05:29) So what is a publisher? Mr. Dorsey: (02:05:29) An entity that is publishing under editorial guidelines and decisions. Sen. Ted Cruz: (02:05:35) Well, your answer happens to be contrary to the text of federal statute, particular Section 230, which defines an information content provider as, "Any person or entity that is responsible, in whole or in part, for the creation or development of information provided through the internet or any other interactive computer service." Let me ask you, was Twitter being a publisher when it censored the New York Post? Mr. Dorsey: (02:06:05) No. We have very clear policies on the conduct we enable on the platform and if there's a violation, we take enforcement action. And people choose to commit to those policies and to those terms of service. Sen. Ted Cruz: (02:06:23) Except your policies are applied in a partisan and selective matter. You claim it was hacked materials and yet you didn't block the distribution of the New York Times story that alleged to talk about President Trump's tax returns, even though a federal statute makes it a crime to distribute someone's tax returns without their consent. You didn't block any of that discussion, did you? Mr. Dorsey: (02:06:42) Our policy was focused on distribution of the actual hack materials and the New York Times- Sen. Ted Cruz: (02:06:47) Did you block the discussion of the President's tax return material? Mr. Dorsey: (02:06:51) And in the New York Times case, we interpreted as reporting about the hacked materials, not distribution of [inaudible 02:06:58]. Sen. Ted Cruz: (02:06:57) Did you block Edward Snowden when he illegally released material? Mr. Dorsey: (02:07:04) I don't have the answer to that. Sen. Ted Cruz: (02:07:06) The answer is no. You having used this in a selective matter, let me ask you were you being a publisher when you forced Politico, another journalistic outlet, to take down their tweets on a topic that you had deemed impermissible? Mr. Dorsey: (02:07:23) No. We were enforcing our policy and our terms of service. Sen. Ted Cruz: (02:07:27) So on October 15th, Jake Sherman, a reporter at Politico, tweeted the following, "I tweeted a link to the New York post story right after it dropped yesterday morning, I immediately reached out to the Biden campaign to see if they had any answer. I wish I'd given the story a closer read before tweeting it, Twitter suspended me." So you actually have a reporter reporting on a story, asking the other side for comment. And Twitter says, "Hi Jake Sherman, your account @JakeSherman has been locked for violating Twitter rules." Now, what did the Politico reporter do? Immediately tweets after that, "My goal was not to spread information." Well, that's a little worrisome just in and of itself, "My goal was to raise questions about the story." Sen. Ted Cruz: (02:08:08) "Oh, my overlords in Silicon Valley, I was attacking the New York Post. You don't understand, I was attacking them, as I did in subsequent tweets, and see how the Biden campaign was going to respond." They later did respond and then, not long after, Jake Sherman comes back with, "My account is clearly no longer suspended, I deleted the tweet." When Twitter is editing and censoring and silencing the New York Post, the newspaper with the fourth highest circulation in the country, and Politico, one of the leading newspapers in the country, is Twitter behaving as a publisher when it's deciding what stories reporters are allowed to write and publish and what stories they're not? Mr. Dorsey: (02:08:51) No. And that account is not suspended, it fell afoul of the hacked materials policy, we realized that there was an error in that policy and the enforcement and we corrected that within 24 hours. Sen. Ted Cruz: (02:09:00) Hold on, I'm literally looking at the tweet from Twitter that says, "Your account has been locked." You're you're telling me that this is not an accurate... Mr. Dorsey: (02:09:10) That's a lock and can be unlocked when you delete the offending tweet. Sen. Ted Cruz: (02:09:13) I understand that you have the star chamber power, your answer is always, "Well, once we silence you, we can choose to allow you to speak," But you are engaged in publishing decisions. Let me shift to a different topic, Mr. Dorsey, does voter fraud exist? Mr. Dorsey: (02:09:32) I don't know for certain. Sen. Ted Cruz: (02:09:34) Are you an expert in voter fraud? Mr. Dorsey: (02:09:36) No, I'm not. Sen. Ted Cruz: (02:09:38) Well, why then is Twitter right now putting purported warnings on virtually any statement about voter fraud? Mr. Dorsey: (02:09:48) We're simply linking to a broader conversation so that people have more information. Sen. Ted Cruz: (02:09:52) No, you're not. You put up a page that says, "Voter fraud of any kind is exceedingly rare in the United States." That's not linking to a broader conversation, that's taking a disputed policy position. And you're a publisher when you're doing that, you're entitled to take a policy position, but you don't get to pretend you're not a publisher and get a special benefit under section 230 as a result. Mr. Dorsey: (02:10:14) That link is pointing to a broader conversation with tweets from publishers and people all around the country. Sen. Ted Cruz: (02:10:22) Mr. Dorsey, would the following statement violate Twitter's policies, "Absentee ballots remained the largest source of potential voter fraud."? Mr. Dorsey: (02:10:31) I imagine that we would label it so that people can have more context and read through. Sen. Ted Cruz: (02:10:36) Okay. How about this quote, "Voter fraud is particularly possible where third-party organizations, candidates, and political party activists are involved in handling absentee ballots," would you flag that as potentially misleading? Mr. Dorsey: (02:10:56) I don't know the specifics of how we might enforce that, but I imagine a lot of these would have a label pointing people to a bigger conversation, a broader conversation. Sen. Ted Cruz: (02:11:06) Well, you're right, you would label them because you've taken the political position right now that voter fraud doesn't exist. I would note both of those quotes come from the Carter-Baker Commission on Federal Election Reform. That is Democratic President, Jimmy Carter and former Secretary of State James Baker and Twitter's position is essentially voter fraud does not exist. Are you aware that just two weeks ago in the State of Texas, a woman was charged with 134 counts of election fraud? Are you aware of that? Mr. Dorsey: (02:11:37) I'm not aware of that. Sen. Ted Cruz: (02:11:38) If I tweeted that statement with a link to the indictment, would you put a warning on it that says, "Well, the Democratic Party position right now is voter fraud doesn't exist."? Mr. Dorsey: (02:11:48) I don't think it's useful to get into hypotheticals, but I don't believe so. Sen. Ted Cruz: (02:11:53) You don't believe so. Well, we're going to test that because I'm going to tweet that and we'll see what you put on it. Sen. Ted Cruz: (02:11:57) All right. Yesterday, Mr. Dorsey, you and I spent a considerable amount of time on the phone and you said that you wanted to embrace transparency. So I want to ask you, I have asked Twitter, I've asked Facebook multiple times, how many times have you blocked Republican candidates for office, their tweets or their posts in 2016 and 2018 and 2020? How many times have you blocked Democratic candidates for office? How many times have you blocked Republican office holders? How many times have you blocked Democratic office holders? Twitter has repeatedly refused to answer that question with specific hard data and cataloging the examples. In the interest of transparency, which you said you want to embrace, will you commit in this hearing right now to answer those questions in writing? Sen. Lindsay Graham: (02:12:47) And we'll let that be the last question. Mr. Dorsey: (02:12:48) That's exactly what we want to do. Sen. Ted Cruz: (02:12:50) I'm sorry, Mr. Dorsey, I didn't hear you. Mr. Dorsey: (02:12:52) That's exactly what we're pushing for as we think about building upon 230, is transparency not just- Sen. Ted Cruz: (02:12:58) Is that a yes that you'll answer those questions in writing? Mr. Dorsey: (02:13:01) Transparency not just of outcomes, but also our process as well. Sen. Ted Cruz: (02:13:04) Is that a yes that you will answer those questions in writing? Mr. Dorsey: (02:13:08) We'll certainly look into it and see what we can do. Sen. Ted Cruz: (02:13:10) And actually answered them and not give lawyerly doublespeak about why you're not going to give specifics, answer them. Will you commit to this committee that you will answer those questions? Mr. Dorsey: (02:13:20) We're going to work to answering broader transparency around outcomes? Sen. Ted Cruz: (02:13:24) All right, that's a no. Mr. Zuckerberg, how about you? Will you commit that Facebook will answer those specific questions cataloging the number of instances in which Democrats in '16, '18 and '20 had been silenced versus the number of instances in which Republicans have been silenced on Facebook? Mr. Zuckerberg: (02:13:40) Senator, I'm not sure if we have that data available, but I will follow up with you or your team. Sen. Ted Cruz: (02:13:47) Okay, I'm going to take that as a yes, and I'm going to take Twitter, we'll see if it's a yes or, "Transparency is bogus and we don't intend to provide it." Sen. Lindsay Graham: (02:13:55) Senator Durbin? Sen. Dick Durbin: (02:14:00) Thank you, Mr. Chairman. We live in a dangerous world, issues of national security, the worst pandemic public health crisis in modern times in America, and we were being challenged as to whether there is going to be a peaceful transition of power in America in the presidency. At that moment in time, we decided none of those topics were important and what was important was to determine whether or not social media was discriminating against Republicans. It's an interesting question, I think there are more important and timely questions. We have a recount underway in Georgia, we have allegations made by the election officials, the Republican election officials, where they have faced literally death threats. We are trying to determine whether or not the social media instruments of America are fair to the Republican Party. Sen. Dick Durbin: (02:15:08) I'm trying to struggle with this issue because I want to put it in a context and maybe I can't, maybe this is unique. We certainly know what the constitution says when it comes to free speech and we know what it meant over the years, New York Times versus Sullivan and others with publications, we certainly didn't suggest that anyone that used a telephone line for nefarious, illegal, banded activity somehow implicated the telephone company into it by its nature. And then came radio and TV and we had to come up with new rules in terms of, at one time, equal time, fair content and so forth. And now we have this relatively new mechanism of communicating information and we're trying to determine what to do with it, whether to treat it like a newspaper publishing or treat it like some sort of a communications network alone. Section 230 is an attempt to do that and I'm sure everybody finds fault with it. Sen. Dick Durbin: (02:16:21) I'd like to ask the two witnesses if they would comment on the historical aspects of this particular debate, if they have any thoughts? Mr. Zuckerberg, Mr. Zuckerberg: (02:16:36) Senator, one of the points in the discussion that I find interesting is people ask if the regulatory model should be more like the news industry or more like telco's, but from my perspective, these platforms are a new industry and should have a different regulatory model that is distinct from either of those other two. I think it is not the case that we are like a telco and that there are clearly some categories of content, whether it's terrorism or child exploitation, that people expect us to moderate and address, but we're also clearly not like a news publisher in that we don't create the content and we don't choose upfront what we publish, we give people a voice to be able to publish things. So I do think that we have responsibilities and it may make sense for there to be liability for some of the content that is on the platform, but I don't think that the analogies to these other industries that have been created previously will ever be fully the right way to look at this. I think it deserves and needs its own regulatory framework to get built here. Sen. Dick Durbin: (02:18:00) Thank you. Would the other witness care to respond? Mr. Dorsey: (02:18:07) From a historical perspective, 230 has created so much goodness and innovation and if we didn't have those protections when we started Twitter 14 years ago, we could not start. And that's what we're most concerned with is making sure that we continue to enable new companies to contribute to the internet, to contribute to conversation. And we do have to be very careful and thoughtful about changes to 230 because going one direction might box out new competitors and new startups, going another might create a demand for an impossible amount of resources to handle it, and going at another might encourage even more blocking of voices or what's being raised here, which is censorship of voices and changing the internet dramatically. So... Sen. Dick Durbin: (02:19:07) SO let's... Go ahead. Mr. Dorsey: (02:19:09) So I believe that we can build upon 230. I think we can make sure that we're earning people's trust by encouraging more transparency around content moderation and our process of it, I think we need much more straightforward appeals. And I think the biggest point to really focus on going forward is algorithms and how they are managing and creating these experiences and being able to have choice in how to use those algorithms on platforms like ours. Sen. Dick Durbin: (02:19:42) Let me get into a specific, Mr. Zuckerberg, October 10th, Detroit Free Press reported, "13 men charged Thursday in a conspiracy to kidnap Michigan Governor Gretchen Whitmer used Facebook and secure messaging apps to connect and plot their attack. The group's use of Facebook spans almost a full year, members began-" Sen. Dick Durbin: (02:20:03) ... Use of Facebook spans almost a full year. Members began to use the social media platform as a recruitment tool in November, 2019 according to an affidavit by Brian Russell, Detective Sergeant Michigan State Police. Once recruited, members communicated by a secure encrypting message platform. According to news reports, Facebook alerted the FBI about the Michigan kidnappers online activity several months before the arrest. Thank goodness. However, in August a Facebook page for the Kenosha Garden Militia, which advocated violence in the aftermath of the shooting of Jacob Blake was reportedly flagged over 455 times to Facebook. However, the page was deemed non-violating and left up. More than 4,000 people responded to that event, 100s of armed militia members showed up. A member of this group, a teenager from Illinois, later shot and killed two people on the streets of Kenosha. Mr. Zuckerberg, you describe Facebook's handling of this militia page as an operational mistake. Can you explain the exact reason why the Kenosha militia page was not taken down? Mr. Zuckerberg: (02:21:15) Senator, yes. And first, what happened in Kenosha was obviously terrible. What happened here was we rolled out a strengthened policy around militia pages in general. Whereas before that, we would have allowed a group that was a militia as long as it wasn't planning or organizing violence directly. In the lead up to the election, we strengthened the policy to disallow more of those groups because we were on high alert and were treating the situation is very volatile around potential civil unrest around the election. We just put that policy into place, and for a number of reasons, it had not yet been fully rolled out and all of the content reviewers across the company hadn't been fully trained on that. Mr. Zuckerberg: (02:22:10) So we made mistakes in assessing whether that group should be taken down. But upon appeal, when it was escalated to a more senior level of content review folks who have more specific expertise in these areas, we recognized that it did violate the policy and we took it down. It was a mistake, it was certainly an issue, and we're debriefing and figuring out how we can do better. Although, one other piece that I would add is that the person who carried out the shootings was not in any way connected to that page or links to any of the content there from anything that we or others can tell. Sen. Dick Durbin: (02:22:56) Mr. Chairman, if I can ask one more question? Yesterday, the FBI released its annual hate crime incident report. The report found that more people were killed in hate motivated violence in 2019 than any year since the FBI began collecting hate crime data in 1990. The report also found that race-based hate crimes remained the most common type of hate crimes last year, and documented increase in religion based hate crimes, anti-Hispanic hate crimes, and hate crimes targeting individuals based on gender identity. Given these statistics, it appears to me that it's more important than ever for social media companies to combat hate on their platforms. And I might add too what one of my colleagues stated earlier, this is not Antifa, but these are documented hate crimes from FBI. Sen. Dick Durbin: (02:23:44) Muslims have reached out to you many times, Mr. Zuckerberg, about this issue relating to published content that reflects on certain religious groups. And you said at a hearing, you do not allow hate crimes on Facebook. Yet in May, 2020, the tech transparency project found more than 100 American white supremacist groups, many of them explicitly anti-Muslim, active on the platform, both on their own group pages, as well as auto-generated content. Facebook did nominally alter some of the content, but the hate groups largely remained. Are you looking the other way, Mr. Zuckerberg, in a potentially dangerous situation? Mr. Zuckerberg: (02:24:35) No Senator, this is incredibly important and we take hate speech as well as incitement of violence extremely seriously. We banned more than 250 white supremacist organizations and treat them the same as terrorist organizations around the world. And we've ramped up our capacity to identify hate speech and incitement to violence before people even see it on the platforms. Our AI and human review teams, you can track our results in the transparency reports that we issue, now take down about 94% of the hate speech that we find on our platforms before anyone has to even report it to us, which is a dramatic amount of progress from where we were a few years ago when we were just starting to ramp up on this, where we're taking about 20% of it down before people had to report it to us. So there's still more progress to make. We're very invested in this, and you have my commitment that we view this as an issue of the highest severity and one that we are very focused on. Sen. Dick Durbin: (02:25:45) Thank you very much. Mr. Graham: (02:25:46) Senator Sasse? Ben Sasse: (02:25:48) Thank you Mr. Chairman, thank you for hosting this hearing. Clearly important topics around content moderation. I'm a skeptic of the content moderation policies that exist, both because I don't think the standards are very transparent and I don't think the execution is very consistent. That said, I'm more skeptical than a lot of my colleagues, I think on both sides of the aisle, about whether or not there's a regulatory fix that will make it better instead of worse. I especially think it's odd that so many in my party are zealous to do this right now when you would have an incoming administration of the other party that would be writing the rules and regulations about it. And I think it's telling that a number of folks on the other side of the diocese, I think of Senator Blumenthal, a guy I like, but who seemed to almost be giddy about the prospect of a new government regulatory agency to police online speech. Ben Sasse: (02:26:45) And I think a lot of people on my side should take pause at the idea that so many on the other side of the aisle are excited about having the next administration get to write these rules and regulations. But to the broader question, first just to get to kind of a level set, and I want to thank both the witnesses for being here today, but when Senator Lee lays out some of the issues he did about just that every human community is going to be situated in a different place about policy commitments and priorities and beliefs. Ben Sasse: (02:27:14) But when Senator Lee said that 93% of Facebook employees who contribute to politics do so on the left and 99%, I think it was, of Twitter employees contribute on the left, I would just be interested to see if either of the two of you think that has implications in the shepherding of your organizations. Again, I recognize fully that you're private organizations, and so again, I'm more skeptical of a governmental fix for a lot of the problems we're talking about here today. But I'm curious as to whether or not Mr. Zuckerberg and Mr. Dorsey, and I guess we'll start with Facebook, I'm curious as to whether or not you think it's likely that there is systemic bias inside your organization in the execution of content moderation policies given that your employee base is so unrepresentative of America in general. Mr. Zuckerberg: (02:28:04) Senator, I think it's a good question and certainly I think it means that we have to be more intentional about what we do, and thoughtful. Our principle and goal is to give everyone a voice and to be a platform for all ideas. As you mentioned, I do think it's undisputed that our employee base, at least the full-time folks, politically would be somewhat, or maybe more than just a little somewhat, to the left of where our overall community is, where the community basically spans almost wide varieties of people across society. So I do think that that means that we need to be careful and intentional internally to make sure that bias doesn't seep into decisions that we make. Although, I'd point out a couple of things. One is that people have a lot of different views outside of work, and we expect and I think generally see that people conduct themselves professionally. And second, the folks who are doing the content review work, we have about 35,000 people doing content review, are typically not based in Silicon Valley. Mr. Zuckerberg: (02:29:20) They're based in places all over the country and all over the world because we serve people in countries all over the world. So I think that the geographic diversity of that is more representative of the community that we serve than just the full-time employee base at our headquarters in the Bay area. Ben Sasse: (02:29:42) Thanks, Mr. Zuckerberg. Mr. Dorsey? Mr. Dorsey: (02:29:45) Yeah, this is obviously not something we interview for, and even have an understanding of when people are in the company. And with that understanding, we intend to make sure that both our policy and our enforcement is objective. And I realized that it looks rather opaque and certainly the outcomes might not always match up with our intention and the perception of those outcomes may not match up. But that's why I think it's so important that we're not just transparent around our policies, but the actual operations of our content moderation. If people don't trust our intent, if people are questioning that, that's a failure and that is something that we need to fix and intend to fix. And I think it would benefit the industry as well. But I do, again, point back to something I said earlier on the testimony, which is a lot of these decisions are not being made by humans anymore, they're being made by algorithms. And that's certainly enforcement decisions, but also decisions around what you see or what you don't see. And to me, that is the body of work, that is the conversation that we should be focused on because that is the enduring use case for everyone who interacts with these services. Ben Sasse: (02:31:11) Thank you. And I wish it were true, that these were all easy, objective questions. That the questions were, if somebody says, "Is the sky green?" That's an objective question, that the sky is blue and white, not green. But most of the things we're talking about here and the places where you're applying content moderation labels are not really simply objective questions. They're mostly subjective questions. If we talked about Medicare for All being easily paid for inside a ten-year budget window on assumptions, X, Y, and Z, that don't raise taxes, that's not true. There isn't any math by which Medicare for All pays for itself in some short term window, but I don't think any of us really think you're going to slap a label on that saying, "This is disputed accounting or math or policy projections." And so really what's happening is there's a prioritization grid that people are going through as they build even the algorithms, even those that aren't driven by humans, and they're driven by policy priorities of situated individuals. Ben Sasse: (02:32:19) I may be wrong about this, but my suspicion is that your employee base is not actually 99% left of center, I bet it's less than that. And I would speculate that part of the reason less than 1% of your employees give money to candidates on the right is because there's a social stigma attached to having conservative views inside your organization. And I would guess that those same sort of internal cultural biases inform the subjectivity of which issues end up labeled. So again, this is an odd place to be in that I am skeptical that the content moderation policies are thought out well. They're not transparent enough for us to really know, but I'm definitely skeptical that they're consistently applied. And yet I'm not really on the side of thinking there's some easy governmental fix here. There's a lot about Section 230 that we could debate. Ben Sasse: (02:33:09) I think some of the things Senator Durbin said about how in the era of telephones, nobody blamed the phone company for other people having spread misinformation by the phone. Exactly, that's what would be the case if Section 230 were actually neutral, but you're applying content moderation policies and seemingly in a way that's not objective. So I know that I'm nearly at time, but I think it would be useful for us to hear from both of you to give us three or five-year window into the future. If there isn't new legislation, what is changing besides just saying we're moving from humans to more AI? What qualitatively is changing in the way content moderation happens inside your organizations short of a new regulatory scheme? Can you tell us where you think you're actually improving and what problems you're trying to solve? Mr. Zuckerberg, you first, please. Mr. Zuckerberg: (02:34:02) Senator, one of the areas that we're very focused on is transparency, both in the process and in the results. So we're already at the point where every quarter we issue a community standards enforcement report that basically details the prevalence of each category of harmful content and how effective we are at addressing it before people have to even report it to us. Over time, we would like to fill that out and have more detail on that and then make it more robust. We've already committed to an independent, external audit of those metrics that people can trust them even more. People have lots of different kinds of requests for where we might go with that in the future, whether that's breaking down the stats by country or language or into more granular buckets, adding more data around precision. But I think that that would all be very helpful so that people can see and hold us accountable for how we're doing. And for what it's worth, I think that that would be a valuable part of a regulatory framework that would not feel particularly overreaching to me, is something that could be put in law that would create an apples to apples framework that all companies in this space would have to report on the outcomes and effectiveness of their programs in that way, so at least we can see how everyone is doing. That seems like a sensible step to me. Ben Sasse: (02:35:28) Thank you, Mr. Dorsey? Speaker 3: (02:35:30) Senator Whitehouse. Ben Sasse: (02:35:31) Sorry, Mr. Dorsey is still answering the same question and then I'll give it back to you in a hurry, Mr. [inaudible 02:35:36]. Speaker 3: (02:35:36) So, sorry. I missed that. It's a junior acting chairman. Mr. Dorsey? Mr. Dorsey: (02:35:41) Thank you. Well, if we're considering three to five years out, I think the realization that a centralized global content moderation system does not scale and we need to rethink how we operate these services. And I would point to, we certainly need transparency around any process that we have and around the practice and the outcomes of those iterations. But I think having more control so that individuals can moderate themselves, pushing the power of moderation to the edges and to our customers and to the individuals using the service, is something we'll see more of. And I also believe that having more choice around how algorithms are altering my experience and creating my experience is important. So being able to turn off ranking algorithms, being able to choose different ranking algorithms that are found written by third party developers in somewhat of an algorithmic marketplace, I think is important and a future that would excite and energize us. Speaker 3: (02:36:55) Thank you. I've appreciated my interaction with both of your companies in the run-up to this, and I think both of you said some meaty things there about ways we can move toward greater transparency. So I'll follow up again. Thank you, Mr. Chairman. Mr. Graham: (02:37:07) Thank you, Senator Whitehouse? Sheldon Whitehouse: (02:37:09) Thank you, Chairman. Gentlemen, let me start with just a moments history to give some context to my questions. When the tobacco industry discovered that its product was deadly, it responded to that news with a systematized program of denying that set of facts. The upshot for the tobacco industry was not great. It was found in federal court have been engaged in massive fraud and was put under court order to cease its fraudulent behavior. At around the same time, the fossil fuel industry began to run into a similar problem regarding the effects of its product and it picked up the tobacco industry scheme kind of where it left off, including using some of the same individuals, some of the same entities, many of the same methods as the tobacco industry's denial operation. Sheldon Whitehouse: (02:38:14) These are persistent, highly motivated, very well-funded and complex information operations, not unlike a hostile intelligence service would run, and they are quite secretive. And we're now seeing a new form, I guess you'd call it election denial, happening around our country right now. So that's the background that I come at this from seeing and I'm wondering if each of you see a difference between individual error and basically mass disinformation. Is there a difference between odd people with fringe views who offer personal opinions and an orchestrated plan of deliberate misinformation or disinformation that is driven by motivated interests, whether foreign or domestic? Mr. Zuckerberg: (02:39:11) Senator, I absolutely think that there's a difference and you can see it in the patterns of use on the platforms. And in our policies and operations, we view these coordinated, inauthentic behavior operations networks of fake and sometimes combining with real accounts to push out a message, but make it seem like it's coming from a different place than it is, or it might be more popular than it is. This is what we saw the Internet Research Agency out of Russia do in 2016. And since then, a number of other governments and private organizations, including some companies like what you've mentioned, have engaged in this behavior. Mr. Zuckerberg: (02:39:58) Now, the good news is that I think that the industry has generally gotten its systems to be a lot more sophisticated to defend against that in the last several years. It's a combination of AI systems that we've built to find networks of accounts that aren't really behaving quite the way that a normal person would coupled with large numbers of content reviewers, sometimes with expertise in counter terrorism or counter-intelligence. And then some signal sharing, whether it's with the intelligence community, law enforcement, different groups that have expertise in different areas and with other tech platforms. But this is a big effort on, I think, all of our sides to make sure that we can defend against this kind of interference. And I think we are getting better and better at it. Sheldon Whitehouse: (02:40:49) Well, let me encourage you to persist. As you know, the last time you were here, you were asked about advertising paid for on Facebook denominated in rubles, which was not a very sophisticated scheme to be able to penetrate. But Facebook was unable to penetrate it and your upgrade from that original setup was simply to allow a shell corporation to intermediate between the real actor and not. So I encourage you to continue to try to make sure that real voices are what are heard on Facebook. Mr. Dorsey, let me turn to you and ask you the same question in the context of bots. Brown University recently did a study that showed that about 25% of all tweets about climate change are generated by bots. Most of them obviously push out climate denial, as I described that operation. How is Twitter's capacity to identify a bot as opposed to a real customer? Mr. Dorsey: (02:41:59) Well, to build off your previous question, I do think there is a difference, as Mark said, and I do think there are many coordinated campaigns to manipulate the public conversation, to divide people all around the world, to confuse them and generally to distract. And we do have policies and enforcement to prevent as much of this as possible. It is a growing threat and it shows no signs of slowing down. Bots are one way that entities do this. Sometimes it may look like a bot, but it's actually a human that it is organized with other humans for a particular agenda. So it is challenging. We are doing work right now to better identify bots on our service as a- Sheldon Whitehouse: (02:42:48) Let me just interject Mr. Dorsey real quick. As a baseline proposition, do you agree that a bot does not deserve a voice on your platform? That it should be actual people and organizations? Mr. Dorsey: (02:43:01) I don't agree with that as a high-level. I think we should be labeling bots so that people have greater context for what they're interacting with. Sheldon Whitehouse: (02:43:10) Fair enough. Mr. Dorsey: (02:43:11) There are plenty of bots on our service that provide a valuable function and I wouldn't want to take that away. Sheldon Whitehouse: (02:43:20) Let me ask both of you, and maybe you can supplement this with the answer in writing for the record because my time is getting short and this is a complicated question, but the question is when does it matter to Twitter and when does it matter to Facebook to know who the actual entity is who is using your platform? Let me start with you, Mr. Dorsey, since Mr. Zuckerberg went first last time. And you can defer to a written answer if you'd like, because my time is running very short. Mr. Dorsey: (02:43:58) We'll add to this conversation with a written answer, but I do believe that pseudonymity is important. We have seen its usefulness with activists and with whistle blowers, and I think that is critical. But certainly there are times, and it's charged by the severity of potential outcomes, where we need to dig into identity and take actions. Sheldon Whitehouse: (02:44:27) We'll follow up with that. And let me just ask you, since my time has expired, Mr. Zuckerberg, to respond or have your organization respond in writing. Thank you. Mr. Graham: (02:44:36) Thank you. Senator Whitehouse brought up something very important. Now I'm going to ask this as directly as I can. To Facebook and Twitter, do you have any internal research or evidence to suggest that your platforms can be addictive? Mr. Zuckerberg? Mr. Zuckerberg: (02:45:04) Senator, I think we can follow up with a summary of research that we have. But from what I've seen so far, it's inconclusive and most of the research suggests that the vast majority of people do not perceive or experience these services as addictive or have issues. But I do think that there should be controls given to people to help them manage their experience better. And this is something that we're very focused on. Mr. Graham: (02:45:32) Mr. Dorsey? Mr. Dorsey: (02:45:34) I'm not aware of internal research, but we can follow up. But I do think, like anything else, these tools can be addictive and we should be aware of that, acknowledge it, and make sure that we are making our customers aware of better patterns of usage. So the more information the better here. Mr. Graham: (02:45:55) Thank you. Senator Hawley? Josh Hawley: (02:45:56) Thank you, Mr. Chairman. In the late 19th century, the heads of the biggest corporations in America, the robber barons, got together and they set rates, they set prices, they determined how they would control information flow. They determined how they'd get rid of competition. And I'll be darned if we aren't right back there again. Except for this time, you're the robber barons. Your companies are the most powerful companies in the world and I want to talk about how you're coordinating together to control information. In recent days, my office was contacted by a Facebook whistleblower, a former employee of the company, with direct knowledge of the company's content moderation practices. And I want to start by talking about an internal platform called Tasks that Facebook uses to coordinate projects, including censorship. The Tasks platform allows Facebook employees to communicate about projects they're working on together. That includes Facebook's censorship teams, including the so-called community wellbeing team, the integrity team, and the hate speech engineering team, who all use the task platform to discuss which individuals or hashtags or websites to ban. Now, Mr. Zuckerberg, you're familiar with the test platform, aren't you? Mr. Zuckerberg: (02:47:11) Senator, we use the Task system for, I think it's, as you say, for people coordinating all kinds of work across the company, although I'm not sure if I'd agree with the characterization specifically around content moderation that you gave. Josh Hawley: (02:47:28) Well, let's get into that. And let me see if we can refresh your memory and provide folks at home watching with an example. Here over my shoulder is an example, is a screenshot of the Task platform in use. You'll notice, if the cameras zoom in, several references to election integrity throughout on these lists of tasks. Again, this is shared across Facebook sites, company locations by working groups. What particularly intrigued me is that the platform reflects censorship input from Google and Twitter as well. So as I understand it, Facebook censorship teams communicate with their counterparts at Twitter and Google, and then enter those companies suggestions for censorship onto the task platform so that Facebook can then follow up with them and effectively coordinate their censorship efforts. Mr. Zuckerberg, let me just ask you directly under oath now, does Facebook coordinate its content moderation policies or efforts in any way with Google or Twitter? Mr. Zuckerberg: (02:48:32) Senator, let me be clear about this. We do coordinate on and share signals on security related topics. So for example, if there is signal around a terrorist attack or around child exploitation imagery or around a foreign government creating an influence operation, that is an area where the companies do share signals about what they see. But I think it's important to be very clear that that is distinct from the content and moderation policies that we or the other companies have, where once we share intelligence or signals between the companies, each company makes its own assessment of the right way to address and deal with that information. Josh Hawley: (02:49:21) Well, I'm talking about content moderation, I'm talking about individuals, websites, hashtags, phrases to ban. Is it your testimony that you do not communicate with Twitter or Google about content moderation, about individuals, websites, phrases, hashtags to ban? Just yes or no? Do you communicate with Twitter or Google about coordinating your policies in this way? Mr. Zuckerberg: (02:49:46) Senator, we do not coordinate our policies. Josh Hawley: (02:49:49) Do your Facebook content moderation teams communicate with their counterparts at Twitter or Google? Mr. Zuckerberg: (02:49:56) Senator, I'm not aware of anything specific, but I think it would be probably pretty normal for people to talk to their peers and colleagues in the industry. [crosstalk 02:50:05] Josh Hawley: (02:50:04) It would be normal, but you don't do it? Mr. Zuckerberg: (02:50:07) No, I'm saying that I'm not aware of any particular conversation, but I would expect that some level of communication probably happens. It's different from coordinating what our policies are or our responses in specific instances. Josh Hawley: (02:50:22) Well fortunately, I understand that the task platform is searchable. So will you provide a list of every mention of Google or Twitter from the task platform to this committee? Mr. Zuckerberg: (02:50:34) Senator, that's something that I can follow up with you and your team after on. Josh Hawley: (02:50:39) Yes or no? I'm sure you can follow up with the list, but why don't you commit while I've got you here under oath, it's so much better to do this under oath. Will you commit now to providing a list from the tasks platform of every mention of Google or Twitter? Mr. Zuckerberg: (02:50:55) Senator, respectfully, without having looked into this, I'm not aware of any sensitivity that might exist around that. So I don't think it would be wise for me to commit to that right now. So I would have to follow- Josh Hawley: (02:51:08) That's a no. How many items on the task platform reflect that Facebook, Twitter, and Google are sharing information about websites or hashtags or platforms that they want to suppress? Mr. Zuckerberg: (02:51:20) Senator, I do not know. Josh Hawley: (02:51:23) Will you provide a list of every website and hashtag that Facebook content moderation teams have discussed banning on the task platform? Mr. Zuckerberg: (02:51:33) Senator again, I would be happy to follow up with you or your team to discuss further how we might move forward on that, but [crosstalk 02:51:42]. Josh Hawley: (02:51:41) Will you commit to it here? Senator Cruz and Senator Lee both asked you for lists of individuals, websites, entities that have been subject to content moderation. You expressed doubt about whether any such information exists, but you've also now said that the task website... You've acknowledged the test platform exists, that it is searchable. So will you commit to providing the information you have logged on the task website about content moderation that your company has undertaken? Yes or no? Mr. Zuckerberg: (02:52:09) Senator, I think it would be better to follow up once I've had a chance to discuss with my team what any sensitivity around that would be that might prevent the kind of sharing that you're talking about. But once I've done that, I would be happy to follow up. Josh Hawley: (02:52:25) All right. So you won't commit to do it here. We could of course subpoena this information, but I'd much rather get it from you voluntarily. But I think, let everybody take note, that Mr. Zuckerberg has now repeatedly refused to provide information that he knows that he has and has now acknowledged that he has, that Tasks has [inaudible 02:52:42] Let me switch to a different topic. Mr. Zuckerberg, tell me about Sentra. What is the Facebook internal tool called Sentra? Mr. Zuckerberg: (02:52:51) Senator, I'm not aware of any tool with that name. Josh Hawley: (02:52:55) Well, let me see if this refreshes your memory. There's a demonstrative now over my shoulder. Sentra is a tool that Facebook uses to track its users not just on Facebook, but across the entire internet. Sentra tracks different profiles that a user visits, their message recipients, they're linked accounts, the pages they visit around the web that have Facebook buttons. Sentra also uses behavioral data to monitor users accounts even if those accounts are registered under a different name. And you can see a shot here, a screenshot provided to us of the central platform. We blocked out the user's name in the interest of privacy, although you can see this individual's birth date and age, when they first started using Facebook, their last login, as well as all manner of trackings. How many different devices have they used to access Facebook? How many different accounts are associated with their name? What accounts have they visited? What photos have they tagged? And on and on and on. Mr. Zuckerberg, how many accounts in the United States have been subject to review and shut down through Sentra? Mr. Zuckerberg: (02:53:52) Senator, I do not know because I'm not actually familiar with the name of that tool. I'm sure that we have tools that help us with our platform and community integrity work, but I am not familiar with that name. Josh Hawley: (02:54:06) Do you have a tool that does exactly what I've described and that you can see here over my shoulder? Or are you saying that that doesn't exist? Mr. Zuckerberg: (02:54:15) Senator, I'm saying that I'm not familiar with it and that I'd be happy to follow up and get you and your team the information that you would like on this. But I'm limited in what I'm familiar with and can share today. Josh Hawley: (02:54:32) Always amazing to me, Mr. Chairman, how many people before this committee suddenly develop amnesia. Maybe it is something about the air in the room. Let me ask you this, when a Facebook employee accesses a user's private information like their private messages or their personally identifiable data, is a record made of that, Mr. Zuckerberg? Mr. Zuckerberg: (02:54:53) Sorry Senator, could you repeat that? Josh Hawley: (02:54:54) Record made of any time a Facebook employee accesses a user's private information, personal identifiable information? Josh Hawley: (02:55:03) ... private information, personal identifiable information. For example, messages. Is a record made anytime a Facebook employee does that? Mr. Zuckerberg: (02:55:09) Senator, I believe so. Josh Hawley: (02:55:10) Does it trigger an audit? Mr. Zuckerberg: (02:55:14) Senator, I think sometimes it may. Josh Hawley: (02:55:18) How many audits have been conducted? Mr. Zuckerberg: (02:55:21) Senator, I do not know the exact number of audits off the top of- Josh Hawley: (02:55:23) Can you get me a list? Mr. Zuckerberg: (02:55:26) Senator, we can follow up on that to see what would be useful here. Josh Hawley: (02:55:31) I'm almost finished, Mr. Chairman. Will you commit to giving us a list of the number of times Facebook employees have accessed users' personal account information without their knowledge? Yes or no? Mr. Zuckerberg: (02:55:45) Senator, we should follow up on what would be useful here. It is, of course, in the operations of the company, if someone reports something, sometimes necessary for people at the company to go review and understand the context around what is happening when someone reports something. So this is fairly frequent and is a matter of course. We do have security systems that can detect anomalous patterns to flag, but we should follow up in more detail on what you're interested in. Josh Hawley: (02:56:19) Mr. Chairman, I'll just say in closing that what we have here is clear evidence of coordination between Twitter, Google, and Facebook. Mr. Zuckerberg knows he has the tools to track this, but he either doesn't remember or won't commit to letting us see it. We have evidence of Facebook tracking its own users all across the web. Mr. Zuckerberg won't answer questions about it, can't remember the name, isn't sure if the tool is deployed in this way, and won't commit to giving us basic information. I submit to you that this is both totally unacceptable and totally predictable because it is exactly what these tech companies have done to the American people and to Congress for years now, which is why it is time we took action against these modern day robber barons. Thank you, Mr. Chairman. Chairman Graham: (02:56:58) Senator Klobuchar. Senator Klobuchar: (02:57:00) I thank you very much, Mr. Chairman. I'm, as you know, the lead Democrat on the Antitrust Subcommittee, and I'm going to take a little different approach here than Mr. Hawley did when it comes to competition policy because I understand why they might be coordinating when it comes to security. What I want to focus on is what I think we're seeing all over this country, not just in tech. We're seeing a start-up slump, we're seeing more and more consolidation. And throughout history, we've seen that that is not good for small businesses, it's not good for consumers, and it's not good for capitalism in the end. Even successful companies, even popular companies, and even innovative companies are subject to the antitrust laws of this country. When I asked Mr. Pichai about this at the Commerce Committee hearing a few weeks ago, he said, he told me Google was happy to take feedback. And my response was that the Justice Department already provided feedback in the form of a federal antitrust complaint. And I know there is investigation reportedly going on out of the FTC right now regarding your company, Mr. Zuckerberg. Senator Klobuchar: (02:58:12) So I want to start with exclusionary conduct regarding excluding smaller competitors by limiting interoperability with the Facebook platform. The investigation that we saw in the House recently gave us a number of examples of companies, excluded companies, including Vine, Stackla, MessageMe, and Ark. And my view is this conduct, exclusionary conduct, not only damaged the ability of these smaller businesses to compete, but it deprived customers of convenient access. You're one of the most successful companies, biggest companies in the world, Mr. Zuckerberg, Facebook. Do you think that this is fair competition or not with regard to the interoperability and how you've conducted yourself with these other companies? Mr. Zuckerberg: (02:59:04) Senator, I'm generally strongly in favor of interoperability and building platform and API access for companies to be able to access. That's why we built the Facebook platform in 2007. Some of the policies that you mentioned I think came about because what we were seeing was not necessarily startups, but larger competitors like Google and some of our Chinese rivals from trying to access our systems in order to use their scale to compete with us better. And it just felt to us like, at the time, that that wasn't the intent of what we were trying to enable. Senator Klobuchar: (02:59:42) Okay, well, we may have a non-Chinese example here. I just want to know, I know that maybe we could hear from Mr. Dorsey. And I have concerns about Facebook's treatment of Twitter's subsidiary, Vine. It's my understanding is that once Facebook recognized Vine as a competitor after Twitter acquired it in 2013, it cut off Vine's ability to interoperate with Facebook so that Vine users couldn't upload their videos to Facebook. And then I think that Twitter shut down Vine in 2016. Mr. Dorsey, could you tell me about the actual impact of Facebook's actions on Vine's business, on Vine's ability to compete, and on your decision to shut down the service? And I know you're not a Chinese company. Mr. Dorsey: (03:00:29) Well, I don't know about the intent on the other side, but I know our own experience was we found it extremely challenging to compete with Vine. And ultimately, decided that the ball moved past us and we shut it down. Again, I don't know the specifics and the tactics and what was done, but we did find it very, very challenging market to enter even though we existed prior to some of our peers doing the same thing. Senator Klobuchar: (03:01:03) Okay, I'm going to move to something else quickly, Instagram and WhatsApp. We have some released internal Facebook emails in which you, Mr. Zuckerberg, wrote that Instagram was nascent, and if they grow to a large scale, they could be very disruptive to us. And in a later email, you confirmed that one of the purposes of Facebook acquiring Instagram would be to neutralize a competitor. You wrote those emails that were mentioned in that House report. Is that right, Mr. Zuckerberg? Mr. Zuckerberg: (03:01:33) Senator, I believe so. And I've always distinguished between two things, though. One is that we had some competition with Instagram in the growing space of kind of camera apps and photo sharing apps. But at the time, I don't think we or anyone else viewed Instagram as a competitor as a kind of large multipurpose social platform. In fact, people at the time kind of mocked our acquisition because they thought that we dramatically spent more money than we should have to acquire something that was viewed as primarily a camera and photo sharing app at the time. Senator Klobuchar: (03:02:11) Okay, well, and then here's the issues though. We don't know how it would have done. And when we look at your emails, it kind of leads us down this road, as well with WhatsApp, that part of the purchase of these nascent competitors is to, I'll use the words of FTC Chairman Joe Simons who just said last week, "A monopolous can squash a nascent competitor by buying it, not just by targeting it with anti-competitive activity." So I know that this is a subject of investigation. Maybe we'll be hearing something soon. But I think it's something that committee members better be aware of, not just with Facebook, but what's been going on with these deals that have gone through and how it has led to more and more consolidation, and how we as the Senate, and I just talked to Chairman Graham about this last week, could actually do something about this by changing some of the standards in our laws to make it easier to bring these cases, and not just involving tech. Senator Klobuchar: (03:03:10) So I want to go to something here at the end, the political ad discussion we had in front of the Commerce Committee, Mr. Zuckerberg. I know you said that Facebook had made over $2 billion on political ads over the last few years. You said, this was your quote, "Relatively small part of your revenue." I know that, but it's kind of a big part of the lives of politics when that much money is being spent on ads. This is a bill I actually have with Senator Graham. And yet, we have seen these political ads that keep creeping through despite your efforts to police them on your own. And this is why I would so badly like to pass The Honest Ads Act. One ad that went through, it says, "In three battleground states, ballots marked for Donald Trump had been discarded. Poll, will voter fraud only increase closer to November?" So it stated in three battleground states, paid ad, ballots marked for Donald Trump had been discarded. This played between September 29th and October 7th, 2020, had up to 200,000 impressions. Does this ad violate Facebook's policy? Mr. Zuckerberg: (03:04:16) Sorry, can you repeat what the ad was? Senator Klobuchar: (03:04:21) The ad was an American Action News ad they've advertised a lot of in your platform. And it said, "In three battleground states, ballots marked for Donald Trump had been discarded." This was pre-election. Mr. Zuckerberg: (03:04:36) Senator, I don't know off the top of my head if that specific ad violates our policies. I'd be happy to follow up afterwards on that. Senator Klobuchar: (03:04:42) Okay, would you commit to a policy where actual people's eyes, people, could review these ads instead of just being hit with algorithm review? Mr. Zuckerberg: (03:04:57) Senator, we do have a review and verification of political advertisers before they can advertise. Senator Klobuchar: (03:05:03) Okay, so does every ad go through a human being like the TVs do? Mr. Zuckerberg: (03:05:13) Senator, I think our policy is that we want to verify the authenticity of anyone who's doing political or social issue advertising. And I think it's worth noting that our people reviewers are not, in all cases, always more accurate than the technical systems- Senator Klobuchar: (03:05:33) Okay, so are you saying a human being reviews every ad? It's just really yes or no or I don't know? Mr. Zuckerberg: (03:05:36) Senator, I don't know. I don't think so. Senator Klobuchar: (03:05:39) Okay. Well, we'll follow up then in the written. And then you brought these cease and desist order against NYU for publishing a report that noting over the last two years, Facebook has not properly labeled approximately 37 million in political ads. Why would you not support this project? Why would you bring a cease and desist against them? Mr. Zuckerberg: (03:06:02) Senator, is that the project that was scraping the data in a way that might've been a- Senator Klobuchar: (03:06:08) That's your definition, but it's. Mr. Zuckerberg: (03:06:09) The FTC consent decree that we have. Senator Klobuchar: (03:06:12) The reason it's happening is we haven't passed The Honest Ads Act. So they're trying, they're not violating privacy, they're trying to get the ads so people can see the ads, other campaigns, journalists, everyone. Mr. Zuckerberg: (03:06:25) Senator, you know that I support The Honest Ads Act and agree that we should have that passed. And even before that, that we've implemented it across our systems. But I think in the case that you're referring to, that project was scraping data in a way that we had agreed in our FTC consent decree around privacy that we would not allow. So we have to follow up on that and make sure that we take steps to stop that violation. Senator Klobuchar: (03:06:56) Okay. Last, Mr. Dorsey, do you think there should be more transparency with algorithms as part of this is not just ... And I'm off of the ads now. I'm on just generically. Part of this is that people don't know how this data is going across the systems and across the platforms. And people basically are buying access, has been my impression. So that even if you say like, "What's the news in the last 24 hours?" Old stuff comes up. Something's gone awry from the beginnings of this. Would it be helpful, do you think, if there was more transparency with algorithms? Mr. Dorsey: (03:07:33) I do think it would be helpful, but it's technically very, very challenging to enforce that. I think a better option is providing more choice to be able to turn off the algorithms or choose a different algorithm so that people can see how it affects one's experience. Senator Klobuchar: (03:07:49) Okay. Thank you. And I ask that both of you look at the bill that Senator Kennedy and I have, the Journalism Competition and Preservation Act, to help the content providers negotiate with digital platforms. Thank you. Chairman Graham: (03:08:03) Thank you. Senator Tillis. Senator Tillis: (03:08:06) Thank you, Mr. Chairman. Thank you, gentlemen, for joining. Mr. Chairman, I know you've asked the question a couple of times about whether or not these platforms can be addictive. I think they probably can be based on what I've read in one of two ways. They could be just the nature of the personality and engagement in a tool that they can somehow relate to. But I also think there is a transactional addiction. And I think you also mentioned social dilemma. I think that's the use of analytics, which I don't criticize among the platforms, but it's the use of analytics to addict you to go down a certain path to produce a certain outcome. And that could either be an outcome forming an opinion or an outcome buying something you didn't even think about 30 minutes before you started going down that path. So I think there are things that we've got to look at. And I do agree with Mr. Zuckerberg and Mr. Dorsey, it's not conclusive, but common sense would tell you it's a problem already and it could become a bigger problem. Senator Tillis: (03:09:07) Mr. Zuckerberg, I'd like to go back to the task platform for a minute. When I looked at the screenshot that Senator Hawley put up, it looked a lot like a work management tool. Can you tell me a little bit about that? And how many people were actually engaged as users on that platform at Facebook? Mr. Zuckerberg: (03:09:30) Senator, yes, thank you. I was a bit surprised by Senator Hawley's focus on our task system because all this is, it's a basic internal project management tool. It's exactly what the name sounds like. It's used by companies, by people across our company, thousands of times a day to assign projects and track them. And it's used for all manner of different types of tasks across different people and teams. Senator Tillis: (03:10:03) And do you know roughly how many Facebook either contractors or full-time employees are actually users of the task platform? Mr. Zuckerberg: (03:10:15) I think that probably the majority of Facebook employees and people we work with have some interaction with the task system as part of some part of their work. It's basically just a company-wide to do list. Senator Tillis: (03:10:32) The other platform that Senator Hawley mentioned was the Centra platform. You said you weren't familiar with that one, but I think that is something that would be helpful maybe as a followup to really understand the nature of that platform. I won't press you on it today because you said you weren't specifically familiar with the name of the tool, but I would be more interested in how it's used. But Mr. Dorsey, does Twitter have a platform similar to the task platform for work management communication among staff? Mr. Dorsey: (03:11:05) Absolutely. I mean, even the smallest companies use these tools. We use a tool called [Tierra 00:03:11:10]. Senator Tillis: (03:11:11) Yep. I was involved in implementing these in my time in technology sector so I could see why you have these platforms. But Mr. Zuckerberg, you mentioned you didn't think there was a systematic coordination between Google and Twitter, but you could conceive of how people in similar professions may have a discussion, have a relationship, maybe talk about it over a beer. So could you see how the skeptic could see how these platforms could be used across platforms to force certain outcomes? Let's say you had 100 people at Facebook, 100 people at Twitter, and 100 people at Google that all had a political bent. They get together, they share notes, and then they go back and make decisions that could make it appear like it's a corporate initiative, but it could be an initiative by maybe some well-intentioned, but misguided staff. Could you at least conceive of that being possible? Mr. Zuckerberg: (03:12:12) Senator, I understand the concern and I think that coordination specifically on writing the policies or enforcement decisions could be problematic in the way that you're saying, which is why I really wanted to make sure that it was clear that what we do is share signals around potential harms that we're seeing, whether it's specific content in the aftermath of a terrorist attack that people are trying to share virally. So that way if one platform is seeing it, another platform can be prepared that it will probably see that content soon too. Signals around foreign interference in elections. But I think it's quite important that each company deals with those signals in the way that is in line with their own policies. And that, I think, is very different from saying that the companies are kind of coordinating to kind of figure out what the policies should be. I understand what the concern would be around that. And that's why I wanted to be clear about what we do and don't do there. Senator Tillis: (03:13:16) No, I agree with that. I would find it horribly irresponsible to think that this was some sort of a systematic approach across the platforms. But just with the sheer numbers of people that you all employ now, I could see how some of what's been suggested here in the hearing could actually occur with just small groups of people trying to manipulate certain outcomes. I don't want to get into details there except to know that the task platform, if it's similar to ones that I have experience with, has a lot of logging, has a lot of data, to where maybe you could do yourself a service by saying, "I hear what's been suggested here, but in analyzing the interactions between groups of people and seeing maybe some aberrations, some people being more active and more geared towards one outcome or another," it could actually help you aleve some of our concerns with the way these platforms are being manipulated. Senator Tillis: (03:14:14) I'm not going to have time to drill down into some of the specific questions. I am glad to hear that you all are open on some regulatory outcome. I will tell you, if you listen to my colleagues on both sides of the aisle today, I fully expect that Congress is going to act in the next Congress, that we're going to produce an outcome. And some people think that that's not possible because that maybe the Republicans and Democrats are far apart. But if you listen to what they're asking you, they're concerned with a kind of outcome that they didn't like on social media in equal measure. So I do believe that you would be well-served to come to the table as an industry and identify things. Senator Tillis: (03:15:02) Mr. Zuckerberg, I like what you've said about transparency. And Mr. Dorsey, I do think that the algorithms, when you talk about the sheer scale, are probably the most sustainable way to go. But we're still going to have to have some confidence. I like your concept on choice as well, but we're going to have to have more visibility in what's occurred and what's produced certain outcomes. Like a Veteran's Day post that I did after the election, it was actually after my opponent had conceded. I just posted a picture thanking veterans. And for a period of time, I think it was suspended and directing people towards election results. I would like to think, if that was a result of an algorithmic decision, that my opponent, who almost certainly posted a veteran's ad and every other person who was up for election got a similar treatment. Because if they didn't, it would seem to me that there was some other factor in play if these algorithms are being applied to the base of, in that case, political commentary from elected officials or candidates. Senator Tillis: (03:16:10) So I view this hearing as an opportunity to seek your commitment on two things. One I mentioned to you all yesterday, I've got a Intellectual Property Subcommittee hearing in the middle of December. I would like to have a Facebook and Twitter representative there. I know that you're very different platforms, but I think you play very prominently in a hearing that Senator Coons, who's sitting across from me now, would like to have you represented. I think I can speak for Senator Coons that that would be helpful. And we'd like to get your commitment to have witnesses for that hearing in the middle of December. Mr. Zuckerberg, can I get that commitment? Mr. Zuckerberg: (03:16:46) Senator, yes. We will make sure that we have the right subject matter expert to join your hearing. Senator Tillis: (03:16:53) Thank you. And Mr. Dorsey? Mr. Dorsey: (03:16:56) We'll follow up with determining the best course of action there. Senator Tillis: (03:17:01) Thank you. And then we'll be following up on a series of questions that I'd like to ask that let me get my head around some of the analytics information that I think you almost certainly have and hopefully be willing to share it, but we'll do that in a collaborative way in my office. Thank you for being here today. Chairman Graham: (03:17:19) Thank you. We're going to take a five minute break. I think our witnesses have requested a break and they certainly have earned it. And if it's okay with you, Senator Coons, we'll come back in about five minutes. Thank you. [inaudible 03:17:43]. Chairman Graham: (03:22:36) (silence). Okay. Do we have our witnesses on the other end? Mr. Zuckerberg, Mr. Dorsey? We got both. Thank you. I'm sorry we went so long without a break. Senator Coons. Senator Coons: (03:23:06) Thank you, Mr. Chairman. In the last four years, we have seen some unprecedented attacks on our democratic institutions, our social norms, the ways in which we conduct ourselves in this democracy, and many would say on truth itself. And in today's society, you can't talk about truth without also considering the impact of social media and social media platforms. So if I might, Mr. Zuckerberg and Mr. Dorsey, free expression and open debate are, of course, core values of our society. But whether you wished for it or not, the inescapable fact is your algorithms, your policies, and your business decisions shape what billions of people across the world, and a working majority of people here in our nation, understand to be true. That's the case for election integrity, for a potential COVID-19 vaccine, for climate change, for hateful and dangerous stereotypes, and many other critical issues. Senator Coons: (03:24:04) I also want to recognize that it, in no small part, was the hard work of many, led by your ingenuity and resolve, that built these impressive American companies and revolutionized the way the world communicates. We need that same resolve to reckon today with what must be done to win our society's battle for truth. Mr. Zuckerberg, as you know, yesterday, I sent you, along with 14 of my colleagues, a total of 15 senators, we sent you a letter urging Facebook to do more to address hate speech and calls to violence on the platform. We focused particularly on anti-Muslim bias on an issue that warrants specific attention given the tragic consequences of anti-Muslim hate speech in Myanmar and Sri Lanka and New Zealand and right here in the United States. And I appreciate that Facebook has taken actions in response to these issues, but this letter points out why we need better metrics and transparency to actually evaluate your actions. So my colleagues and I urge better enforcement, in particular, of your call to arms policy, which could have made a difference in a recent tragedy in Kenosha, Wisconsin. Senator Coons: (03:25:17) You and I spoke last week. I appreciated our conversation. Can I count on you to provide specific and written responses to each of the questions in this letter? And then can we discuss them again? Mr. Zuckerberg: (03:25:33) Senator, yes. I read your letter and I commit to getting back in detail with our team to address the important topics that you've raised. And one of your questions that I can actually answer right now, I think it was your second question about reporting in our quarterly transparency reports about the prevalence of hate speech that we find on our platforms. We will actually be adding that metric into our transparency reports this Thursday when we announce our latest transparency report. Senator Coons: (03:26:16) Thank you, Mr. Zuckerberg. Let me just make sure I hear you right about prevalence because that's one of my areas of concern is the absence from the report of the prevalence of hate content. You mean you'll be reporting, not just what percentage of hate speech on the platform you're identifying, catching, proactively removing, but the total volume? Mr. Zuckerberg: (03:26:37) Senator, that's my understanding is, yeah, the prevalence of that content as a percentage of content on the platform. And over time, our goal is going to be to get into more detail, which is the subject of some of the questions that you've asked here, as well as we've already committed to an independent audit of the community standards enforcement reports. So that way people can have full confidence in all of the numbers that we're putting out. We've been doing these reports for, I think, less than a few years now. And we'll continue to flesh them out and add more details, that way people can apply the appropriate oversight and scrutiny to the work. Senator Coons: (03:27:21) Thank you. I want to move on for a moment, if I could, about your call to arms policy. You said earlier today that Facebook made an operational mistake in not taking down an event page that called for people to bring weapons to a public park in Kenosha. As I think we all know, there was a tragic incident of vigilantism in Kenosha where a young man brought his AR-15 from Illinois to Kenosha and ended up with two protesters dead and one injured. You indicated this operational mistake was because Facebook had just adopted its militia policy a week earlier, and contractors without specialized training didn't pick up the violation. And I appreciate your frankness as to that in your answers to questions earlier today from Senator Durbin. But your response to Senator Durbin didn't mention that the event page also violated a separate call to arms policy in place for over a year that contractors aren't tasked to enforce. So I just have to ask as a followup, why didn't you before, and also today, reference the call to arms policy when reviewing what went wrong in Kenosha? Mr. Zuckerberg: (03:28:31) Senator, my understanding is that that post did not necessarily violate that call to arms policy at the time. The call to arms policy does not prohibit anyone from saying, "Let's go get our guns and do something." For example, if people are organizing a hunting trip, that's obviously not going to be something that should be against the policies. But what we do on some of these policies, which I think I'm glad to get the opportunity to address this, is some of these are context specific and just require a higher level of context and expertise in the area to enforce. So we don't necessarily have all of the 35,000 reviewers assess every single one of these policies. So I can follow up in more detail, if you'd like, on the call to arms policy and the nuance there specifically, but that's also a bit on how we operationalize these policies. Senator Coons: (03:29:36) Thank you for that answer. I do want to follow up because just facially, it seemed to me that this was a violation of your own call to arms policy. But I look forward to that conversation. Mr. Dorsey, if I might, at a House Energy Committee hearing, I think it was two years ago, you committed to something that I was just discussing with Mr. Zuckerberg, an independent civil rights audit. But in your case, of Twitter. The audit released by Facebook in July has proven invaluable- Senator Coons: (03:30:03) ... Twitter, and the audit released by Facebook in July has proven invaluable to bringing sunlight to some key areas in which Facebook does need to improve. Will you follow through in your commitment and commission to this independent audit of Twitter? Mr. Dorsey: (03:30:15) So we work with civil rights groups all over the country and around the world to get feedback. We're in constant conversation with them, and we do believe that being more transparent and making our transparency report a lot more robust, which today we still have some gaps, is important for any entity to audit independently of us. We believe that's important, because an audit like that could take away from the work that we need to do. We'd rather provide the information in a raw format so that people can do that work. Senator Coons: (03:30:51) If I heard you right, you aren't going to pursue an independent civil rights audit, but you are going to continue to release data and to consult with civil rights groups. I'd welcome a more thorough answer as to in which way having an independent outside audit would actually harm your transparency efforts. Mr. Dorsey: (03:31:11) I don't mean it would harm it. I mean that we want to provide enough information so that people can do this work independently of us on their own timelines, and that's where we need to make our transparency report more robust. And as I said, we have regular conversations with these groups and take feedback regularly. Senator Coons: (03:31:32) You do, Mr. Dorsey, have policies against deep fakes or manipulated media against COVID-19 misinformation, against things that violate civic integrity, but you don't have a standalone climate change misinformation policy. Why not? Mr. Dorsey: (03:31:51) Well, misleading information, as you are aware, is a large problem. It's hard to define it completely and cohesively. We wanted to scope our approach to start to focus on the highest severity of harm. We focused on three areas, manipulated media, which you mentioned, civic integrity around the election, specifically in public health, specifically around COVID. We wanted to make sure that our resources that we have have the greatest impact on where we believe the greatest severity of harm is going to be. Our policies are living documents. They will evolve. We will add to them, but we thought it important that we focus our energies and prioritize the work as much as we could. Senator Coons: (03:32:41) Well, Mr. Dorsey, I'll close with this. I cannot think of a greater harm than climate change, which is transforming literally our planet and causing harm to our entire world. I think we're experiencing significant harm as we speak. I recognize the pandemic and misinformation about COVID-19, manipulated media also cause harm, but I'd urge you to reconsider that because helping to disseminate climate denialism, in my view, further facilitates and accelerates one of the greatest existential threats to our world. So thank you to both of our witnesses. Thank you, Mr. Chairman. Mr. Graham: (03:33:17) Senator Ernst. Senator Ernst: (03:33:22) Thank you, Mr. Chair, and Mr. Zuckerberg and Mr. Dorsey, thank you both for being here with us today virtually and for your commitment to constantly improving the way your platforms are serving people across the country. There has been a lot of talk today. Many of us have been listening from our offices or online about the censorship of ideas and news on your platforms, and these are the things that have been at the forefront of American's minds in the lead up to the election, as well as the week since our 2020 general election. The people that I hear from, of course, believe that conservatives were wrongfully being silenced while those on the left that were given basically free reign of your platforms. One of the points of contention that is often brought up is that you do recruit heavily from California, which leads to your employee base skewing quite heavily to the left. Senator Ernst: (03:34:28) So my first question is for both of you. Do you have concerns about your ability to monitor disinformation on both sides of the political aisle equally, given that the majority of your employees typically do lean towards the more progressive side? And again, to both of you, have you taken any steps then at all to make your employee base more representative of the country as a whole when it comes to political affiliation? And Mr. Zuckerberg, if we could start with you, please. Mr. Zuckerberg: (03:35:08) Thank you, Senator. I think those are both really important topics. In terms of assessing what is misinformation, I think it's important that we don't become the deciders on everything that is true or false ourselves, which is why we've tried to build a program of independent fact checkers that we can work with on this, and those fact checkers are accredited not by us but by the independent Poynter Institute for journalism as part of the international fact-checking network, and it includes fact checkers that I think span the political spectrum, as well as I think the majority of them who would call themselves apolitical. So we've tried to address the issue of making sure that there isn't a bias in our actions by actually having us not be the deciders on that type of content ourselves. And to your second question about taking steps to diversify the employee base, we this is a sensitive area in that I don't think it would be appropriate for us to ask people on the way in as they were interviewing what their political affiliation is, which of course makes it hard to know. (silence). Mr. Dorsey: (03:38:05) And I think the tools are in a state where we can do that more easily. We've obviously been forced to do it with COVID, and I don't think it's a state that we will return from. The days of having one centralized massive corporate headquarter in any one particular city are certainly over for us at least, and I think many other entrepreneurs starting companies today. Senator Ernst: (03:38:30) Yeah, very good. I really appreciate that, and I think that COVID has taught us all a very important lesson. For those to be able to work remotely, I think you will find a greater diversity in thought, which is very important I think for the types of platforms that you both represent. Senator Ernst: (03:38:48) Now, I'd like to move on to an entirely different topic, and since I began my career here in the Senate, I have been committed to of course protecting those who need it most and, and folks, our children are the most in need, and it's our job as lawmakers to respond to the ongoing threats against them. Social media has created a whole new world for all of us, and it can help us share that information and resources with the public about human trafficking and child exploitation, and it can also help us keep track of sexual predators and ensure our children are safe from those known threats. In fact, I've been working on legislation that would help update what information sexual predators have to provide about their online identities. And as we all know, however, social media can also be incredibly harmful. Child sexual abuse materials, CASM, is present on nearly every single social media platform that exists, and in such polarized times, I am grateful that it is this subject that we do find it doesn't matter if you're on the left or the right. We can come together to find solutions for this issue. Senator Ernst: (03:40:10) Mr. Zuckerberg, I know that you and I touched upon this briefly last week when we spoke over the phone, and I do hope, Mr. Dorsey, that you also share Mr. Zuckerberg's commitment to fighting these types of issues on your platforms. So just very briefly here as I'm running out of time, but Mr. Zuckerberg, I do understand that Facebook is planning to outfit Facebook Messenger with end to end encryption. And how do you hope to prevent the dissemination of child sexual abuse material if neither law enforcement nor you can access that messenger data? Is there some sort of apparatus that you will have in place that can help law enforcement with those situations? And then Mr. Dorsey, we'll go to you next as well. Mr. Zuckerberg: (03:40:59) Senator, thank you for this. I think you're you're right on every count in what you just said, both that child sexual exploitation is one of the greatest threats that we focus the most on, And it is also an area that we'll face new challenges as we move to intending encryption across our messaging systems. Of course, the reason why we're moving to encryption is because people want greater privacy and security in their messaging systems, and over time are choosing systems that can provide them more privacy and security. That's something that I think it makes sense for us to offer. I think encryption broadly as good, but it is going to mean that we're going to need to find and develop some new tactics. Mr. Zuckerberg: (03:41:53) A lot of what we have found around the best ways to identify bad actors on our systems is not actually by looking at the specific content itself, but by looking at patterns of activity and where is it that a group or a person is not behaving in the way that a normal person would, so you can flag and review that? And we've grown increasingly sophisticated at that. That that goes across the foreign interference prevention work that we do, and it also will be a factor here, and I'd be happy to follow up in more detail on what we have planned. But overall, I would say that this is something that we were very focused on, and I agree with your concern. Senator Ernst: (03:42:37) Okay, thank you very much. And Mr. Dorsey, you as well, so those that are on Twitter, making sure that law enforcement would have access if at all possible, if you could give me an overview of that, please? Mr. Dorsey: (03:42:51) Child exploitation is absolutely terrible, and we don't tolerate it on our service at all. We regularly work with law enforcement to address anything that we see, inclusive of the patterns that Mark has mentioned. The majority of Twitter is public, so we don't have as much activity in private channels, so it's a different approach, but we still see the same activity, and it's one of our highest priorities in terms of the severity of harm. Senator Ernst: (03:43:22) Thank you both very much for being accessible to us today. I truly appreciate your input. Mr. Chairman, thank you. Mr. Graham: (03:43:29) Thank you, Mr. Zuckerberg, I really want to appreciate what Facebook has done in the area of sexual exploitation of children. You all have done a very good job of trying to help law enforcement in that area. Senator Hirono. Senator Hirono: (03:43:42) Thank you, Mr. Chairman. Mr. Zuckerberg, for the second time in three weeks, you've been called before the Senate committee so that my Republican colleagues can beat you up over claims that your platforms are supposedly biased against conservatives. The fact of the matter is that these allegations are completely baseless. Everyone who has systematically looked at the content on social media from Media Matters to the Cato Institute to former Republican Senator John Kyl has found absolutely no evidence of anti-conservative bias, and data from CrowdTangle show that far right content from the likes of Fox News, Ben Shapiro, David Bongino dominates the daily top 10 most engaged pages on Facebook. So all of these allegations about the fact that you hire or all of your employees are left of center is a relevant of nothing, certainly not relevant on some sort of anti-conservative bias in terms of your practical moderation. Senator Hirono: (03:44:48) So the way I see it, this hearing is a transparent effort by my Republican colleagues to work the refs, and unfortunately, in my view, it is working. Two weeks ago, The Washington Post reported that Facebook has bent over backwards to avoid claims that it was biased against conservatives, and it removed a strike against Donald Trump Jr.'s Instagram account that would have penalized them as a repeat offender, apparently, one of several strikes removed from the accounts of Trump family members. For Trump super PAC, American First Action was allowed to post material rated false by Facebook's third party fact checkers without penalty. These are just a few examples, and they are nothing new. In 2019, Facebook included Breitbart, a website described by its co-founder as a platform for the alt-right, as one of its trusted news sources. Early in 2019, Facebook selected The Daily Caller, another site with white nationalist ties, to be one of its third party fact checkers. Senator Hirono: (03:46:00) And the Wall Street Journal has reported how Joel Kaplan, former deputy chief of staff to George W. Bush, stopped changes designed to make Facebook's algorithms less divisive because the changes would have disproportionately affected conservative users and publishers according to Kaplan. So Mr. Zuckerberg, you founded Facebook, a company with a market capitalization of approximately $80 billion, and you control a majority share of the company's voting stock. Mr. Zuckerberg, I'm really wondering at what point you will stop giving in to basis claims of anti-conservative bias and start exercising your control over Facebook to stop driving division and actually, to quote you, "build community and bring the world closer together," as you claim is Facebook's mission. Senator Hirono: (03:46:54) My questions to both of you; a recent Harvard study found that President Trump was the single biggest source of voting related misinformation in the run-up to the presidential election. Since the election, President Trump has only continued the lies on Twitter and Facebook, also claiming that he won reelection and that the election is being stolen from him. But the truth is Joe Biden won the election, as major news networks and the Associated Press have confirmed. In response to President Trump's lies, you have, at most, added a warning label while still allowing the president's misinformation to remain online. In response to questions from Senator Feinstein, we defended the labels, claiming they point people to a broader conversation around the election. I have serious questions about the effectiveness of these labels, particularly since President Trump and his allies continue to spread their lies. For both of you, what evidence do you have that these labels are effective in addressing President Trump's lies? Response, please. Mr. Dorsey: (03:48:05) So I think Mark mentioned this earlier as well. We are doing a retrospective on the effectiveness of all of our actions through the election. We believe the labels point to, as you said, a broader conversation that people can see what's happening with the election and with the results. We don't want to put ourselves in a position of calling an election. That is not our job, so we're pointing to sources and pillars that have traditionally done this in the past, and that is the intention of the policy. That's the intention of the labeling system. Senator Hirono: (03:48:47) Mr. Zuckerberg? Mr. Zuckerberg: (03:48:50) Senator, we view the additional context that we put on posts as part of an overall response and effort to make sure that people have reliable information about the election. So we don't expect that it's just going to be when people are seeing a post that may be casting doubt on a legitimate form of voting or may have misinformation that we can correct and help people understand how they could really vote, for example. So that's why we put the Voter Information Center prominently on the top of Facebook and Instagram for months leading up to the election and kept it afterwards so people can see reporting on the results. Mr. Zuckerberg: (03:49:40) As I mentioned in my opening statement, 140 million Americans visited that. I think this was the largest voting information campaign in the history of our country, so I think when taken together, these actions were quite strong of an effort to communicate accurate, reliable information to people at the times when they needed it, about how they can vote in the election, encouraging them to vote, having confidence in the election system, knowing who and when the election had been called. It's just part of an overall system. Senator Hirono: (03:50:19) My time is running. So all of the information, the actual information about voter information you provide, that is good, but we're talking about all of the misinformation. Actually, outright lies that are put out by the president, and you have these labels, and I really have questions as to whether or not this kind of labeling, and I'm glad that at least Mr. Dorsey is determining whether these labels do anything to actually create a larger framework for discussion. I really seriously doubt whether that is actually happening. Since I'm running out of time, I just wanted to get to Donald Trump is president, you consider a user of these. A lot of his posts get on whether they contain misinformation, especially on whether he won the election and COVID. You name it, the fraudulent elections that he alleges, et cetera. But I wonder what are both of you prepared to do regarding Donald Trump's use of your platforms after he stops being president? Will he still be deemed newsworthy and will he still get to use your platforms to spread this misinformation? Mr. Zuckerberg: (03:51:33) Senator, let me clarify. My last answer, we are also having academic study, the effect of all of our election measures, and they'll be publishing those results publicly. In terms of President Trump and moving forward, there are a small number of policies where we have exceptions for politicians under the principle that people should be able to hear what their elected officials are saying and candidates for office. But by and large, the vast majority of our policies have no newsworthiness or political exception, so if the president or anyone else is spreading hate speech or inciting violence or posting content that delegitimizes the election or valid forms of voting, those will receive the same treatment as anyone else saying those things, and that will continue to be the case. Senator Hirono: (03:52:31) Remains to be seen. Mr. Dorsey? Mr. Dorsey: (03:52:34) So we do have a goal around public interest where for global leaders, we do make exceptions in terms of whether, if a tweet violates our terms of service, we leave it up, but we leave it up behind an interstitial, and people are not allowed to share that more broadly, so a lot of the sharing is disabled with the exception of quoting it so that you can add your own conversation on top of it. So if an account suddenly is not a world leader anymore, that particular policy goes away. Mr. Graham: (03:53:11) Thank you. Senator Hirono: (03:53:11) So I am running out of time, but, Mr. Chairman, I'd like to enter into the record a number of studies, particularly a November 1, 2020 article in the Washington post titled "Trump allies largely unconstrained by Facebook's rules against repeating falsehoods, cement pre-election dominance," a May 26, 2020 article in the Wall Street Journal titled "Facebook executives shutdown efforts to make the site less divisive," three studies from Media Matters finding no anti-conservative bias on Facebook, and an article by Dr. Francesca Tripodi titled, "No, big tech isn't silencing conservatism." I would like to enter these items into the record. Mr. Graham: (03:53:52) Without objection. Senator Kennedy. Senator Kennedy: (03:53:57) Thank you, Mr. Chairman. Gentlemen, each of you has founded an extraordinarily successful company, and they're both American companies, and I think I would be remiss if I didn't say congratulations. I'm very proud of the fact that it was American ingenuity that did this. I think we can also both agree that both Twitter and Facebook have enormous power as a result of your success. You're not companies, your countries, at least in terms of power. I want to test a point of view here. I'm not sure I subscribe to it, but I want to get your thoughts on it. Mr. Dorsey, do you believe everything you read? Mr. Dorsey: (03:55:09) No. Senator Kennedy: (03:55:10) Why not? Mr. Dorsey: (03:55:13) I think it's healthy to have skepticism about everything and then have a mindset of verifying it and using as much information as possible to do so. Senator Kennedy: (03:55:26) Do you have somebody on your staff who protects you from reading things that they think you shouldn't? Mr. Dorsey: (03:55:34) No. Senator Kennedy: (03:55:36) Mr. Zuckerberg, do you believe everything you read? Mr. Zuckerberg: (03:55:41) No, Senator. Senator Kennedy: (03:55:43) Why not? Mr. Zuckerberg: (03:55:47) Because of a lot of things are incomplete or incorrect. Senator Kennedy: (03:55:53) So you exercise your own judgment? Mr. Zuckerberg: (03:55:57) Yes, Senator. Senator Kennedy: (03:56:00) Okay. Do you have somebody on your staff whose job is to filter things that they think you should not be reading? Mr. Zuckerberg: (03:56:12) Senator, not externally, although I would hope that the teams that I work with internally do their best to make sure that the information that they're presenting me with are always accurate. Senator Kennedy: (03:56:27) Okay. Here is a point of view. I'm not sure I subscribe to it, but it is a legitimate point of view, I think, and I'd like to know your thoughts on it. You have both, and this is directed to each of you, you have both Democrats and Republicans upset with you. The Democrats are upset with you, this point of view holds because they want you to publish ... I'm not using that word as a term of art or science here with any special meanings. The Democrats want you to publish stuff on your platforms that they agree with, but they don't want you to publish stuff that they disagree with. This point of view also holds that the Republicans are upset with you because they want you to publish things on your platforms that they agree with, but they don't want you to publish stuff on your platforms that they disagree with. Senator Kennedy: (03:57:43) What if we had a rule? What if your companies had rule? This is a question, not a suggestion. What if your companies had a rule that said, "Okay, people aren't morons. I would like to treat people as they treat me. That is that I can read what I want to read and exercise my own good judgment about whether I choose to believe it, so here's the rule we're adopting. If you go on Twitter or Facebook, you can't bully people. You can't threaten people. Maybe this is a subset of both of those, but you can't commit a crime with your words and you can't incite violence. But other than that, you can print any damn thing you want to, and we'll let our users judge." Give me your thoughts on that. Mr. Dorsey: (03:59:04) Those are generally the rules that we have. I mean, our focus on these policies- Senator Kennedy: (03:59:09) No, you don't, Mr. Dorsey. Excuse me for interrupting, but you're censoring right and left trying to make both sides happy, and you're making neither side happy. Mr. Dorsey: (03:59:20) No, that's not the intention. The intention is to- Senator Kennedy: (03:59:23) I know it's not the intention, but it's the result. Mr. Dorsey: (03:59:28) I can see why you might say that and why you might perceive that, and that's why we do think it's important that we add more transparency to how we moderate content, that we give more control to individuals to moderate their own content and focus on algorithms. But a lot of our policies are focused on making sure that people feel that they can express themselves in the first place and not driven away. Everything that you mentioned about bullying, about harassment, around illegal content or violence, incitement to violence, that is what our policies are, and that is our intent. Senator Kennedy: (04:00:00) I know, and excuse me for interrupting, but my time's limited, and I want to hear from Mr. Zuckerberg. But you're not just doing that. You've started to sensor content. Why not have both Mr. Biden and Mr. Trump able to say whatever they want to on your platform, so long as they don't threaten, bully, incite violence, commit a crime. I'm not justifying the use of either Twitter or Facebook to hurt the Rohingyas. Mr. Zuckerberg, what are your thoughts on my suggestion? Get out of the censorship business other than the exceptions I talked about? Mr. Zuckerberg: (04:00:43) Senator, in principle, I agree with what you are saying, although I think that there are more categories of harm than just the ones that you've mentioned. But I think the basic principle behind what you're saying is a definition of free expression that says that people should be able to share their opinions broadly, except if it's going to cause imminent or irreparable harm to another person, which even the most ardent first amendment supporters agree that you shouldn't be able to yell "fire" in a crowded theater if there's not actually a fire, because that could put people in the risk of imminent harm. So you mentioned terrorism, you mentioned child exploitation and bullying as forms of harm, and I think a lot of the debate is around what are other forms of harm? For example, we're in the middle of a pandemic, and we've assessed that misinformation about COVID and treatments that could put people in additional risk of getting the disease or not seeking the right treatment if they have it, that those are also things that could cause imminent harm. We've taken the position that select- Senator Hirono: (04:02:03) Mr. Zuckerberg, let me interrupt you, and I really do apologize, but I'm going to be cut off in a second and appropriately so. I'm not saying you're wrong by doing what you just described, but that makes you a publisher, and that creates problems with Section 230. I just think one point of view is that at some point, we've got to trust people to use their own good judgment, to decide what they choose to believe and not believe and not try to assume that we're smart and they're stupid, and that we can discern believable information and information that shouldn't be believed, but everybody else is too stupid to do it. I'm done. Thank you, Mr. Chairman. Mr. Graham: (04:03:04) I think you put your finger on a really maybe the central issue, Senator Kennedy, is how do we let people make up their own minds without what they're saying, creating violence or threats to others, a very complicated endeavor. Senator Booker. Senator Booker? Senator Booker: (04:03:27) Thank you. Chairman, can you hear me? Chairman? Mr. Graham: (04:03:30) Yes, and to our witnesses, we have two more senators and we'll be done, and I appreciate your patience. Senator Booker. Senator Booker: (04:03:38) I appreciate that, Mr. Chairman, and I appreciate listening to this hearing. I really want to bring just focus back to what I think is why we're here, which is the 2020 election, and I've been saying in this committee for many months now about the tragic consequences of us normalizing things that should express considerable outrage. There's not a person on this committee on either side that doesn't know who the next president of United States will be. President-elect Joe Biden and Kamala Harris will be the president and vice president of United States come January 20th, but what is going on right now is dangerous, and it is a threat to our democracy. For the first time in American history, we are seeing a sitting president of the United States make wild and baseless accusations that undermine the democratic process, that don't just delegitimize it. Senator Booker: (04:04:35) What the president United States is doing is trying to thwart our democracy. As we speak, Donald Trump is waging an all out war on the truth and our democratic systems, and one of his weapons of choice in this distant formation war is social media, and specifically the two gentlemen here, their platforms, Twitter and Facebook. You have the tools to prevent him from weaponizing these platforms to degrade our democracy and our democratic ... Senator Booker: (04:05:03) ... weaponizing these platforms to degrade our democracy and our democratic institutions, and to cause such damage that even after January 20th, it could be one of the first times that millions of Americans think and believe that this election was what is baselessly being charged by Donald Trump. Senator Booker: (04:05:20) Let's be clear on what's happened. Donald Trump's shameful and shameless lies that are persisting about voter fraud and the outcome of this election were some of the most engaged content on social media in the days after the election. By one measure, during the week after the election, his posts on Facebook made up all, every single one of the top 10 most engaged posts in the United States, and 22 out of 25 of the top most engaged posts in our country. And his number one post, the top of them all, was a false declaration of victory. On Twitter, his tweet on falsely claiming victory was viewed by millions of users. This was, and is, not just a disinformation campaign by the President of United States, but literally the most powerful person in our country doing an all out assault on the Constitutional ideal of a democracy that he was sworn to protect. Senator Booker: (04:06:23) Let's take a step back, because I think this would be bipartisan if we looked at what was happening in another country. If we saw, and I'm on the Foreign Relations Committee and I know how we come together on issues like this, if a strong leader, strong man leader of a democracy had denied his loss in a democratic election, made consistent and constant baseless claims about fraud, if he fired military leaders, while his Foreign Minister talked about a smooth transition of the defeated leaders next term, even potentially in jest, any government looking at this situation, including ours, would be putting out statements urging calm and calling for the peaceful transition of power, for the rule of law, for the honoring of democratic norms and traditions. Senator Booker: (04:07:10) We're seeing concrete consequences right now of President Trump's rhetoric. We are actually in the midst of the fourth largest mass casualty event in American history. This is not just something that should not be treated with calm and normalcy, but we all, people who believe in this country, should be standing up and talking about the consequences. Senator Booker: (04:07:32) We have his political appointee, the General Service Administrator, refusing to designate Joe Biden as president-elect and provide the transition team the resources mandated by federal law. Senator Booker: (04:07:44) It was not that long ago that the 9/11 Commission said that one of the things that undermined our ability to meet the terroristic threats to our country happened because of a transition that was undermined, or excuse me, a transition that did not happen on the normal course. President Trump's actions since election day should shock all of us. All of us who care about the welfare of our democracy. Who care about our norms. And I hope the platforms here can maintain the highest levels of vigilance. Senator Booker: (04:08:16) To the gentlemen before us today, I'd like to ask specifically, have you taken any steps to modify your platforms algorithms to ensure that blatantly false election disinformation posted by election officials and specifically the most powerful person in the United States, Donald Trump, isn't amplified? That his posts that might get a lot of interactions, that are dead wrong, don't somehow get boosted by your algorithms. If you could both respond to that as quickly as possible. Mr. Zuckerberg: (04:08:55) Senator, I'll go first and I share your concern on this and I think it's unfortunate that we had to put in place a policy around premature or false declarations of victory, but we had to do that. And we anticipated this back in September when we put the policy in place. And a lot of what we're trying to do is help distribute reliable information, which we attach both to posts on the topic by President Trump or any of the other candidates or elected officials who were talking on the subject. Mr. Zuckerberg: (04:09:34) But more importantly, we put that reliable information, including about election results, at the top of Facebook and Instagram for everyone to see. And that supersedes what the algorithm or what newsfeed chooses to show. Senator Booker: (04:09:48) I appreciate that. I'd just like to get Jack's. This is information I know Jack, if you want to just respond on the algorithm. Excuse me, Mr. Dorsey, if you want to respond about the algorithms too. Do you have a specific measures that you're taking to prevent your algorithms from boosting false content? Mr. Dorsey: (04:10:07) Yes, so many of the labels did change how the algorithms amplify content. Senator Booker: (04:10:16) President Trump right now is spreading dangerous misinformation about our electoral process. It's going on right now. And maybe if you guys, you gentlemen, would just cogently... Through this process, this ongoing process right now, are there steps you will be taking that you have not already delineated as we are going into what could be very dangerous waters, unprecedented waters, in this country? Is there any additional steps that you will be taking right now in the coming days or weeks to stop the further amplification and undermining of our democracy? Senator Booker: (04:10:54) We are heading potentially, depending upon the behavior of a president who's shown himself to be erratic. Are there steps that you are prepared to take in the coming days and weeks to address this misinformation that we are seeing is coming in an unrelenting manner? [crosstalk 04:11:16]. Mr. Zuckerberg: (04:11:18) This is unfortunately an eventuality that we planned for and we've taken a number of steps, not just including the fact checking program that we've set up broadly, but we stopped recommending all civic and political groups as an example, because of the risk of misinformation or harm growing there, we've temporarily paused all political ads because of a risk of potential abuse or inflaming tension or potential unrest or violence. And there are a number of other steps that we've taken like this as well, that we've done in other countries when there are risks of civil unrest and that we've shown have worked. I'd be happy to follow up in detail on all of the steps that we're taking there. Senator Booker: (04:12:07) Thank you. Your team has been helpful. Mr. Dorsey, any new steps that you want to give me? And I'm now treading on the indulgence of the chairman, if you could be really cogent. I mean new steps. Mr. Dorsey: (04:12:18) We're going to continue to remain vigilant around our enforcement of civil integrity. I think it's really important that we stay agile and that we learn. So we need to learn about the effectiveness of this work and how to carry it forward. Senator Booker: (04:12:31) If the chairman would indulge me in one more sort of question to Mr. Zuckerberg. I was really pleased that the group Stop The Steal, which was a group formed on Facebook with disinformation trying to delegitimize the election. I was grateful that you all suspended that account after 24 hours. But I'm concerned about what lessons you've learned. Because clearly outside groups like the Center for Countering Digital Hate flagged that groups posts containing calls to violence hours before Facebook did. And I'm wondering what you all have learned about speed. Senator Booker: (04:13:13) There's an old saying that a lie can travel halfway around the world while the truth is still putting its pants on. What does Facebook really factor in in terms of speed and trying to combat surges of disinformation about this group? Senator Booker: (04:13:29) Maybe another example, an additional sort of addendum to that question, Mr. Zuckerberg, Twitter, for example, permanently suspended, Mr. Bannon's Twitter account, it suspended his show's Twitter account, after he made horrendous steps about acts of violence against Dr. Fauci and FBI Director Wray. Senator Booker: (04:13:53) I guess I'm just simply asking why would Facebook not take the similar steps and similar stand? Mr. Zuckerberg, very cogently, could you talk about that speed issue? When your platforms diverge, I'm really wondering why one platform in Twitter saw that as a standard to remove, but you all did not follow in that decision. Mr. Zuckerberg: (04:14:20) Thanks, Senator. I'm happy to address both of those. On speed, you're certainly right that that's important. And part of what we focus on is figuring out which types of messages or things are going to go viral quickest because it's not just about trying to get to everything within five hours for example, it's actually much more important to get to the harms that are going viral quickly within an hour, even if some things that are probably not going to get much distribution at all might be deprioritized for a little bit longer. Mr. Zuckerberg: (04:14:59) I think making sure that we stay on top of what are the hashtags, what are the groups, what are the messages, who are the bad actors who are trying to spread this content? And as we see the threat evolving, we are typically able to evolve and move faster as well. So we're very focused on that. [crosstalk 00:10:22]. Mr. Graham: (04:15:19) Thank you, very much. Anything else [crosstalk 04:15:23]. Senator Booker: (04:15:25) I just want to give you an amen [inaudible 00:04:15:28]. The second part of that question, I'd love to get on the record, but I just want to say to you, you mentioned earlier, I know you said that Chairman Graham will be chairman again, but I think you really said something really important earlier about the effects of social media platforms on our kids. I can cite many studies, like the University of Pittsburgh who said thar kids are on social media have about twice that the rates of eating disorders and image concerns. Senator Booker: (04:15:54) I just would really say, and I know that two gentlemen there would welcome the opportunity to come and discuss that perhaps with other experts, but there's something really going on in terms of the self-esteem, wellbeing, and even flourishing of our children who are deeply affected by these platforms, whether you want to use a technical term like addiction or not, there's enough evidence that these platforms and children's engagement on them is causing a heightened levels of sort of a deleterious effect on their wellbeing. I'd love it if we could do such a hearing sometime soon. Mr. Graham: (04:16:26) We follow up into the every patient Senator Blackburn. Thank you very much. Senator Blackburn: (04:16:30) Thank you, Mr. Chairman. I appreciate- Mr. Graham: (04:16:31) Last, but certainly not least. Senator Blackburn: (04:16:32) That is correct, and I appreciate that. And even though my colleague from New Jersey went twice his time, I am going to [crosstalk 00:11:44]. Mr. Graham: (04:16:43) These are Senate minutes. Senator Blackburn: (04:16:45) Yes, they are Senate minutes. I will agree with my colleagues who have talked about the impact on children. The distribution of information that damages women and children, that leads to violence against women and children, human trafficking, the utilization of these platforms by pedophiles. This is something that we are going to continue to work on. Senator Blackburn: (04:17:09) When I was in the House we passed legislation to put more tools in the hands of local law enforcement to fight this. But you all at these social media platforms are going to have to do your part to work with us on this to protect our children. Senator Blackburn: (04:17:27) I will also say that we're keeping an eye, and with each of you yesterday I talked about your financial component, Square there for Mr. Dorsey and Libra with Mr. Zuckerberg, and the application of these components to your sites. We're talking about 2020 elections, but we're also looking ahead to how we clean up some of what transpired before the 2022 elections. Senator Blackburn: (04:17:58) I think it's fair to say two that, you all probably are now fully aware that there's great frustration with Americans and with this committee, with the way you act invincible, the way your employees act as if you're the invincible gods of the Silicon Valley. Facebook and Twitter, don't get to be the last word in what counts as real news in this country, even though you're beginning to conduct yourself as news publishers and distributors. Senator Blackburn: (04:18:29) My colleagues and I have asked you all repeatedly through the years for greater transparency and to accept responsibility. You've chosen to do neither. So it is going to be up to us to change existing law and to hold you to account on behalf of the American people. Senator Blackburn: (04:18:50) Section 230, the reforms that we're going to put in place will take away this liability shield that you've turned into an opaque wall that you and your content moderators, whether they're algorithmic or human beings or combinations, are hiding behind. Senator Blackburn: (04:19:08) The Online Freedom and Viewpoint Diversity Act, I thank Chairman Graham and Chairman Wicker for working with me on this. This is set up for a markup in this committee on Thursday. Senator Blackburn: (04:19:22) Mr. Zuckerberg, you were stating earlier that we needed to put some definition in place. We're going to do that. We're going to take away nebulous language, and we're going to be specific, unlawful, inciting personal harm, inciting terrorism. We're going to do that and clear that up for you. Senator Blackburn: (04:19:44) Mr. Zuckerberg, Facebook is more like a government than a traditional company, is a statement that you have made, and there's a lot of power in that for you. So yes or no, on a couple of questions here. Does Facebook routinely sensor a user's account at the behest of a foreign government? Yes or no. Mr. Zuckerberg: (04:20:12) Senator, I'm not sure if there's anything in particular you're referring to, but in general we don't censor- Senator Blackburn: (04:20:19) Well, there is something in particular that I'm referring to and I'll answer it. Yes, you've done that. You have 60 million users in Vietnam. Of course, this is a communist regime. Under the orders of the Vietnamese government, did Facebook shut down and ban the account of a Vietnamese dissident because he criticized the government's land policy? Yes or no. Mr. Zuckerberg: (04:20:46) Senator, I'm not familiar with all the details of that, but I believe that we may have done that. And that in general, we try to follow the local laws of different countries we operate- Senator Blackburn: (04:20:57) Yes, you did. And you kept him off for three months. In Turkey, does Facebook have an anti-blasphemy policy where it will take down photos of the prophet Muhammad, if the Turkish government orders it to do so? Mr. Zuckerberg: (04:21:13) Senator again, we don't have a policy against that, but we do follow- Senator Blackburn: (04:21:19) Well, the answer is yes. Mr. Zuckerberg: (04:21:20) Well, we follow local laws in the countries where we operate. Senator Blackburn: (04:21:22) The answer is yes. In Russia, under pressure from the Russian government, did Facebook take down a post advertising the rally in support of the dissident, Alexei Navalny. The answer is yes. I'll help you with that. Senator Blackburn: (04:21:38) Do you believe it's Facebook duty to comply with state sponsored censorship so it can keep operating, doing business, and selling ads in that country? Mr. Zuckerberg: (04:21:49) Senator, in general, we try to comply with the laws in every country where we operate and do business. Senator Blackburn: (04:21:59) I think that you prioritize profit over principle. When you look at these countries, and also in communist China, which they have banned their citizens from you, you can't operate there. Senator Blackburn: (04:22:14) In China, Twitter, you have an opponent there. You've got a knockoff, Weibo, that is a Chinese Communist Party owned company. But your companies, even though they're banned there, you're still trying to do business in those countries. Mr. Dorsey, does Twitter do business with Huawei? Mr. Dorsey: (04:22:34) I don't believe so, but we can follow up. Senator Blackburn: (04:22:40) I can answer it for you, sir. You helped launch Huawei's Mate 30 Pro 5G and it is featured on Twitter's marketing page website. How about Alibaba? You do business with Jack Ma's company with their links to the Chinese Communist Party? Mr. Dorsey: (04:23:01) If by business, you mean allowing people to advertise on our platform- Senator Blackburn: (04:23:05) Your answer is yes. Mr. Zuckerberg, are you aware that last year China's top internet regulator agreed to spend over $800,000 for the communist mouthpiece, the People's Daily, and they did this so that they could advertise and promote China to the American people on Facebook? Senator Blackburn: (04:23:26) The point of all of this, and the answer to that, Mr. Zuckerberg, whether you're aware or not, is you probably are, and you know that what they're doing is gaining access to this market. Senator Blackburn: (04:23:40) This is why we're going to keep a real close watch over what you all are doing with Libra and what you are doing with Square. Because we see what has happened. Ir's important for us to protect people and to protect human rights. Senator Blackburn: (04:23:59) Let me move to election content and that monitoring, because we do have concerns about some of the things that happen there. Mr. Zuckerberg, let me ask you this, have you heard of the Trump Accountability Project? Mr. Zuckerberg: (04:24:23) Senator, I'm not familiar with that. Senator Blackburn: (04:24:25) That is a project that is an attempt to blacklist Americans who have served in the Trump administration and to prohibit them from gaining future employment. Now in communist China, in Putin's Russia, in totalitarian states, the government regularly will issue a blacklist on their enemies. Enemies of the state are banned from getting a job and if their names fall on the blacklist, they are out. Senator Blackburn: (04:24:55) This seems disturbing that it would be happening here in this country. So Mr. Zuckerberg, do you agree with me there is seriously something wrong with an un-American blacklist tarring people from future employment simply because they belong to a different political party? Mr. Zuckerberg: (04:25:22) Senator, I generally agree that people should not be discriminated against because of political beliefs. Senator Blackburn: (04:25:30) Okay, that is a positive step. Now on Facebook, I wrote in a post, and I'm quoting, "The Trump Accountability Project is the epitome of the cancel culture. Our nation has long benefited from robust political debate and this effort to silence those who support our president is vile." Senator Blackburn: (04:25:56) As you can tell from this statement, nothing was said about the election or the results, either directly or indirectly, but somehow I got slapped with your elections flag sticker. So what each of you need to realize, and you've heard it time and again today you, say you don't keep lists. Obviously you have lists. Because there are some of us who are regularly censored and called down by your content moderators. Do we want to see these lists? Yes. How have you built these lists? We want to know. Senator Blackburn: (04:26:46) I would remind each of you, you are a Title 1 service, you are an information service. You are to be the new public square. But what you are doing with your power that you have derived because federal law gave you the ability to stand up and grow without being hit by lawsuits, you have used this power to run amuck. You have used it to silence conservatives. You have used it to build your lists. You have used this power to act like you hold all the power. That you can make these decisions. You have driven this cancel culture, because you have not called to account your moderators. You have refused to take responsibility for your employees and their actions, so thereby reigning you in on the issues of privacy, data security, content moderation, liability protections, defining who is a publisher in the virtual space, that is up to us, because you have proven you do not have the will, the strength, the ability, and you will not accept the responsibility to do it for yourselves. I yield my time. Mr. Graham: (04:28:21) Thank you very much, Senator Blackburn. To the two witnesses, you made it through. Thank you. Hopefully we'll understand a little bit better about where the committee's at and our concerns. I want to thank you for appearing. I wish we could do it in person, but I can understand why we had to do it remotely. Mr. Graham: (04:28:41) We will have more hearings coming up in the next Congress, I'm sure, to try to find ways to modify 230 to deal with some of the issues that were brought before the committee. I just want to thank you both and just say that you have been hugely successful in ways probably beyond your own imagination, and we've got problems around your platforms that have to be dealt with, and we will do it, hopefully, collaboratively. Mr. Graham: (04:29:08) The bottom line is we want to make these platforms better. We want to continue to grow this part of our society responsibly. And right now, without regulation or without lawsuit is pretty much becoming the wild wild west. And I appreciate both of you for being willing to try to find ways to come up with systems that will ensure more transparency, more choice, and more confidence. Senator Blumenthal: (04:29:40) Mr. Chairman. Mr. Graham: (04:29:40) Yes, sir? Senator Blumenthal: (04:29:42) If I may just add my thanks to the witnesses and also to you for having this hearing. I think there's one certainty here, which is that Mr. Zuckerberg and Mr. Dorsey will be back. They will be back in the next session of Congress. I hope that joining them will be Google and Amazon and others who should be held similarly accountable. Mr. Graham: (04:30:09) I agree. To these two companies, thank you for stepping up to the plate, and to the other companies, you need to be here also. Senator Blumenthal: (04:30:17) I, again, thank them. And we need to have greater accountability by reducing the shield. It's now nearly complete. And I want to thank you, Senator Graham, for working with me on the EARN IT Act, a number of our colleagues have raised the problem with child sexual abuse material. Best way to counter it is to act. We really are serious about all this rhetoric and the jumble of grievances that we've heard. Let's begin the journey with a single step. We can do it through the EARN IT Act. It's on the floor of the United States Senate having been reported unanimously out of this committee. Let's have a vote. Mr. Graham: (04:31:02) Agreed. Change is going to come. Thank you. The hearing is adjourned.